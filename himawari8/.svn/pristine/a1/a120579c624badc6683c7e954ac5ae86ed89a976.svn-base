__author__ = 'jano'
"""
    JMA'S mission specific HRIT Reader. Follows strictly http://www.jma.go.jp/jma/jma-eng/satellite/introduction/4_2HRIT.pdf

"""

import numpy as np
from collections import OrderedDict
import struct
import datetime
import os
import tarfile
import shutil
from mtsat.hrit.utils import toGDAL
from mtsat.geometry import ctrans
import bz2
import zipfile



MTSAT_HRIT_IMAGE_DATA = \
    {
        'VIS' : {
            'DK01': {'channel_type':'FD', 'NL':5500, 'NC':5500},
            'DK02': {'channel_type':'NH', 'NL':5500, 'NC':11000},
            'DK03': {'channel_type':'SH', 'NL':5500, 'NC':11000}
        },
        'IR1': {
            'DK01': {'channel_type': 'FD', 'NL': 5500, 'NC': 5500},
            'DK02': {'channel_type': 'NH', 'NL': 1375, 'NC': 2750},
            'DK03': {'channel_type': 'SH', 'NL': 1375, 'NC': 2750}
        },
        'IR2': {
            'DK01': {'channel_type': 'FD', 'NL': 2750, 'NC': 2750},
            'DK02': {'channel_type': 'NH', 'NL': 1375, 'NC': 2750},
            'DK03': {'channel_type': 'SH', 'NL': 1375, 'NC': 2750}
            },
        'IR3': {
            'DK01': {'channel_type': 'FD', 'NL': 2750, 'NC': 2750},
            'DK02': {'channel_type': 'NH', 'NL': 1375, 'NC': 2750},
            'DK03': {'channel_type': 'SH', 'NL': 1375, 'NC': 2750}
        },
        'IR4': {
            'DK01': {'channel_type': 'FD', 'NL': 2750, 'NC': 2750},
            'DK02': {'channel_type': 'NH', 'NL': 1375, 'NC': 2750},
            'DK03': {'channel_type': 'SH', 'NL': 1375, 'NC': 2750}
        },
        'IR5': {
            'DK01': {'channel_type': 'FD', 'NL': 2750, 'NC': 2750},
            'DK02': {'channel_type': 'NH', 'NL': 1375, 'NC': 2750},
            'DK03': {'channel_type': 'SH', 'NL': 1375, 'NC': 2750}
        }
    }

MTSAT_HRIT_NAV_DATA = {

    'VIS': {
            'DK01': {'channel_type': 'FD', 'CFAC': 40932513, 'LFAC': 40932513, 'COFF': 5500, 'LOFF': 5500, 'RESOLUTION':1000},
            'DK02': {'channel_type': 'NH', 'CFAC': 40932513, 'LFAC': 40932513, 'COFF': 5500, 'LOFF': 5300, 'RESOLUTION':1000},
            'DK03': {'channel_type': 'SH', 'CFAC': 40932513, 'LFAC': 40932513, 'COFF': 5500, 'LOFF': 200, 'RESOLUTION':1000}
    },
    'IR1': {
            'DK01': {'channel_type': 'FD', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1375, 'RESOLUTION':4000},
            'DK02': {'channel_type': 'NH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1325, 'RESOLUTION':4000},
            'DK03': {'channel_type': 'SH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 50, 'RESOLUTION':4000}
    }
    ,
    'IR2': {
            'DK01': {'channel_type': 'FD', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1375, 'RESOLUTION': 4000},
            'DK02': {'channel_type': 'NH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1325, 'RESOLUTION': 4000},
            'DK03': {'channel_type': 'SH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 50, 'RESOLUTION': 4000}
    }
    ,
    'IR3': {
            'DK01': {'channel_type': 'FD', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1375, 'RESOLUTION': 4000},
            'DK02': {'channel_type': 'NH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1325, 'RESOLUTION': 4000},
            'DK03': {'channel_type': 'SH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 50, 'RESOLUTION': 4000}
    }
    ,
    'IR4': {
            'DK01': {'channel_type': 'FD', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1375, 'RESOLUTION': 4000},
            'DK02': {'channel_type': 'NH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1325, 'RESOLUTION': 4000},
            'DK03': {'channel_type': 'SH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 50, 'RESOLUTION': 4000}
    }
    ,
    'IR5': {
            'DK01': {'channel_type': 'FD', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1375, 'RESOLUTION': 4000},
            'DK02': {'channel_type': 'NH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 1325, 'RESOLUTION': 4000},
            'DK03': {'channel_type': 'SH', 'CFAC': 10233128, 'LFAC': 10233128, 'COFF': 1375, 'LOFF': 50, 'RESOLUTION': 4000}
    }

}






# a MTSAT HRIT image can have only following number of lines
MTSAT_HRIT_IMAGE_NLINES = 11000, 11000//2, 11000//4, 11000//8

#the number of lines in a full disk MTSAT HROIT image
MTSAT_HRIT_FDIMAGE_NLINES = 11000

MTSAT_HRIT_BYTE_ORDER = '>' # the byte order ot MTSAT HRIT files, BIG endian




RECORDS = {
    0: ('Primary Header', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('File_Type_Code', 'B'), ('Total_Header_Length', 'I'), ('Data_Field_Length', 'Q')))),
    1: ('Image Structure', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('NB','B'), ('NC', 'H'), ('NL', 'H'), ('Compression_Flag', 'B')))),
    2: ('Image Navigation', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Projection_Name','32s'), ('CFAC', 'I'), ('LFAC', 'I'), ('COFF', 'I'), ('LOFF', 'I')))),
    3: ('Image Data Function', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Data_Definition_Block', '%ss')))),
    4: ('Annotation', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Annotation_Text', '%ss')))),
    5: ('Time Stamp', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('CDS_P_Field', 'B'), ('CDS_T_Field', '6s')))),
    6: ('Ancillary text', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Ancillary_Text','%ss')))),
    7: ('Key header', OrderedDict((('Header_Type', 'I'), ('Header_Record_Length', 'I'), ('Key_Number','I')))),
    128: ('Image Segment Identification', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Image_Segm_Seq_No','B'), ('Total_No_Image_Segm', 'B'), ('Line_No_Image_Segm', 'H')))),
    129: ('Encryption Key Message Header', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'),  ('Station_Number', 'H')))),
    130: ('Image Compensation Information Header', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'),  ('Image_Compensation_Information', '%ss')))),
    131: ('Image Observation Time Header', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Image_Observation_Time', '%ss')))),
    132: ('Image Quality Information Header', OrderedDict((('Header_Type', 'B'), ('Header_Record_Length', 'H'), ('Image_Quality_Information', '%ss'))))
}

class HRITHeader(object):

    """
        JMA mission specific Header Object.
        While the document mixes sometimes ambiguously/interchangeably to the concepts of Header and Record
        this module distinguishes them clearly. A HRIT Header consists of reader Records. While a Record can have a name that contains word Header
        it is still a record, respectively a dictionary.
        A header is therefore a sum of records, some of them general and some mission specific.
        Simple as that.

        The Header is dynamic, that is it can adapt and read Unknown records.
        At runtime the RECORDS dictionary controls the exact structure of each record.
        One can distinguish two


    """

    def __init__(self, buffer=None, byte_order=None):
        if buffer is None:
            raise ValueError, 'Can not create a Header object without a buffer'
        try:
            iter(buffer)
        except TypeError:
            raise TypeError, 'buffer argument is not iterable'
        if not isinstance(buffer, basestring):
            raise TypeError, 'buffer argument should be a string'
        if byte_order is None:
            raise ValueError, 'Can not create a Header object without knowing the byte order'

        htype_fmt = '%sB' % byte_order
        hlen_fmt = '%sH' % byte_order
        i = 0
        self.records = {}
        while i < len(buffer):
            #compute header type
            rec_type = struct.unpack(htype_fmt, buffer[i])[0]
            #compute record length
            rec_len_start = i + 1
            rec_len_end = rec_len_start + 2
            rec_len = struct.unpack(hlen_fmt,buffer[rec_len_start:rec_len_end])[0]
            rec_start = i
            rec_end = i + rec_len
            #extract the bytes corresponding to the record
            rec_buffer = buffer[rec_start:rec_end]

            #fetch the format and element names of the recpords, altough they are called headers they are records in the header.
            #I am following  strictly http://www.jma.go.jp/jma/jma-eng/satellite/introduction/4_2HRIT.pdf

            hitems = RECORDS.get(rec_type, ('UnknownHeader', OrderedDict([('Content', '%ss')])))
            hname, records = hitems
            #compute format string. because certain records have a variable length, the format string contains a format charater "%s"
            #the value of this format charater has to be computed dynamically and filled in
            fmt = '%s%s' % (byte_order, ''.join(records.values()))
            fchar = '%s'
            if fchar in fmt: # the records length is variable
                #get the  known part and variable part
                known_part, variable_part = fmt.split(fchar)
                #compute the size of the known part
                sz = struct.Struct(known_part).size
                #substract the  size of the known part from the record length to get the size of the variable part
                diff = rec_len - sz
                #compute the format string
                fmt = known_part + fchar % diff + variable_part
            #print rec_type, fmt
            rec_data = dict(zip(records.keys(), struct.unpack(fmt, rec_buffer)))

            #handle specifics
            #extract subsatellite point
            if rec_type == 2:
                proj_str = rec_data['Projection_Name'].strip()
                rec_data['SSP'] = float(proj_str.split('(')[1][:-1])
                rec_data['Projection_Name'] = proj_str
            #convert CDS_T_Field bytes into datetime according to CCSDS
            if rec_type == 5:
                t_field_buffer = rec_data['CDS_T_Field']
                days = struct.unpack('%sH'% byte_order, t_field_buffer[:2])[0]
                msecs = struct.unpack('%sI'% byte_order, t_field_buffer[2:])[0]
                rec_data['CDS_T_Field'] = datetime.datetime(1958, 1, 1) + datetime.timedelta(days=days, milliseconds=msecs)
            # store the COFFs and LOFFs into an array
            if rec_type == 130:
                data = rec_data['Image_Compensation_Information'].strip().split('\r')
                ic = np.zeros((len(data)/3), dtype=[('LINE', np.uint16), ('COFF', np.float32), ('LOFF', np.float32)])
                for j in range(0, len(data), 3):
                    linestr = data[j]
                    coffstr = data[j+1]
                    loffstr = data[j+2]
                    _line, lv = linestr.split(':=')
                    _coff, coffv = coffstr.split(':=')
                    _loff, loffv = loffstr.split(':=')
                    ic[j//3] = int(lv), float(coffv), float(loffv)

                rec_data['Image_Compensation_Information'] = ic
            if rec_type == 131:
                data = rec_data['Image_Observation_Time'].strip().split('\r')
                io = np.zeros((len(data)/2), dtype=[('LINE', np.uint16), ('TIME', np.float32)] )
                for j in range(0, len(data), 2):
                    linestr = data[j]
                    timestr = data[j + 1]
                    _line, lv = linestr.split(':=')
                    _time, timev = timestr.split(':=')
                    io[j//2] = int(lv),float(timev)

                rec_data['Image_Observation_Time'] = io

            #store the record data
            self.records[hname] = rec_data
            i += rec_len

    def __iter__(self):
        return iter(self.records.items())
    def __str__(self):

        return str(self.records)

class HRITSegment(object):
    """
        Represents a JMA HRIT Image segment.
        Consists of a header and data
    """
    byte_order = MTSAT_HRIT_BYTE_ORDER
    def __init__(self, fpath=None):
        """

        :param fpath, str, path to the :
        :return:
        """
        self._fpath = fpath
        f = open(self._fpath)
        #establish endiannes by extracting number of lines and cols and comparing with NLINES
        f.seek(20) #jump to byte 20 (size of primary header + Heaer type, record length and NB
        buf = f.read(2)
        #BIG endian
        nl = struct.unpack('%sH' % self.byte_order, buf)[0]

        if nl not in MTSAT_HRIT_IMAGE_NLINES:
            raise ValueError, '%s has wrong byte order. Expected big endian' % self.__class__.__name__
        #set pointer to byte 4, and read byte 5 to find out the total header length
        f.seek(4)
        header_length = struct.unpack('%sI' % self.byte_order, f.read(4))[0]
        #reset pointer
        f.seek(0)

        #1 create header
        self.header = HRITHeader(buffer=f.read(header_length), byte_order=self.byte_order)
        self.NL = self.header.records['Image Structure']['NL']
        self.NC = self.header.records['Image Structure']['NC']
        self.NB = self.header.records['Image Structure']['NB']
        self.SEG_NUM = self.header.records['Image Segment Identification']['Image_Segm_Seq_No']
        self.is_compressed = bool(self.header.records['Image Structure']['Compression_Flag'])

        self.ssp = self.header.records['Image Navigation']['SSP']
        self.CFAC = self.header.records['Image Navigation']['CFAC']
        self.LFAC = self.header.records['Image Navigation']['LFAC']
        self.COFF = self.header.records['Image Navigation']['COFF']
        self.LOFF = self.header.records['Image Navigation']['LOFF']

        self.shape = self.NL, self.NC
        #2 grab data

        self.size = self.NL*self.NC

        self.data = np.zeros(self.shape, dtype=np.uint16)
        block = np.memmap(self._fpath, dtype='%su2' % self.byte_order, mode='r', offset=header_length,shape=self.shape)
        self.data[...] = block.copy()
        del block
        f.close()

class HRITChannel(object):
    """
        Represents a conceptual JMA HRIT File corresponding to a slot (datetime) and a channel (VIS).
        In reality does not exists as a file because JMA HRIT files are segmented.


    """

    def __init__(self, files=None, datetime=None ):
        """
        HRITChannel constructor. Accepts an iterable of strings representing the segment files.
        It is the responsibility of the user to supply the correct number of segment files.

        :param files, iterable of strings containing the full path to the segment file:
        :return: None
        """

        if not files:
            raise ValueError, 'No segment files were provided in argument "files"=%s ' % str(files)
        self._files = sorted(files)
        #extract infor form file name
        self.basename = self._files[0].split('/')[-1][:-4]
        t_ = self.basename.split('_')[1]
        self.scene_type = self.basename[4:8]
        self.channel_name = t_[4:]
        #set attributes from constants
        for _n, _v in MTSAT_HRIT_IMAGE_DATA[self.channel_name][self.scene_type].items():
            setattr(self,_n, _v)
        self.NB = None
        self.resolution = (MTSAT_HRIT_FDIMAGE_NLINES / self.NC) * 1000
        self.segments = []
        self.SSP = None
        self.is_compressed = None
        self.seg_lines = []
        self.seg_nums = []
        self.nsegs = 0
        ICOLINES = []
        COFFS = []
        LOFFS = []
        IOTLINES = []
        TIMES = []
        for f in  self._files:
            try:
                s = HRITSegment(fpath=f)

                seg_header = s.header
                self.CFAC = s.CFAC
                self.LFAC = s.CFAC
                self.COFF = s.COFF
                self.LOFF = s.LOFF
                if self.SSP is None:
                    self.SSP = s.ssp
                else:
                    if self.SSP != s.ssp:
                        raise ValueError, 'Invalid segment %s. SSP is not consistent %s, %s' % (f, self.SSP, s.ssp)
                if self.NB is None:
                    self.NB = s.NB
                else:
                    if self.NB != s.NB:
                        raise ValueError, 'Invalid segment %s. NB is not consistent %s, %s' % (f, self.NB, s.NB)
                self.nsegs += 1
                self.seg_lines.append(s.header.records['Image Segment Identification']['Line_No_Image_Segm'])
                self.seg_nums.append(s.header.records['Image Segment Identification']['Image_Segm_Seq_No'])
                self.segments.append(s)

                # avoid the last element because it is redundant. the next segment start with the next line
                ICOLINES += seg_header.records['Image Compensation Information Header']['Image_Compensation_Information']['LINE'].tolist()
                COFFS += seg_header.records['Image Compensation Information Header']['Image_Compensation_Information']['COFF'].tolist()
                LOFFS += seg_header.records['Image Compensation Information Header']['Image_Compensation_Information']['LOFF'].tolist()
                IOTLINES += seg_header.records['Image Observation Time Header']['Image_Observation_Time']['LINE'].tolist()[:-1]
                TIMES += seg_header.records['Image Observation Time Header']['Image_Observation_Time']['TIME'].tolist()[:-1]
            except Exception as e:
                print e
                pass


        self.proj4_str = '+proj=geos +a=6378169.0 +b=6356583.8 +h=35785831.0 +lon_0=%.2f +units=m' % self.SSP


        self.ICOLINES = np.array(ICOLINES, dtype=np.uint16)
        self.COFFS = np.array(COFFS, dtype=np.float32)
        self.LOFFS = np.array(LOFFS, dtype=np.float32)
        self.TIMES = np.array(TIMES, dtype=np.float32)
        self.IOTLINES = np.array(IOTLINES, dtype=np.uint16)
        self.size = self.NL*self.NC
        self.shape = self.NL, self.NC
                

        self._data = None
        if np.all(self.LOFF == self.LOFFS) and np.all(self.COFF == self.COFFS):
            self.is_shifted = False
            self.correction_level = None
        else:
            self.is_shifted = True
            self.ico_offsets = np.zeros(shape=(self.NL,), dtype=[('COFF',np.float32), ('LOFF', np.float32)])

            for i in range(self.ICOLINES.size-1):
                start, end = self.ICOLINES[i]-1, self.ICOLINES[i+1]-1
                if i == self.ICOLINES.size - 2:
                    end +=1
                j=i+1

                step_l = end-start

                if step_l == 1:
                    ratio = np.array([0])
                else:
                    ratio = np.arange(step_l) / float(step_l - 1)
                self.ico_offsets['COFF'][start:end] = self.COFFS[i] + ratio * (self.COFFS[j] - self.COFFS[i])
                self.ico_offsets['LOFF'][start:end] = self.LOFFS[i] + ratio * (self.LOFFS[j] - self.LOFFS[i])
            self.correction_level = 'header'

        #compose the calibration table
        cdata = self.segments[0].header.records['Image Data Function']['Data_Definition_Block'].strip().split('\r')
        sctable = []
        for e in cdata:
            n, v = e.split(':=')
            if '$' in n:
                pass
            else:
                try:
                    int(n)
                    sctable.append((int(n), v))
                except ValueError:
                    pass

        dt =[('count', np.int32), ('value', np.float32)]
        self.ctable = np.array(sctable, dtype=dt )

        max_ind = sctable[-1][0]


        self.calibration_table = np.zeros(max_ind+1, dtype=dt)
        self.calibration_table['count'][:] = np.arange(max_ind+1)

        #find the designated count index
        dup_mask_index = np.where(self.ctable['value'][1:] == self.ctable['value'][:-1])[0]
        if dup_mask_index.size == 0 or self.ctable.size <3: # we are not able to fetch the designated count point for some reason so no calibration shall be performed
            self.ca_be_calibrated = False
            self.designated_point = None
        else:
            self.can_be_calibrated = True
            self.designated_point = self.ctable[dup_mask_index].item()
            #interpolate the calibration table
            self.calibration_table['value'] = np.interp(np.arange(max_ind+1),self.ctable['count'], self.ctable['value'])
        self.scan_datetime = self.segments[0].header.records['Time Stamp']['CDS_T_Field']
        self.datetime = datetime



    def calibrate(self):
        if self.can_be_calibrated:
            if self.channel_name == 'VIS':
                x0,y0 = self.ctable[0].item()
                x1,y1 = self.ctable[1].item()
                scale = (y1-y0)/(x1-x0)
                offset = (y0-x0) * scale
                return offset + self.data * scale


            else:
                return self.data


        else:
            raise ValueError('Image data can not be calibrated!')

    @property
    def data(self):
        """
            Collects the data chunk from individual segments into one big numpy array
        """
        if self._data is None:
            self._data = np.zeros(self.shape, dtype='u2')
            for s in self.segments:
                seg_start_line = (s.SEG_NUM-1)*s.NL
                seg_end_line = s.SEG_NUM*s.NL
                self._data[seg_start_line:seg_end_line,:] = s.data
        return self._data




    def __str__(self):
        s = '\n'
        s+= 'Image: %s \n' % self.basename
        s+= 'Image Type: %s \n' % self.channel_type
        s+= 'Image name: %s \n' % self.channel_name
        s+= 'Navigation: CFAC: %s, LFAC: %s, COFF: %s, LOFF: %s, SSP: %.2f \n' % (self.CFAC, self.LFAC, self.COFF, self.LOFF, self.SSP)
        s+= 'Image Geometry: Resolution(m): %s, LINES: %s, COLUMNS: %s' % (self.resolution, self.NL, self.NC)
        return s

class ArchivedHRITImage(object):
    """
        An archive that contains segmented Himawari 6-7 HRIT images
    """
    def __init__(self, archive_path=None, extraction_path='/tmp'):
        """
        Initializes and acrchive, extrcats and parses it's content
        :param archive_path:
        :param extraction_path:
        :return:
        """
        self.tar_file = None
        self.basename = None
        self.extracted_folder = None
        self.__channel_files = {}
        self.__loaded_channels = {}
        if archive_path is not None and isinstance(archive_path,basestring):
            if os.path.exists(archive_path):
                _, _ext = os.path.splitext(archive_path)
                if _ext:
                    _mode = 'r|%s' % _ext[1:]
                    if tarfile.is_tarfile(archive_path):
                        self.__extract__(archive_path=archive_path, mode=_mode, extraction_path=extraction_path)

            else:
                raise tarfile.ReadError('The archive %s does not exist' % archive_path)
        else:
            raise tarfile.ReadError('Invalid "archive_path" argument!')


    def __extract__(self, archive_path=None, mode=None, extraction_path=None):
        """
        Extracts
        :param path:
        :param mode:
        :return:
        """
        tar_file = tarfile.open(name=archive_path, mode=mode)
        if tar_file is None:
            raise AttributeError('%s was not properly initialised' % self)
        if not tar_file.members:
            tar_file.close()
            self.basename = tar_file.name
            del tar_file

            return
        #check write perms
        try:
            _f = os.path.join(extraction_path,'f.txt')
            open(_f, 'w')
            os.remove(_f)
        except Exception as e:
            raise e

        try:
            self.basename = tar_file.members[0].name
            self.datetime = datetime.datetime.strptime(self.basename.split('_')[-1], '%Y%m%d%H%M')
        except ValueError:
            self.basename = tar_file.members[0].name.split('/')[0]
            self.datetime = datetime.datetime.strptime(self.basename.split('_')[-1], '%Y%m%d%H%M')
            
        tar_file.extractall(path=extraction_path)
        self.extracted_folder = os.path.join(extraction_path,self.basename)
        tar_file.close()
        del tar_file
        for n in os.listdir(self.extracted_folder):
            abs_hrit_seg_path = os.path.join(self.extracted_folder,n)
            if len(n) != 28:
                print RuntimeWarning('skipping HRIT segment %s' % abs_hrit_seg_path)
                continue
            _channel = n[8:11]
            if self.__channel_files.has_key(_channel):
                self.__channel_files[_channel].append(abs_hrit_seg_path)
            else:
                self.__channel_files[_channel] = []
                self.__channel_files[_channel].append(abs_hrit_seg_path)


    def __getitem__(self, key):
        if not self.channels:
            raise Exception('HRIT archive %s appears to be empty!' % self.basename)
        if key not in self.channels:
            raise ValueError('HRIT channel "%s" does not exist. Available channels are %s' % (str(key), self.channels))

        if not key in self.__loaded_channels.keys():
            _channel_files = self.__channel_files[key]
            requested_channel = HRITChannel(files=_channel_files, datetime=self.datetime)
            self.__loaded_channels[key] = requested_channel
        return self.__loaded_channels[key]


    def    __delitem__(self, key):
        del self.__loaded_channels[key]

    def __setitem__(self, key, value):
        pass

    def __del__(self):
        #clean channels
        if hasattr(self, '__loaded_channels'):
            for cn, c in self.__loaded_channels.items():
                #print 'deleting channel %s' % cn
                del c
        if self.extracted_folder and os.path.exists(self.extracted_folder):
            shutil.rmtree(self.extracted_folder)


    @property
    def channels(self):
        return sorted(self.__channel_files.keys())

class H08_ArchivedHRITImage(ArchivedHRITImage):
    """
        Reader for H08 HRIT from Eumetsat
    """
    def __init__(self, archive_files=None, extraction_path=None):
        """
        Initializes and acrchive, extrcats and parses it's content
        :param archive_path:
        :param extraction_path:
        :return:
        """
        import zipfile
        assert len(archive_files) == 10, '"archive_files" argument needs to contain 10 Himawari bz2 files. '
        self.tar_file = []
        self.basename = None
        self.extracted_folder = None
        self.__channel_files = {}
        self.__loaded_channels = {}
        
        for archive_path in archive_files:
            z_file = bz2.BZ2File(archive_path)  # open the file
            data=z_file.read()                  # get the decompressed data
            newfilepath=archive_path[:-4]       # assuming the filepath ends with .bz2
            open(newfilepath,'wb').write(data)  # write a uncompressed file
            
            self.tar_file.append(newfilepath)
        
        archive=extraction_path+newfilepath[:-4].split('/')[-1]+'.tar.bz2'
        
        tar = tarfile.open(archive, "w:bz2")
        for name in self.tar_file:
            tar.add(name, recursive=True)
        tar.close()
      
        
        if archive is not None and isinstance(archive,basestring):
            if os.path.exists(archive):
                _, _ext = os.path.splitext(archive)
                if _ext:
                    _mode = 'r|%s' % _ext[1:]
                    self.__extract__(archive_path=archive, mode=_mode, extraction_path=ep)                   
 
            else:
                raise tarfile.ReadError('The archive %s does not exist' % archive)
        else:
            raise tarfile.ReadError('Invalid "archive_path" argument!')
        
         
    def __extract__(self, archive_path=None, mode=None, extraction_path=None):
        """
        Extracts
        :param path:
        :param mode:
        :return:
        """
        tar_file = tarfile.open(name=archive_path, mode=mode)
        if tar_file is None:
            raise AttributeError('%s was not properly initialised' % self)
        if not tar_file.members:
            tar_file.close()
            self.basename = tar_file.name
            del tar_file

            return
        #check write perms
        try:
            _f = os.path.join(extraction_path,'f.txt')
            open(_f, 'w')
            os.remove(_f)
        except Exception as e:
            raise e

        try:
            self.basename = tar_file.members[0].name
            self.datetime = datetime.datetime.strptime(self.basename.split('_')[-1], '%Y%m%d%H%M')
        except ValueError:
            self.basename = tar_file.members[0].name.split('/')[-1]
            self.datetime = datetime.datetime.strptime(self.basename.split('_')[-2], '%Y%m%d%H%M')
            
        tar_file.extractall(path=extraction_path)
        self.extracted_folder = os.path.join(extraction_path,self.basename[:-4])
        tar_file.close()
        del tar_file
        for n in os.listdir(self.extracted_folder):
            abs_hrit_seg_path = os.path.join(self.extracted_folder,n)
            if len(n) != 28:
                print RuntimeWarning('skipping HRIT segment %s' % abs_hrit_seg_path)
                continue
            _channel = n[8:11]
            if self.__channel_files.has_key(_channel):
                self.__channel_files[_channel].append(abs_hrit_seg_path)
            else:
                self.__channel_files[_channel] = []
                self.__channel_files[_channel].append(abs_hrit_seg_path)

    def __getitem__(self, key):
        if not self.channels:
            raise Exception('HRIT archive %s appears to be empty!' % self.basename)
        if key not in self.channels:
            raise ValueError('HRIT channel "%s" does not exist. Available channels are %s' % (str(key), self.channels))

        if not key in self.__loaded_channels.keys():
            _channel_files = self.__channel_files[key]
            requested_channel = HRITChannel(files=_channel_files, datetime=self.datetime)
            self.__loaded_channels[key] = requested_channel
        return self.__loaded_channels[key]


    def    __delitem__(self, key):
        del self.__loaded_channels[key]

    def __setitem__(self, key, value):
        pass

    def __del__(self):
        #clean channels
        if hasattr(self, '__loaded_channels'):
            for cn, c in self.__loaded_channels.items():
                #print 'deleting channel %s' % cn
                del c
        if self.extracted_folder and os.path.exists(self.extracted_folder):
            shutil.rmtree(self.extracted_folder)


    @property
    def channels(self):
        return sorted(self.__channel_files.keys())
def h08_hrit_info(folder=None):
    from general_utils.daytimeconv import date2dfb
    from mtsat.Himawari8.slotmapping import hm2slot
    
    FILENAMECOL='FILENAME'
    CHANNEL ='CHANNEL'
    DFBCOL='DFB'
    SLOTCOL='SLOT'
    SIZECOL='SIZE'
    
    NC_FILENAME_LENGTH = 32
    
    
    _DTYPE =  [(FILENAMECOL, 'S%s' % NC_FILENAME_LENGTH), (CHANNEL, 'S3'), (DFBCOL, 'i4'), (SLOTCOL, 'i4'), (SIZECOL, 'i8')]

    fldr = os.path.abspath(folder)
    gen = [(e, e[8:11], date2dfb(datetime.datetime.strptime(e[12:20], '%Y%m%d').date()),  hm2slot(h=int(e[20:22]), m=int(e[22]+'0')), os.path.getsize(os.path.join(fldr, e))) for e in os.listdir(fldr) if e.endswith('.bz2')]
    
    h08_files = np.fromiter(gen, dtype=_DTYPE)
    h08_files.sort(order=[CHANNEL,DFBCOL, SLOTCOL])
    return h08_files
    
if __name__ == '__main__':
    import filecmp
    import glob, sys
    from mtsat.hrit.navigation import ll2lc,YX2ll,offset_lc
    from pylab import plt, show
    from mpl_toolkits.basemap import Basemap
    from mtsat.hrit.navigation import lc2YX

    fp = '/home/simon/Himawari-8/Eumetcast/try/'
    ep = '/home/simon/Himawari-8/Eumetcast/hrits/'
    h08_hrit_files = h08_hrit_info(fp)
    pfiles = h08_hrit_files[h08_hrit_files['CHANNEL'] == 'VIS']['FILENAME']
    p = [os.path.join(fp,e) for e in pfiles]
    h08_himage = H08_ArchivedHRITImage(archive_files=p, extraction_path=ep)
    vis_channel = h08_himage['VIS']
    from pylab import show, imshow
    imshow(vis_channel.data)
    show()
    
    
            
    sys.exit()
    
    hrit_archive = ArchivedHRITImage(archive_path=fp1)
    vis_channel = hrit_archive['IR1']
    print vis_channel.resolution
    data = vis_channel.data
    calibrated = vis_channel.calibrate()
    res = 2000
    y,x = ctrans.lc2YX(l=0, c=0, loff=vis_channel.LOFF, coff=vis_channel.COFF, resolution=2000)
    print y,x
    gt = (x, res, 0, y, 0, -res)
    proj4_str = '+proj=geos +a=6378169.0 +b=6356583.8 +h=35785831.0 +lon_0={} +units=m'.format(vis_channel.SSP)
    toGDAL(fpath='/home/simon/mtsat_project/tiff/DK01IR1_201511172330_{}.tiff'.format('raw'), array=data, gt=gt,proj=proj4_str)
    toGDAL(fpath='/home/simon/mtsat_project/tiff/DK01IR1_201511172330_{}.tiff'.format('calibrated'), array=calibrated, gt=gt,proj=proj4_str)
  

