#! /usr/bin/env python
'''
Created on Aug 24, 2009
Updated in Oct 16, 2009

@author: tomas
disaggregation of lowres GHI and DNI to highres inclined surface
inputs: DNI, GHI monthly time slot percentiles
    horizons (5x5 degree tiles)
output:
    highres 5x5 deg. GI and DNI output on inclined or 2-axis tracker (considering high resolution shadowing)    
'''

from string import zfill
import os, sys
import math
import datetime
import numpy
import netCDF4

from general_utils import latlon_nctools
from general_utils import latlon
from general_utils import mounting_geom
from general_utils import shading_utils
from general_utils import daytimeconv
from general_utils import basic_mail
import general_utils.solar_geom_v5 as solar_geom
#import msg_geom
#from mfg.mfg_functions import mfg_geom

#logger section
from general_utils import basic_logger
logger = basic_logger.basic_logger_make(basic_logger.get_run_module_name()+'.main', 'info')




def make_model_output_disaggreg_ms_latlon(file_name, latlon_bbox, overwrite = False, slot_min=10, slot_max=80, logger=None, version=None):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return False
    
    #[month,slot,row,col] - long term monthly stats of 15 min value mean
    description='solargis sun irradiance model output  monthly statistics by 15 min dissagregated by terrain'
    metadata=[['description',description],['projection',"geographic coordinates"]]
    if version is not None:
        metadata.append(['version', version])
        
    img_channels=['mean']
    img_types=["NC_SHORT"]
    img_units=['W']
    img_long_names=['15min longterm mean by month']
    chunksizes=[[1,1,128,128]]
    novals=[-9.]
    result=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=latlon_bbox, compression=True, chunksizes=chunksizes)
    
    logger.info('Create dissagreg output grid NetCDF: '+str(result))
    
    if result==False:
        logger.error('Failed to create dissagreg output grid NetCDF')
        return False
        
    return True

def make_model_output_disaggreg_m_latlon(file_name, latlon_bbox, overwrite = False, logger=None, version=None):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return False
    
    #[month,row,col] - long term monthly stats of 15 min value mean
    description='solargis sun irradiance model output  monthly statistics by 15 min dissagregated by terrain'
    metadata=[['description',description],['projection',"geographic coordinates"]]
    if version is not None:
        metadata.append(['version', version])

    img_channels=['mean']
    img_types=["NC_SHORT"]
    img_units=['W']
    img_long_names=['daily sum of irradiation longterm mean by month']
    chunksizes=[[1,128,128]]
    novals=[-9.]
    result=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=latlon_bbox, compression=True, chunksizes=chunksizes)
    
    logger.info('Create dissagreg output grid NetCDF: '+str(result))
    
    if result==False:
        logger.error('Failed to create dissagreg output grid NetCDF')
        return False
        
    return True

def make_model_output_disaggreg_shdloss_m_latlon(file_name, latlon_bbox, overwrite = False, logger=None, version=None):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return False
    
    #[month,row,col] - long term monthly stats of 15 min value mean
    description='shadowing loss'
    metadata=[['description',description],['projection',"geographic coordinates"]]
    if version is not None:
        metadata.append(['version', version])

    img_channels=['shdloss']
    img_types=["NC_FLOAT"]
    img_units=['%']
    img_long_names=['loss by shadowing of daily sum of irradiation longterm mean by month']
    chunksizes=[[1,128,128]]
    novals=[-9.]
    result=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=latlon_bbox, compression=True, chunksizes=chunksizes)
    
    logger.info('Create shadowing loss grid NetCDF: '+str(result))
    
    if result==False:
        logger.error('Failed to create shadowing loss grid NetCDF')
        return False
        
    return True

#write merged msg model output data (4D data version)
def write_proj_model_output_disaggreg_4dim(NC_out_filename, in_variab_name, dim0_minmax, dim1_minmax, dim2_minmax, dim3_minmax, data, logger):
    if not(hasattr(dim0_minmax, '__iter__')) or len(dim0_minmax) != 2 :
        logger.error('Variable %s dimension 0 range error' % (in_variab_name))
        return False

    dim0_min, dim0_max = dim0_minmax
    if (dim0_min > dim0_max):
        logger.error('Variable %s dimension 0 range error' % (in_variab_name))
        return False

    if not(hasattr(dim1_minmax, '__iter__')) or len(dim1_minmax) != 2 :
        logger.error('Variable %s dimension 1 range error' % (in_variab_name))
        return False

    dim1_min, dim1_max = dim1_minmax
    if (dim1_min > dim1_max):
        logger.error('Variable %s dimension 1 range error' % (in_variab_name))
        return False
    
    if not(hasattr(dim2_minmax, '__iter__')) or len(dim2_minmax) != 2 :
        logger.error('Variable %s dimension 2 range error' % (in_variab_name))
        return False

    dim2_min, dim2_max = dim2_minmax
    if (dim2_min > dim2_max):
        logger.error('Variable %s dimension 2 range error' % (in_variab_name))
        return False

    if not(hasattr(dim3_minmax, '__iter__')) or len(dim3_minmax) != 2 :
        logger.error('Variable %s dimension 3 range error' % (in_variab_name))
        return False

    dim3_min, dim3_max = dim3_minmax
    if (dim3_min > dim3_max):
        logger.error('Variable %s dimension 3 range error' % (in_variab_name))
        return False

    rootgrp = netCDF4.Dataset(NC_out_filename, 'r+')
    varDict=rootgrp.variables
    
    
    if not(in_variab_name in varDict.keys()):
        logger.error('Variable %s not found in NetCDF %s ' % (in_variab_name, NC_out_filename))
        rootgrp.close()
        return False
    

    in_var=varDict[in_variab_name]
    in_var.set_auto_maskandscale(False)

    if (in_var.ndim != 4):
        logger.error('Variable %s has more than %d dimensions' % (in_variab_name, 4))
        rootgrp.close()
        return False
    
    dim0_name = in_var.dimensions[0]
    nc_dim0_min, nc_dim0_max = varDict[dim0_name].valid_range
    if (dim0_min < nc_dim0_min) or (dim0_max > nc_dim0_max):
        logger.error('Requested variable %s dimension 0 range out of NetCDF range' % (in_variab_name))
        rootgrp.close()
        return False
    
    dim0_min_idx=dim0_min-nc_dim0_min
    dim0_max_idx=dim0_max-nc_dim0_min
    
    dim1_name = in_var.dimensions[1]
    nc_dim1_min, nc_dim1_max = varDict[dim1_name].valid_range
    if (dim1_min < nc_dim1_min) or (dim1_max > nc_dim1_max):
        logger.error('Requested variable %s dimension 0 range out of NetCDF range' % (in_variab_name))
        rootgrp.close()
        return False
    
    dim1_min_idx=dim1_min-nc_dim1_min
    dim1_max_idx=dim1_max-nc_dim1_min

#    nc_xmin, nc_xmax = varDict['col'].valid_range
#    nc_ymin, nc_ymax = varDict['row'].valid_range
    
    ymin_idx = dim2_min
    ymax_idx = dim2_max

    xmin_idx = dim3_min
    xmax_idx = dim3_max
    
    #finally write the data
    in_var[dim0_min_idx:dim0_max_idx+1,dim1_min_idx:dim1_max_idx+1, ymin_idx:ymax_idx+1,xmin_idx:xmax_idx+1] = numpy.around(data, decimals=0)
    rootgrp.close()

    return True


#write merged msg model output data (4D data version)
def write_proj_model_output_disaggreg_3dim(NC_out_filename, in_variab_name, dim0_minmax, dim2_minmax, dim3_minmax, data, logger):
    if not(hasattr(dim0_minmax, '__iter__')) or len(dim0_minmax) != 2 :
        logger.error('Variable %s dimension 0 range error' % (in_variab_name))
        return False

    dim0_min, dim0_max = dim0_minmax
    if (dim0_min > dim0_max):
        logger.error('Variable %s dimension 0 range error' % (in_variab_name))
        return False
    
    if not(hasattr(dim2_minmax, '__iter__')) or len(dim2_minmax) != 2 :
        logger.error('Variable %s dimension 2 range error' % (in_variab_name))
        return False

    dim2_min, dim2_max = dim2_minmax
    if (dim2_min > dim2_max):
        logger.error('Variable %s dimension 2 range error' % (in_variab_name))
        return False

    if not(hasattr(dim3_minmax, '__iter__')) or len(dim3_minmax) != 2 :
        logger.error('Variable %s dimension 3 range error' % (in_variab_name))
        return False

    dim3_min, dim3_max = dim3_minmax
    if (dim3_min > dim3_max):
        logger.error('Variable %s dimension 3 range error' % (in_variab_name))
        return False

    rootgrp = netCDF4.Dataset(NC_out_filename, 'r+')
    varDict=rootgrp.variables
    
    
    if not(in_variab_name in varDict.keys()):
        logger.error('Variable %s not found in NetCDF %s ' % (in_variab_name, NC_out_filename))
        rootgrp.close()
        return False
    
    in_var=varDict[in_variab_name]
    in_var.set_auto_maskandscale(False)

    if (in_var.ndim != 3):
        logger.error('Variable %s has more than %d dimensions' % (in_variab_name, 3))
        rootgrp.close()
        return False
    
    dim0_name = in_var.dimensions[0]
    nc_dim0_min, nc_dim0_max = varDict[dim0_name].valid_range
    if (dim0_min < nc_dim0_min) or (dim0_max > nc_dim0_max):
        logger.error('Requested variable %s dimension 0 range out of NetCDF range' % (in_variab_name))
        rootgrp.close()
        return False
    
    dim0_min_idx=dim0_min-nc_dim0_min
    dim0_max_idx=dim0_max-nc_dim0_min
    
    
    ymin_idx = dim2_min
    ymax_idx = dim2_max

    xmin_idx = dim3_min
    xmax_idx = dim3_max
    
    #finally write the data
    in_var[dim0_min_idx:dim0_max_idx+1, ymin_idx:ymax_idx+1,xmin_idx:xmax_idx+1] = numpy.around(data, decimals=0)
    rootgrp.close()

    return True


def read_lowres_2d_data_for_highres_bbox(file_name, var_names, out_latlon_bbox, logger):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return None

    if not(os.access(file_name, os.F_OK)):
        logger.warning("Input data NetCDF file %s not found",file_name)
        return None

    try:
        rootgrp=netCDF4.Dataset(file_name, 'r')
    except:
        logger.error('Failed to open input data NetCDF %s', file_name)
        return None
    
    dimDict = rootgrp.dimensions
    varDict = rootgrp.variables

    dkeys=dimDict.keys()
    if not(('row'in dkeys) and ('col' in dkeys)) and not(('lon'in dkeys) and ('lat' in dkeys))and not(('longitude'in dkeys) and ('latitude' in dkeys)):
        logger.error('Dimensions row, col or lat, lon not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None

    if ('row'in dkeys) and ('col' in dkeys):
        nc_height = len(dimDict['row'])
        nc_width = len(dimDict['col'])
        nc_w, nc_e = varDict['col'].valid_range
        nc_s, nc_n = varDict['row'].valid_range
    elif('latitude'in dkeys) and ('longitude' in dkeys):
        nc_height = len(dimDict['latitude'])
        nc_width = len(dimDict['longitude'])
        nc_w, nc_e = varDict['longitude'].valid_range
        nc_s, nc_n = varDict['latitude'].valid_range
    else:
        nc_height = len(dimDict['lat'])
        nc_width = len(dimDict['lon'])
        nc_w, nc_e = varDict['lon'].valid_range
        nc_s, nc_n = varDict['lat'].valid_range


    #create bbox with avial lowres data based on the size of highres bbox
    nc_latlon_bbox = latlon.bounding_box(nc_w, nc_e, nc_s, nc_n, nc_width, nc_height, (nc_e-nc_w)/nc_width) #nc bbox
    nc_latlon_bbox_clipped = nc_latlon_bbox.intersect(out_latlon_bbox) #bbox intersect with high res bbox
    nc_latlon_bbox_buffered = nc_latlon_bbox_clipped.buffer_px(px=1) #buffer by one px
    nc_latlon_bbox_clipped = nc_latlon_bbox_buffered.intersect(nc_latlon_bbox) #clip by nc_bbox - to be sure we are not outside after buffer
    
    px_xmin, px_xmax, px_ymin, px_ymax = nc_latlon_bbox.pixel_coords_of_bbox(nc_latlon_bbox_clipped)
#    print px_xmin, px_xmax, px_ymin, px_ymax
    
    #now finally read the data
    if not(var_name in varDict.keys()):
        logger.error('Variable %s in input data NetCDF %s', file_name)
        rootgrp.close()
        return None
    
    try:
        data=varDict[var_name][px_ymin:px_ymax+1, px_xmin:px_xmax+1]
    except:
        logger.error('Problem reading input data from NetCDF %s', file_name)
        rootgrp.close()
        return None
    rootgrp.close()
        
    return data, nc_latlon_bbox_clipped


def read_lowres_data_for_highres_bbox(file_name, var_names, out_latlon_bbox, slot_min, slot_max, logger):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return None

    if not(os.access(file_name, os.F_OK)):
        logger.warning("Input data NetCDF file %s not found",file_name)
        return None

    try:
        rootgrp=netCDF4.Dataset(file_name, 'r')
    except:
        logger.error('Failed to open input data NetCDF %s', file_name)
        return None
    
    dimDict = rootgrp.dimensions
    varDict = rootgrp.variables

    dkeys=dimDict.keys()
    if not(('row'in dkeys) and ('col' in dkeys)) and not(('lon'in dkeys) and ('lat' in dkeys)) and not(('longitude'in dkeys) and ('latitude' in dkeys)):
        logger.error('Dimensions row, col or lat, lon or latitude, longitude not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None

    if ('row'in dkeys) and ('col' in dkeys):
        nc_height = len(dimDict['row'])
        nc_width = len(dimDict['col'])
        nc_w, nc_e = varDict['col'].valid_range
        nc_s, nc_n = varDict['row'].valid_range
    elif('lon'in dkeys) and ('lat' in dkeys):
        nc_height = len(dimDict['lat'])
        nc_width = len(dimDict['lon'])
        nc_w, nc_e = varDict['lon'].valid_range
        nc_s, nc_n = varDict['lat'].valid_range
    else:
        nc_height = len(dimDict['latitude'])
        nc_width = len(dimDict['longitude'])
        nc_w, nc_e = varDict['longitude'].valid_range
        nc_s, nc_n = varDict['latitude'].valid_range

    if not(('slot'in dkeys) ):
        logger.error('Dimensions slot not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None
    nc_slot_min, nc_slot_max = varDict['slot'].valid_range
    
    if (slot_min < nc_slot_min) or (slot_max > nc_slot_max):
        logger.error('Requested slot range out of NetCDF slots range')
        rootgrp.close()
        return None

    #create bbox with avial lowres data based on the size of highres bbox
    nc_latlon_bbox = latlon.bounding_box(nc_w, nc_e, nc_s, nc_n, nc_width, nc_height, (nc_e-nc_w)/nc_width) #nc bbox
    nc_latlon_bbox_clipped = nc_latlon_bbox.intersect(out_latlon_bbox) #bbox intersect with high res bbox
    nc_latlon_bbox_buffered = nc_latlon_bbox_clipped.buffer_px(px=1) #buffer by one px
    nc_latlon_bbox_clipped = nc_latlon_bbox_buffered.intersect(nc_latlon_bbox) #clip by nc_bbox - to be sure we are not outside after buffer
    
    px_xmin, px_xmax, px_ymin, px_ymax = nc_latlon_bbox.pixel_coords_of_bbox(nc_latlon_bbox_clipped)
#    print px_xmin, px_xmax, px_ymin, px_ymax
    
    #now finally read the data
    if not(var_name in varDict.keys()):
        logger.error('Variable %s in input data NetCDF %s', file_name)
        rootgrp.close()
        return None
    
    try:
        data=varDict[var_name][:,slot_min-nc_slot_min:slot_max-nc_slot_min+1, px_ymin:px_ymax+1, px_xmin:px_xmax+1]
    except:
        logger.error('Problem reading input data from NetCDF %s', file_name)
        rootgrp.close()
        return None
    rootgrp.close()
        
    return data, nc_latlon_bbox_clipped



def read_lowres_data_year_for_highres_bbox(file_name, var_name, out_latlon_bbox, year, logger):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return None

    if not(os.access(file_name, os.F_OK)):
        logger.warning("Input data NetCDF file %s not found",file_name)
        return None

    try:
        rootgrp=netCDF4.Dataset(file_name, 'r')
    except:
        logger.error('Failed to open input data NetCDF %s', file_name)
        return None
    
    dimDict = rootgrp.dimensions
    varDict = rootgrp.variables

    dkeys=dimDict.keys()
    if not(('row'in dkeys) and ('col' in dkeys)) and not(('lon'in dkeys) and ('lat' in dkeys)) and not(('longitude'in dkeys) and ('latitude' in dkeys)):
        logger.error('Dimensions row, col or lat, lon or latitude, longitude not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None

    if ('row'in dkeys) and ('col' in dkeys):
        nc_height = len(dimDict['row'])
        nc_width = len(dimDict['col'])
        nc_w, nc_e = varDict['col'].valid_range
        nc_s, nc_n = varDict['row'].valid_range
    elif('lon'in dkeys) and ('lat' in dkeys):
        nc_height = len(dimDict['lat'])
        nc_width = len(dimDict['lon'])
        nc_w, nc_e = varDict['lon'].valid_range
        nc_s, nc_n = varDict['lat'].valid_range
    else:
        nc_height = len(dimDict['latitude'])
        nc_width = len(dimDict['longitude'])
        nc_w, nc_e = varDict['longitude'].valid_range
        nc_s, nc_n = varDict['latitude'].valid_range

    if not(('year'in dkeys) ):
        logger.error('Dimensions year not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None
    nc_year_min, nc_year_max = varDict['year'].valid_range
    
    if (year < nc_year_min) or (year > nc_year_max):
        logger.error('Requested year %d out of NetCDF %s year range' % (year, file_name))
        rootgrp.close()
        return None

    #create bbox with avial lowres data based on the size of highres bbox
    nc_latlon_bbox = latlon.bounding_box(nc_w, nc_e, nc_s, nc_n, nc_width, nc_height, (nc_e-nc_w)/nc_width) #nc bbox
    nc_latlon_bbox_clipped = nc_latlon_bbox.intersect(out_latlon_bbox) #bbox intersect with high res bbox
    nc_latlon_bbox_buffered = nc_latlon_bbox_clipped.buffer_px(px=1) #buffer by one px
    nc_latlon_bbox_clipped = nc_latlon_bbox_buffered.intersect(nc_latlon_bbox) #clip by nc_bbox - to be sure we are not outside after buffer
    
    px_xmin, px_xmax, px_ymin, px_ymax = nc_latlon_bbox.pixel_coords_of_bbox(nc_latlon_bbox_clipped)
#    print px_xmin, px_xmax, px_ymin, px_ymax
    
    #now finally read the data
    if not(var_name in varDict.keys()):
        logger.error('Variable %s in input data NetCDF %s', file_name)
        rootgrp.close()
        return None
    
    try:
        data=varDict[var_name][year-nc_year_min, :, px_ymin:px_ymax+1, px_xmin:px_xmax+1]
    except:
        logger.error('Problem reading input data from NetCDF %s', file_name)
        rootgrp.close()
        return None
    rootgrp.close()
        
    return data, nc_latlon_bbox_clipped



def read_lowres_multi_data_for_highres_bbox(file_name, var_names, out_latlon_bbox, slot_min, slot_max, logger):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return None

    if not(os.access(file_name, os.F_OK)):
        logger.warning("Input data NetCDF file %s not found",file_name)
        return None

    try:
        rootgrp=netCDF4.Dataset(file_name, 'r')
    except:
        logger.error('Failed to open input data NetCDF %s', file_name)
        return None
    
    dimDict = rootgrp.dimensions
    varDict = rootgrp.variables

    dkeys=dimDict.keys()
    if not(('row'in dkeys) and ('col' in dkeys)) and not(('lon'in dkeys) and ('lat' in dkeys)) and not(('longitude'in dkeys) and ('latitude' in dkeys)):
        logger.error('Dimensions row, col or lat, lon or latitude, longitude not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None

    if ('row'in dkeys) and ('col' in dkeys):
        nc_height = len(dimDict['row'])
        nc_width = len(dimDict['col'])
        nc_w, nc_e = varDict['col'].valid_range
        nc_s, nc_n = varDict['row'].valid_range
    elif('lon'in dkeys) and ('lat' in dkeys):
        nc_height = len(dimDict['lat'])
        nc_width = len(dimDict['lon'])
        nc_w, nc_e = varDict['lon'].valid_range
        nc_s, nc_n = varDict['lat'].valid_range
    else:
        nc_height = len(dimDict['latitude'])
        nc_width = len(dimDict['longitude'])
        nc_w, nc_e = varDict['longitude'].valid_range
        nc_s, nc_n = varDict['latitude'].valid_range

    if not(('slot'in dkeys) ):
        logger.error('Dimensions slot not found in input data NetCDF %s', file_name)
        rootgrp.close()
        return None
    nc_slot_min, nc_slot_max = varDict['slot'].valid_range
    
    if (slot_min < nc_slot_min) or (slot_max > nc_slot_max):
        logger.error('Requested slot range out of NetCDF slots range')
        rootgrp.close()
        return None

    #create bbox with avial lowres data based on the size of highres bbox
    nc_latlon_bbox = latlon.bounding_box(nc_w, nc_e, nc_s, nc_n, nc_width, nc_height, (nc_e-nc_w)/nc_width) #nc bbox
    nc_latlon_bbox_clipped = nc_latlon_bbox.intersect(out_latlon_bbox) #bbox intersect with high res bbox
    nc_latlon_bbox_buffered = nc_latlon_bbox_clipped.buffer_px(px=1) #buffer by one px
    nc_latlon_bbox_clipped = nc_latlon_bbox_buffered.intersect(nc_latlon_bbox) #clip by nc_bbox - to be sure we are not outside after buffer
    
    px_xmin, px_xmax, px_ymin, px_ymax = nc_latlon_bbox.pixel_coords_of_bbox(nc_latlon_bbox_clipped)
#    print px_xmin, px_xmax, px_ymin, px_ymax
    
    #now finally read the data
    for var_name in var_names:
        if not(var_name in varDict.keys()):
            logger.error('Variable %s not found in input data NetCDF %s', var_name, file_name)
            rootgrp.close()
            return None

    data=numpy.empty((len(var_names), 12, slot_max-slot_min+1, px_ymax-px_ymin+1, px_xmax-px_xmin+1), dtype=numpy.int16)
    
    for var_name in var_names:
        var_idx = var_names.index(var_name)
        try:
            data[var_idx,:,:,:,:]=varDict[var_name][:,slot_min-nc_slot_min:slot_max-nc_slot_min+1, px_ymin:px_ymax+1, px_xmin:px_xmax+1]
        except:
            logger.error('Problem reading input data from NetCDF %s', file_name)
            rootgrp.close()
            return None
    rootgrp.close()
        
    return data, nc_latlon_bbox_clipped


def read_horizon_nc_file(filename,x_min,x_max,y_min,y_max,var_name,logger):
    if (filename is None) or (filename==''):
        logger.error( "No NC filename set")
        return None
    
    if not(os.access(filename, os.F_OK)):
        logger.warning("Input data NetCDF file %s not found",filename)
        return None

    rootgrp = netCDF4.Dataset(filename, 'r')
    ncvariabs=rootgrp.variables
    if len(ncvariabs)<1:
        logger.error("no variables found in NetCDF file: %s",filename)
        rootgrp.close()
        return None
    ncvarimg=ncvariabs[var_name]
    ncvarimg.set_auto_maskandscale(False)
    offset=ncvarimg.add_offset
    scale=ncvarimg.scale_factor
    
    img = ncvarimg[:,y_min:y_max+1,x_min:x_max+1]
    rootgrp.close()
    img=offset+scale*img
    return img



def horizons_interpolate_for_dif_isotropic(HeightHor_in, AspectHor_out, ss_box):
    #nearest neighbour interpolator
    
    #calculate aspects of horizon read from file, add one at the end to have full coverage from -pi to pi for stable interpolation    
    HorStep = 2.0*numpy.pi/HeightHor_in.shape[0]
    AspectHor_in = numpy.arange(-numpy.pi,numpy.pi+.01,HorStep)
    HeightHor_in2 = numpy.empty((HeightHor_in.shape[0]+1,HeightHor_in.shape[1],HeightHor_in.shape[2]), dtype=HeightHor_in.dtype)
    HeightHor_in2[0:-1,:,:] =  HeightHor_in
    HeightHor_in2[-1,:,:] =  HeightHor_in[0,:,:]


    #for each aspect in AspectHor_out find index of closest aspect in  AspectHor_in
    azim_inout_indexes = numpy.empty(AspectHor_out.shape,dtype=numpy.int16)
    for out_idx in range(0,AspectHor_out.shape[0]):
        asp_out = AspectHor_out[out_idx]
        diff = numpy.absolute(asp_out - AspectHor_in)
        min_diff = diff.min()
        in_idx = numpy.nonzero(diff==min_diff)[0][0]
        azim_inout_indexes[out_idx] = in_idx
        
    
    HeightHor_out = HeightHor_in2[azim_inout_indexes,:,:]
    
    return HeightHor_out
    


def horizons_interpolate_for_a0(horizons, a0_dissag, ss_box, slot_min, slot_max):
    #calculate horizons for given azimuth
    num_direct=horizons.shape[0]
    a0_idx_dist = (1. + a0_dissag/math.pi) * num_direct /2.
    a0_idx1 = numpy.floor(a0_idx_dist).astype(numpy.int16)
    a0_idx2 = numpy.ceil(a0_idx_dist).astype(numpy.int16)
    a0_idx_dist = a0_idx_dist-a0_idx1

    a0_idx1[a0_idx1<0]=num_direct-1
    a0_idx1[a0_idx1>num_direct-1]= 0
    a0_idx2[a0_idx2<0]=num_direct-1
    a0_idx2[a0_idx2>num_direct-1]= 0
    
#    row_indx_grid=numpy.repeat(numpy.arange(ss_box.width),ss_box.height)
#    col_indx_grid=numpy.tile(numpy.arange(ss_box.height),ss_box.width)
    row_indx_grid=numpy.repeat(numpy.arange(ss_box.height),ss_box.width)
    col_indx_grid=numpy.tile(numpy.arange(ss_box.width),ss_box.height)

    horizons_inter=numpy.zeros_like(a0_dissag)
    for month_idx in range(0, 12):
        for slot_idx in range(0, slot_max-slot_min +1):
            hor1=horizons[a0_idx1[month_idx, slot_idx, :, :].flatten(),row_indx_grid,col_indx_grid]
            hor2=horizons[a0_idx2[month_idx, slot_idx, :, :].flatten(),row_indx_grid,col_indx_grid]
            horwght=horizons[a0_idx2[month_idx, slot_idx, :, :].flatten(),row_indx_grid,col_indx_grid]
            horizons_inter[month_idx, slot_idx, :, :]=(hor1 + (hor2-hor1)*horwght).reshape(ss_box.height,ss_box.width)

    del(a0_idx_dist,a0_idx1,a0_idx2,row_indx_grid,col_indx_grid,hor1,hor2,horwght)
    return horizons_inter


def make_lat_lon_grids(abbox):
    lons=abbox.longitudes()
    lats=abbox.latitudes()
    lon_grid = numpy.zeros((abbox.height,abbox.width),dtype=numpy.float32)
    lat_grid = numpy.zeros((abbox.height,abbox.width),dtype=numpy.float32)
    for c in range (0, abbox.width):
        lat_grid[:,c]=lats
    for r in range (0, abbox.height):
        lon_grid[r,:]=lons
    return lat_grid, lon_grid

def make_LAT_grid_time_min15_r(longitudes_2d, latitudes_2d):
    #calculate MSG scan time offset
#    v_lonlat2toffset_h = numpy.vectorize(mfg_geom.lonlat2toffset_h)
#    msg_time_offset_2d = v_lonlat2toffset_h(longitudes_2d, latitudes_2d)
#    msg_time_offset_2d[msg_time_offset_2d<0] = numpy.nan

    rows = longitudes_2d.shape[0]
    cols = longitudes_2d.shape[1]
    
    LAT=numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    longitudes_LAT_constant_2d = ( (longitudes_2d)/15. )
    
    ET_2d = numpy.empty((rows,cols), dtype=numpy.float32)

    for month_idx in range(0,11+1):
        doy=daytimeconv.month_representativedoys[0][month_idx+1]
        ET_2d[:,:]= solar_geom.perturbation(doy)
        for slot in range(1, 96+1):
            slot_idx = slot -1
            utc=(slot/4.) - 0.125
#            utc_h=daytimeconv.dh2hms(utc)[0]  
#            utc_m=daytimeconv.dh2hms(utc)[1]  
#            utc=utc_h+utc_m/60.
#            utc_msg_2d= msg_time_offset_2d + utc

            LAT[month_idx, slot_idx, :,:] = utc + ET_2d + longitudes_LAT_constant_2d

    del (ET_2d, longitudes_LAT_constant_2d)
    res=((LAT - 12)*15)*math.pi/180
    res[res>math.pi]-=2*math.pi
    return res

def make_declin_grid_min15(year, longitudes_2d):
    rows = longitudes_2d.shape[0]
    cols = longitudes_2d.shape[1]
    
    declin=numpy.empty((12,96,rows,cols), dtype=numpy.float32)

    b=[0, 0.0064979, 0.4059059, 0.0020054, -0.0029880, -0.0132296, 0.0063809, 0.0003508]
    year_dif = year - 1957
    n0 = 78.8946 + (0.2422 * year_dif) - int(0.25 * year_dif)
    t1 = -0.5 - n0 - (longitudes_2d/(360))
    omega0 = (math.pi*2.)/365.2422

    for month_idx in range(0,11+1):
        doy=daytimeconv.month_representativedoys[0][month_idx+1]
        omegat = omega0 * (doy + t1)
        decl = b[1] + b[2]*numpy.sin(omegat) + b[3]*numpy.sin(2.*omegat) + b[4]*numpy.sin(3.*omegat) + b[5]*numpy.cos(omegat) + b[6]*numpy.cos(2.*omegat) + b[7]*numpy.cos(3.*omegat)
        for slot in range(1, 96+1):
            slot_idx = slot - 1
            declin[month_idx, slot_idx, :,:] = decl
    del (t1, omegat, decl)
    return declin

def make_sunposit_grids_min15(lowres_bbox):
    latitude_2d, longitude_2d = make_lat_lon_grids(lowres_bbox)

    time_r = make_LAT_grid_time_min15_r(longitude_2d, latitude_2d)
    declin_grid = make_declin_grid_min15(2006, longitude_2d)
#    print numpy.degrees(time_r[1,:,0,0])
    rows = latitude_2d.shape[0]
    cols = latitude_2d.shape[1]

    sinfi_2d = numpy.sin(latitude_2d*math.pi/180)
    cosfi_2d = numpy.cos(latitude_2d*math.pi/180)

    del(latitude_2d, longitude_2d)
    sinfi = numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    cosfi = numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    for month_idx in range(0,11+1):
        for slot in range(1, 96+1):
            slot_idx = slot - 1
            sinfi[month_idx, slot_idx, :,:] = sinfi_2d
            cosfi[month_idx, slot_idx, :,:] = cosfi_2d
    del (sinfi_2d,cosfi_2d )
    
    sinde = numpy.sin(declin_grid)
    
    sinh0 = (sinfi*sinde) + (cosfi*numpy.cos(declin_grid)*numpy.cos(time_r))
    del(declin_grid)
    h0_r = numpy.arcsin(sinh0)
    cosh0 = numpy.cos(h0_r)
    cecl=cosfi*cosh0
    del (cosfi, cosh0 )
    a0_r=numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    a0_r[:,:,:,:] = math.pi                #toto je pre J a S pol - nie je definovana - da sa nahradit "time in radians" ???
    wh1 = numpy.abs(cecl) >= 0.001
    
    cosas = ((sinfi[wh1]*sinh0[wh1]) - sinde[wh1])/(cecl[wh1])
    cosas[cosas>1.] =1.
    cosas[cosas<-1.] =-1.
    a0_r[wh1]=math.pi - numpy.arccos(cosas)
    del(cosas, sinfi, sinh0, sinde, cecl)
    wh1 = time_r > 0
    a0_r[wh1] =  - a0_r[wh1]           # correction 360 deg
    a0_r = a0_r + math.pi               # correction to have a0 in range from -180 to 180
    wh1=a0_r > math.pi
    a0_r[wh1] = a0_r[wh1] - (2*math.pi)
    
    #refraction correction
    h0_r2 = h0_r*h0_r
    delta_h0refr = 0.061359*(0.1594+(1.1230*h0_r)+(0.065656*h0_r2))/(1.+(28.9344*h0_r)+(277.3971*h0_r2))
    
    h0_r += delta_h0refr
    del(time_r, delta_h0refr)
    return([a0_r,h0_r])



def diffinc_PerezFast_shadingGcomponents_percentiles_GHInormalized(GHI_perc, GHI_mean, DNI_perc, h0, GammaN, Albedo, sinDeltaexp, percentiles, doPVAngularCorr = True):
    #this is "percentiles" version
    #returns components of GHIincl: 
    # cDIF_iso_skydome, cDIF_iso_refl, cDIF_horiz, cDIF_circ, cREFL_incl, cDNI_incl

    
    sinGammaN=numpy.sin(GammaN)
    cosGammaN=numpy.cos(GammaN)
    # from the paper
    F11R=numpy.array([ 0.041, 0.054, 0.227, 0.486, 0.819, 1.020, 1.009, 0.936])
    F12R=numpy.array([ 0.621, 0.966, 0.866, 0.670, 0.106,-0.260,-0.708,-1.121])
    F13R=numpy.array([-0.105,-0.166,-0.250,-0.373,-0.465,-0.514,-0.433,-0.352])
    F21R=numpy.array([-0.040,-0.016, 0.069, 0.148, 0.268, 0.306, 0.287, 0.226])
    F22R=numpy.array([ 0.074, 0.114,-0.002,-0.137,-0.497,-0.804,-1.286,-2.449])
    F23R=numpy.array([-0.031,-0.045,-0.062,-0.056,-0.029, 0.046, 0.166, 0.383])
    EPSBINS=numpy.array([ 1.056, 1.253, 1.586, 2.134, 3.23, 5.98, 10.08,99.99])
    
    # R. Perez naming style conversion______________________________________________________________________
#    DiffHor = GHI - DNI*numpy.sin(h0)

    
#    percentile_coefs={'P1':0.025, 'P5':0.125, 'P25':0.225, 'P50':0.250, 'P75':0.225, 'P95':0.125, 'P99':0.025}
    percentile_coefs=percentiles_weights_dict(percentiles)
    Z=(math.pi/2.)-h0 # rad!!
    Z[Z<0.4]=0.4 
    
    B2 = 5.534e-6
    
    CZ = numpy.sin(h0)
    ZENITH = (math.pi/2. - h0) * 180./math.pi
    wh_cz=CZ <= 0.0
    CZ2=CZ.copy()
    CZ2[CZ2<0.0871557]=0.0871557
    
    AIRMASS=numpy.zeros_like(h0)
    wh1=ZENITH<93.9
    AIRMASS[wh1]=1.0/(CZ[wh1] + (0.15* numpy.power((93.9 - ZENITH[wh1]),-1.253)))
    wh1=(ZENITH>=93.9)
    AIRMASS[wh1]=999
    
    TB2 = B2*numpy.power(ZENITH,3)
    I= numpy.empty(GHI_perc[0,:,:,:,:].shape, dtype=numpy.int8)
    sinDeltaexp[sinDeltaexp< 0.0]=0.0
    
    
    
    
    #angular correction coefficients
    if doPVAngularCorr:
        # based on the PV_AngularDependence function direct Thomas PVGIS implementation (Martin and Ruiz 2001 approach)
        #from Artur's PV_Angular function in solar_geom_v6.py 
        ar=0.16 # The algorithm used in PVGIS uses that value
        ar_exp=math.exp(-1./ar)

        cosGammaN2=cosGammaN
        wh_g = cosGammaN > 0.98
        cosGammaN2[wh_g] = 0.98
#        if cosGammaN >0.98:
#            cosGammaN2 = 0.98
        c1=4./(3.*math.pi)
        c2=ar/2.-0.154
        
        #beam correction
        Bcorr=(1.-(numpy.exp(-sinDeltaexp/ar)-ar_exp)/(1.-ar_exp))
        #reflected correction
        fr=sinGammaN + (GammaN-sinGammaN)/(1.-cosGammaN2)
        Rcorr=max(0.,(1.-numpy.exp((-c1*fr-c2*fr*fr)/ar)))
        #diffused correction 
        fd=sinGammaN + (math.pi-GammaN-sinGammaN)/(1.+cosGammaN2)
        Dcorr = max(0.,(1.-math.exp((-c1*fd-c2*fd*fd)/ar)))
        del (fd,fr)
    else:
        Bcorr=1.0
        Rcorr=1.0
        Dcorr=1.0

    

    
    
    
    #empty arrays for results
    #used for normalization 
    GHIp = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    
    # irradiation components
    cDNI_incl = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cREFL_incl = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_horiz = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_circ = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_iso_skydome = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_iso_refl = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    
    
    for perc in percentiles:
        logger.info('Percentile: '+str(perc))
        #get data for given percentile
        perc_idx = percentiles.index(perc)
        GHI = GHI_perc[perc_idx, :,:,:,:]
        DNI = DNI_perc[perc_idx, :,:,:,:]
        #weight of percentile in total average
        perc_wght = percentile_coefs[perc]

        DiffHor = GHI - (DNI* CZ)
        DiffHor[wh_cz] = GHI[wh_cz]
        DELTA = DiffHor * AIRMASS / 1367. #Solar constant
        
#        EPS = (DNI + DiffHor) / DiffHor
#        EPS = (EPS + TB2) / (1.0 + TB2)
        EPS=numpy.zeros_like(DiffHor)
        #added to avoid zero division
        wh_diff_no0=DiffHor!=0
        EPS[wh_diff_no0] = (DNI[wh_diff_no0] + DiffHor[wh_diff_no0]) / DiffHor[wh_diff_no0]
        EPS = (EPS + TB2) / (1.0 + TB2)
#        EPS = (((DNI + DiffHor) / DiffHor) + TB2) / (1.0 + TB2)
        
        I[:,:,:,:]=7
        I[(EPS<=EPSBINS[6]) & (EPS>EPSBINS[5])]=6
        I[(EPS<=EPSBINS[5]) & (EPS>EPSBINS[4])]=5
        I[(EPS<=EPSBINS[4]) & (EPS>EPSBINS[3])]=4
        I[(EPS<=EPSBINS[3]) & (EPS>EPSBINS[2])]=3
        I[(EPS<=EPSBINS[2]) & (EPS>EPSBINS[1])]=2
        I[(EPS<=EPSBINS[1]) & (EPS>EPSBINS[0])]=1
        I[(EPS<=EPSBINS[0])]=0
        
        F1 = F11R[I] + F12R[I]*DELTA + F13R[I] * Z
        F1[F1<0.]=0.
        F2 = F21R[I] + F22R[I] * DELTA + F23R[I] * Z
        
        
        #GHI derived from percentiles - used for normalization
        GHIp += ((DiffHor) + (CZ*DNI)) * perc_wght

        cDIF_iso_skydome += Dcorr * DiffHor * (( 1.0 + cosGammaN) / 2.0) * (1-F1)  * perc_wght
        cDIF_iso_refl += Dcorr * Albedo * GHI * perc_wght
        cDIF_horiz += Dcorr * DiffHor * sinGammaN * F2 * perc_wght
        cDIF_circ += Bcorr * DiffHor * (sinDeltaexp/ CZ2) * F1 * perc_wght 
        cREFL_incl += (Rcorr * Albedo * GHI * (1.0 - cosGammaN)/2.0) * perc_wght
        cDNI_incl += Bcorr * sinDeltaexp * DNI * perc_wght
        
        del(F1, F2, DELTA, EPS, DiffHor)


    # normalize the percentile derived statistics by mean. in other words the percentiles are used only in relative way,
    # the output mean from percentiles is corrected to be equal to real mean from the data
    wh_corr = GHIp>0.0
    corr = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    corr[wh_corr] = GHI_mean[wh_corr]/GHIp[wh_corr]
    cDIF_iso_skydome *= corr
    cDIF_iso_refl *= corr
    cDIF_horiz *= corr
    cDIF_circ *= corr
    cREFL_incl *= corr
    cDNI_incl *= corr
    
    del(AIRMASS, corr)
    del(Z,I)

    return cDIF_iso_skydome, cDIF_iso_refl, cDIF_horiz, cDIF_circ, cREFL_incl, cDNI_incl


def data_resample(data, projgrids, data_xy_minmax, interpolation='nearest'):
    if (data.ndim > 4) or (data.ndim < 2):
        logger.error('number of data dimensions for resample outside of <2,4> range')
        return None
    
    if len(projgrids) != 6:
        logger.error('projgrids shuold contain 6 grids')
        return None
    proj_x1, proj_y1, proj_x2, proj_y2, proj_x_wght, proj_y_wght = projgrids

#    data_xmin, data_xmax, data_ymin, data_ymax = data_xy_minmax
    if data.dtype is numpy.float32:
        noval=numpy.NaN
    else:
        noval=-9999
        
    if data.ndim == 2:
        out_data = numpy.empty((proj_y1.shape[0],proj_y1.shape[1]), dtype = data.dtype)
        out_data[:,:]=noval
    elif data.ndim == 3:
        out_data = numpy.empty((data.shape[0],proj_y1.shape[0],proj_y1.shape[1]), dtype = data.dtype)
        out_data[:,:,:]=noval
    else:
        out_data = numpy.empty((data.shape[0],data.shape[1],proj_y1.shape[0],proj_y1.shape[1]), dtype = data.dtype)
        out_data[:,:,:,:]=noval
#    wh = (proj_x1 >= data_xmin) & (proj_x1 <= data_xmax) & (proj_x2 >= data_xmin) & (proj_x2 <= data_xmax)
#    wh = wh & (proj_y1 >= data_ymin) & (proj_y1 <= data_ymax) & (proj_y2 >= data_ymin) & (proj_y2 <= data_ymax)


    if (interpolation== 'nearest') or (interpolation== 'n'):
        if data.ndim == 2:
            out_data=data[proj_y1,proj_x1]
        elif data.ndim == 3:
            out_data=data[:,proj_y1,proj_x1]
        else:
            out_data=data[:,:,proj_y1,proj_x1]
        return out_data

    elif (interpolation== 'bilinear') or (interpolation== 'b'):
        if data.ndim == 2:
#            aux1=data[proj_y1,proj_x1]
#            aux2=data[proj_y1,proj_x2]
#            aux3=data[proj_y2,proj_x1]
#            aux4=data[proj_y2,proj_x2]
#            aux5a=aux1 + (aux2 - aux1)*proj_x_wght
#            aux5b=aux3 + (aux4 - aux3)*proj_x_wght
#            out_data = aux5a + (aux5b - aux5a)*proj_y_wght
            aux5a=data[proj_y1,proj_x1] + (data[proj_y1,proj_x2] - data[proj_y1,proj_x1])*proj_x_wght
#            aux5b=data[proj_y2,proj_x1] + (data[proj_y2,proj_x2] - data[proj_y2,proj_x1])*proj_x_wght
            out_data = aux5a + (data[proj_y2,proj_x1] + (data[proj_y2,proj_x2] - data[proj_y2,proj_x1])*proj_x_wght - aux5a)*proj_y_wght
        elif data.ndim == 3:
#            aux1=data[:,proj_y1,proj_x1]
#            aux2=data[:,proj_y1,proj_x2]
#            aux3=data[:,proj_y2,proj_x1]
#            aux4=data[:,proj_y2,proj_x2]
#            aux5a=aux1 + (aux2 - aux1)*proj_x_wght
#            aux5b=aux3 + (aux4 - aux3)*proj_x_wght
#            out_data = aux5a + (aux5b - aux5a)*proj_y_wght
            aux5a=data[:,proj_y1,proj_x1] + (data[:,proj_y1,proj_x2] - data[:,proj_y1,proj_x1])*proj_x_wght
#            aux5b=data[:,proj_y2,proj_x1] + (data[:,proj_y2,proj_x2] - data[:,proj_y2,proj_x1])*proj_x_wght
            out_data = aux5a + (data[:,proj_y2,proj_x1] + (data[:,proj_y2,proj_x2] - data[:,proj_y2,proj_x1])*proj_x_wght - aux5a)*proj_y_wght
        else:
#            aux1=data[:,:,proj_y1,proj_x1]
#            aux2=data[:,:,proj_y1,proj_x2]
#            aux3=data[:,:,proj_y2,proj_x1]
#            aux4=data[:,:,proj_y2,proj_x2]
#            aux5a=aux1 + (aux2 - aux1)*proj_x_wght
#            aux5b=aux3 + (aux4 - aux3)*proj_x_wght
#            out_data = aux5a + (aux5b - aux5a)*proj_y_wght
            aux5a=data[:,:,proj_y1,proj_x1] + (data[:,:,proj_y1,proj_x2] - data[:,:,proj_y1,proj_x1])*proj_x_wght
#            aux5b=data[:,:,proj_y2,proj_x1] + (data[:,:,proj_y2,proj_x2] - data[:,:,proj_y2,proj_x1])*proj_x_wght
            out_data = aux5a + (data[:,:,proj_y2,proj_x1] + (data[:,:,proj_y2,proj_x2] - data[:,:,proj_y2,proj_x1])*proj_x_wght - aux5a)*proj_y_wght
            
#        del (aux1, aux2, aux3, aux4)
#        del (aux5a, aux5b)
        del (aux5a)
        return out_data

    else:
        logger.error('unknown interpolation method. use nearest or bilinear')
        return None
    return None


def _interp_2d(out_time_arr,in_time_arr_ext,adata):
    adata=adata.copy()
    rr=    adata.shape[1]        
    cc=    adata.shape[2]
    res=numpy.empty((out_time_arr.shape[0],rr,cc))    
#    adata=numpy.roll(adata,shift=-1,axis=0)
    adata=numpy.vstack([adata[-1,:,:].reshape((1,rr,cc)),adata,adata[0,:,:].reshape((1,rr,cc))])
    adata=adata.astype(numpy.float64)
    for r in range(0,rr):
        for c in range(0,cc):
            adat = adata[:,r,c]
            odat = numpy.interp(out_time_arr, in_time_arr_ext, adat)
            aux=adat[1:-1]
            wh_in=(aux==aux)
            wh_out=(odat==odat)
            if (wh_in.sum() >0) and (wh_out.sum() >0) and ((odat[wh_out]).sum()>0):
                odat*=aux[wh_in].sum()/((odat[wh_out]).sum()/2.)
            res[:,r,c]=odat
    return res

def percentiles_weights_dict(percentiles):
    if len(percentiles)==0:
        return {}
    if len(percentiles)==1:
        return {percentiles[0]:1.0}
    
    #make sorted percentiles
    spercentiles=list(percentiles)
    spercentiles.sort()

    if spercentiles[0] < 0:
        return None
    if spercentiles[-1] > 100:
        return None

    percentile_wghts={}
    for indx in range(0,len(spercentiles)):
        if indx==0:
            first_half=spercentiles[indx]-0
        else:
            first_half=(spercentiles[indx]-spercentiles[indx-1])/2.
            
        if indx==(len(spercentiles)-1):
            second_half=100-spercentiles[indx]
        else:
            second_half=(spercentiles[indx+1]-spercentiles[indx])/2.
        
        weight=(first_half+second_half)/100.
        percentile_wghts[spercentiles[indx]]=weight
    
    return percentile_wghts

def percentiles_names_list(percentiles, prefix='P', suffix=''):
    perc_names=[]
    for perc in percentiles:
        perc_names.append(prefix+str(perc)+suffix)
    return perc_names


#------------------------------------------------------------
# main
#------------------------------------------------------------

if __name__ == "__main__":
    
    mail_notification='tomas.cebecauer@solargis.com' #email addres to send finish notification to, Use '' to avoid mail notification
#    mail_notification=None
    
    version='v21'
    
    lowres_data_path='/home1/model_data_himawari/data_output_wgs84/v20_combined_2007_2016/'
    horizon_path='/home1/horiz/'
    horizon_path='/net/atlas/data/horizon/horiz_dir48_30arcsec/'  # /net/hydra/home1/horiz/
    
    region_suffix='_pan'
    
    highres_data_path='/home1/model_data_himawari/data_output_dissagr/v20_combined_2007_2016/'

    # 5x5 degree latlon tiles to calculate 
    segments_to_calculate=latlon.expand_segments([[59, 59, 7, 7]])
    
    force_overwrite = True
    
    resolution=10 # 3x3, 5x5, 10x10 pixels; original pixels have 3 arcsec res

    # decide whether inclination and aspect should be read in highres 
    # it is slower, but allows to calculate irradiation on terrain  surface
    inclination_aspect_highres=False  # SLOW - only for incl/azim from file

    inclination_from_file=False
    inclination=0 #module/axis inclination
    inclination_filename = lowres_data_path+'OPTA%s.nc' % (region_suffix)
    inclination_var_name = 'opta'
#    inclination_filename = '/home/tomas/botany/prec/srtm30/srtm15_slope.nc'
#    inclination_var_name = 'slope'
    
    azimuth_from_file=False
    azimuth=0 #module azimuth 0-North 180-South
#    azimuth_filename = lowres_data_path+'AZIM%s.nc' % (region_suffix)mfg_model_out_dissag2grass_test.py
#    azimuth_var_name = 'azim'
    azimuth_filename = '/home/tomas/botany/prec/srtm30/srtm15_azimuth.nc'
    azimuth_var_name = 'azimuth'
    
    mounting=1 
#            1 - fixed
#            5 - t1xV 1-axis tracker, vertical axis, inclined module 
#            6 - t1xI 1-axis tracker, inclined axis
#            7 - t1xNS 1-axis tracker, horizontal NS axis
#            8 - t1xEW 1-axis tracker, horizontal EW axis
#            9 - t2x 2-axis tracker

    doDNI=True
    doDiffI=True
    
    hires_interpol='bilinear'

    specific_year=None # None

    
    #make subset only. if Subset_bos  set to None, then do whole segments
#    sub_xmin, sub_xmax, sub_ymin, sub_ymax, sub_res = 70.0,72.0,28.0,30.0,0.25
#    Subset_box=latlon.bounding_box(xmin=sub_xmin, xmax=sub_xmax, ymin=sub_ymin, ymax=sub_ymax, width=(sub_xmax-sub_xmin)/sub_res, height=(sub_ymax-sub_ymin)/sub_res, resolution=sub_res)
    Subset_box=None
    
    percentiles = [1, 10, 25, 50, 75, 90, 99] #MUST be same as those within ...merge_segments.py

#-------------------------------------------------
    if inclination_aspect_highres and ((not inclination_from_file) and (not azimuth_from_file)):
        print 'inclination_aspect_highres allowed only if inclination_from_file or azimuth_from_file is True. Exit.'
        exit()
    
    Albedo = 0.125

    #inputs
    intime_step_hours = 0.25
    inslot_min, inslot_max = 1, 96
    outtime_step_hours = 0.25
    outslot_min, outslot_max = 1, 96

    NC_in_GHI_name=lowres_data_path+'GHI_15min_m_stats'+region_suffix+'.nc'
    NC_in_DNI_name=lowres_data_path+'DNI_15min_m_stats'+region_suffix+'.nc'

    if specific_year is not None:
        NC_year_GHI_name=lowres_data_path+'GHI_d_m'+region_suffix+'.nc'
        NC_year_DNI_name=lowres_data_path+'DNI_d_m'+region_suffix+'.nc'

    horiz_name_prefix,horiz_name_suffix =horizon_path+'horizon_', '_dir48_'

    #outputs
    if resolution == 1:#1 arcsec pixels == 9 arcsec
        out_res_suffix='3arcsec'
        horiz_name_suffix=horiz_name_suffix+'.nc'
    elif resolution == 3:#3 arcsec pixels == 9 arcsec
        out_res_suffix='9arcsec'
        horiz_name_suffix=horiz_name_suffix+'resc3.nc'
    elif resolution == 5:#5 arcsec pixels == 15 arcsec
        out_res_suffix='15arcsec'
        horiz_name_suffix=horiz_name_suffix+'resc5.nc'
    elif resolution == 10:#10 arcsec pixels == 30 arcsec
        out_res_suffix='30arcsec'
        horiz_name_suffix=horiz_name_suffix+'resc10.nc'
    
    if specific_year is not None:
        out_res_suffix+='_%d'%(specific_year)

    if (mounting == 1):
        if inclination_from_file:
            out_Gincl_prefix='opta'
        elif inclination>0:
            out_Gincl_prefix=str(inclination)
        else:
            out_Gincl_prefix='H'
    elif (mounting == 5) or (mounting == 6):
        out_Gincl_prefix=mounting_geom.mounting_shortname(mounting, preffix="t")+str(inclination)
    else:
        out_Gincl_prefix=mounting_geom.mounting_shortname(mounting, preffix="t")

    out_GHI_name_prefix,out_GHI_name_suffix =highres_data_path+'G'+out_Gincl_prefix+'I_15min_m_', '_'+out_res_suffix+'.nc' # 
    out_GHI_name_prefix_m,out_GHI_name_suffix_m =highres_data_path+'G'+out_Gincl_prefix+'I_m_', '_'+out_res_suffix+'.nc' # 
    if doDNI:
        out_DNI_name_prefix,out_DNI_name_suffix =highres_data_path+'DNI_15min_m_', '_'+out_res_suffix+'.nc' # 
        out_DNI_name_prefix_m,out_DNI_name_suffix_m =highres_data_path+'DNI_m_', '_'+out_res_suffix+'.nc' # 
    if doDiffI:
        out_DiffI_name_prefix,out_DiffI_name_suffix =highres_data_path+'Diff'+out_Gincl_prefix+'I_15min_m_', '_'+out_res_suffix+'.nc' # 
        out_DiffI_name_prefix_m,out_DiffI_name_suffix_m =highres_data_path+'Diff'+out_Gincl_prefix+'I_m_', '_'+out_res_suffix+'.nc' # 
    
    out_res= resolution * 1./1200. #240. for 15arcsec, 400. for 9arcsec
    
    
    
    for seg_col, seg_row in segments_to_calculate:
        logger.info( 'seg: %d %d' %( seg_row,seg_col))
        out_latlon_bbox=latlon.get_5x5_seg_bbox(seg_row, seg_col , out_res)
    
        if (Subset_box is not None) and not(out_latlon_bbox.intersect(Subset_box)):
            logger.info('Skipping seg: %d %d. Out of Subset_box' %( seg_row,seg_col))
            continue
        if Subset_box is not None:
            read_lowres_bbox = out_latlon_bbox.intersect(Subset_box)
        else:
            read_lowres_bbox = out_latlon_bbox

        NC_horiz_filename=horiz_name_prefix+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+horiz_name_suffix
        if not(os.access(NC_horiz_filename, os.F_OK)):
            logger.warning("Input horizon NetCDF file %s not found. skipping segment",NC_horiz_filename)
            continue

        #create output NC files
        #month slot
        NC_out_GHI_filename=out_GHI_name_prefix+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_GHI_name_suffix
        result = make_model_output_disaggreg_ms_latlon(NC_out_GHI_filename,out_latlon_bbox,overwrite = force_overwrite, slot_min=1, slot_max=96,logger=logger, version=version)
        if doDNI:
            NC_out_DNI_filename=out_DNI_name_prefix+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_DNI_name_suffix
            result &= make_model_output_disaggreg_ms_latlon(NC_out_DNI_filename,out_latlon_bbox,overwrite = force_overwrite, slot_min=1, slot_max=96,logger=logger, version=version)
        if doDiffI:
            NC_out_DiffI_filename=out_DiffI_name_prefix+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_DiffI_name_suffix
            result &= make_model_output_disaggreg_ms_latlon(NC_out_DiffI_filename,out_latlon_bbox,overwrite = force_overwrite, slot_min=1, slot_max=96,logger=logger, version=version)
        #monthly
        NC_out_GHI_filename_m=out_GHI_name_prefix_m+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_GHI_name_suffix_m
        result &= make_model_output_disaggreg_m_latlon(NC_out_GHI_filename_m,out_latlon_bbox,overwrite = force_overwrite,logger=logger, version=version)
        if doDNI:
            NC_out_DNI_filename_m=out_DNI_name_prefix_m+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_DNI_name_suffix_m
            result &= make_model_output_disaggreg_m_latlon(NC_out_DNI_filename_m,out_latlon_bbox,overwrite = force_overwrite,logger=logger, version=version)
        if doDiffI:
            NC_out_DiffI_filename_m=out_DiffI_name_prefix_m+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_DiffI_name_suffix_m
            result &= make_model_output_disaggreg_m_latlon(NC_out_DiffI_filename_m,out_latlon_bbox,overwrite = force_overwrite,logger=logger, version=version)
        if result==False:
            logger.warning("Problem creating output file. skipping segment")
            continue
        
            
        logger.info('Reading lowres GHI data')
        var_names=percentiles_names_list(percentiles)
        result = read_lowres_multi_data_for_highres_bbox(NC_in_GHI_name, var_names, out_latlon_bbox, inslot_min, inslot_max,logger)
        if result is None: sys.exit()
        GHI_lowres, lowres_bbox = result
        var_name='mean'
        result = read_lowres_data_for_highres_bbox(NC_in_GHI_name, var_name, out_latlon_bbox, inslot_min, inslot_max,logger)
        if result is None: sys.exit()
        GHI_lowres_mean, lowres_bbox = result

        logger.info('Reading lowres DNI data')
        var_names=percentiles_names_list(percentiles)
        result = read_lowres_multi_data_for_highres_bbox(NC_in_DNI_name, var_names, out_latlon_bbox, inslot_min, inslot_max,logger)
        if result is None: sys.exit()
        DNI_lowres, lowres_bbox = result
        if doDNI or doDiffI:
            var_name='mean'
            result = read_lowres_data_for_highres_bbox(NC_in_DNI_name, var_name, out_latlon_bbox, inslot_min, inslot_max,logger)
            if result is None: sys.exit()
            DNI_lowres_mean, lowres_bbox = result
            
        if specific_year is not None:
            logger.info('Reading lowres data for year %s' % (specific_year))
            
            var_name='GHI_d_m'
            result = read_lowres_data_year_for_highres_bbox(NC_year_GHI_name, var_name, read_lowres_bbox, specific_year,logger)
            if result is None: sys.exit()
            GHI_lowres_year_mean, lowres_bbox = result
            var_name='DNI_d_m'
            result = read_lowres_data_year_for_highres_bbox(NC_year_DNI_name, var_name, read_lowres_bbox, specific_year,logger)
            if result is None: sys.exit()
            DNI_lowres_year_mean, lowres_bbox = result
            #adapt_mean_percentile to year mean
            for m in range(0,12):
                mmeanG=GHI_lowres_mean[m,:,:,:].sum(axis=0)*intime_step_hours
                whG = mmeanG != 0
                rescG=GHI_lowres_year_mean[m,whG]/mmeanG[whG]
                mmeanD=DNI_lowres_mean[m,:,:,:].sum(axis=0)*intime_step_hours
                whD = mmeanD != 0
                rescD=DNI_lowres_year_mean[m,whD]/mmeanD[whD]
                for s in range(0,inslot_max-inslot_min+1):
                    GHI_lowres_mean[m,s,whG]*=rescG
                    DNI_lowres_mean[m,s,whD]*=rescD


        if not inclination_aspect_highres:
            #read lowres data
            if inclination_from_file:
                #read lowres data
                logger.info('Reading lowres inclination data')
                incl = latlon_nctools.latlon_read_lat_lon_nc_bbox(inclination_filename, inclination_var_name, lowres_bbox, interpolate='nearest')
    #            result = read_lowres_2d_data_for_highres_bbox(inclination_filename, inclination_var_name, lowres_bbox, logger)
                if incl is None: sys.exit()
                modul_incl_r=numpy.radians(incl)
            else:
                modul_incl_r=numpy.radians(inclination)
    
            #read lowres data
            if azimuth_from_file:
                #read lowres data
                logger.info('Reading lowres azim data')
                azim = latlon_nctools.latlon_read_lat_lon_nc_bbox(azimuth_filename, azimuth_var_name, lowres_bbox, interpolate='nearest')
    #            result = read_lowres_2d_data_for_highres_bbox(azimuth_filename, azimuth_var_name, lowres_bbox, logger)
                if azim is None: sys.exit()
                azim[azim>360]=azim[azim>360]-360. 
                azim[azim<0]=azim[azim<0]+360. 
                modul_asp_r=numpy.radians(azim -180.)
            else:
                modul_asp_r=numpy.radians(azimuth-180.)
    

            
        logger.info('Calculating solar geometry')
        a0_grid, h0_grid = make_sunposit_grids_min15(lowres_bbox)

        
#        logger.info('Interpolate irrad data 48>96 time slots')
#        import datetime
#        aS=datetime.datetime.now()
##        longit, latit = out_latlon_bbox.center()
##        aux0 = mfg_geom.lonlat2toffset_h(longit, latit)
##        in_time_arr=numpy.empty((48),dtype=numpy.float64)
##        for slot in range(1,48+1):
#        in_time_arr=numpy.arange(0.25,24.0,0.5) # goes output 30 min slot mapping 
#        out_time_arr=numpy.empty((96),dtype=numpy.float64)
#        for slot in range(1,96+1):
#            out_time_arr[slot-1]=(slot/4.) - 0.125
#        
#        #rotate in data and time array    
#        in_time_arr_ext=numpy.hstack([numpy.array(-0.25), in_time_arr, numpy.array(24.25)])
#        
#        mm,dummy,rr,cc = GHI_lowres_mean.shape
#        GHI_lowres_mean96 = numpy.empty((mm,96,rr,cc), dtype=GHI_lowres_mean.dtype)
#        if doDNI or doDiffI:
#            DNI_lowres_mean96 = numpy.empty((mm,96,rr,cc), dtype=DNI_lowres_mean.dtype)
#        pp,mm,dummy,rr,cc = GHI_lowres.shape
#        GHI_lowres96 = numpy.empty((pp,mm,96,rr,cc), dtype=GHI_lowres.dtype)
#        DNI_lowres96 = numpy.empty((pp,mm,96,rr,cc), dtype=DNI_lowres.dtype)
#            
#        for month in range(1,12+1):
#            GHI_lowres_mean96[month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,GHI_lowres_mean[month-1,:,:,:])
#            if doDNI or doDiffI:
#                DNI_lowres_mean96[month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,DNI_lowres_mean[month-1,:,:,:])
#            for p_idx in range(0,pp):
#                GHI_lowres96[p_idx,month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,GHI_lowres[p_idx,month-1,:,:,:])
#                DNI_lowres96[p_idx,month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,DNI_lowres[p_idx,month-1,:,:,:])
#                
#        aE=datetime.datetime.now()
#        print aE-aS
        
#        latlon.visualize_map_3d(GHI_lowres_mean96[0,:,:,:], out_latlon_bbox, interpolation='nearest')
#        GHI_lowres=GHI_lowres96
#        DNI_lowres=DNI_lowres96
#        GHI_lowres_mean=GHI_lowres_mean96
#        if doDNI or doDiffI:
#            DNI_lowres_mean=DNI_lowres_mean96

        sina0_grid = numpy.sin(a0_grid)
        cosa0_grid = numpy.cos(a0_grid)
        sinh0_grid = numpy.sin(h0_grid)
        cosh0_grid = numpy.cos(h0_grid)
        rotation_limit = [None, None]
        rotation_limit2 = [None, None]
        backtrack = False
        relative_spacing_rows = 0
        relative_spacing_columns = 0
        



        if not inclination_aspect_highres:
            logger.info('Calculating module geometry')
            #inc_angle_cos_grid, GammaNV = mounting_geom.mounting_incidencecos_gamma(mounting, a0_grid, h0_grid, modul_incl, modul_asp)
            latitudes_2d=lowres_bbox.latitudes(array2d=True)
#            dummy, GammaNV, dummy, inc_angle_cos_grid, dummy,dummy, dummy, dummy = mounting_geom.mounting_geom_angles(mounting, a0_grid, h0_grid, GN=modul_incl_r, AN=modul_asp_r, latitude=latitudes_2d)
            dummy, inc_angle_cos_grid, GammaNV ,dummy, dummy, dummy, dummy, dummy, dummy, dummy, dummy = mounting_geom.mounting_geom_angles(mounting, sina0_grid, cosa0_grid, a0_grid, sinh0_grid, cosh0_grid, h0_grid, GN=modul_incl_r, AN=modul_asp_r, latitude=latitudes_2d, rotation_limit=rotation_limit, rotation_limit2=rotation_limit2, backtrack=backtrack, relative_spacing_rows=relative_spacing_rows, relative_spacing_columns=relative_spacing_columns)

        
            logger.info('Calculating diffuse components')
            #        percentile_names=var_names
            cDIF_iso_skydome, cDIF_iso_refl, cDIF_horiz, cDIF_circ, cREFL_incl, cDNI_incl = diffinc_PerezFast_shadingGcomponents_percentiles_GHInormalized(GHI_lowres, GHI_lowres_mean, DNI_lowres, h0_grid, GammaNV, Albedo, inc_angle_cos_grid, percentiles, doPVAngularCorr=False)
        
        
        #DISAGGREGATION
        #test if lowres box covers whole out_latlon_bbox
        res=out_latlon_bbox.intersect(lowres_bbox)
        if not res.equals(out_latlon_bbox):
            logger.warning("lowres data does not cover whole segment bbox, reducing")
            out_latlon_bbox2=res
        else:
            out_latlon_bbox2=out_latlon_bbox
        
        #resampling
        if not inclination_aspect_highres:
            subseg_bboxes = out_latlon_bbox2.subsegments(subseg_size=0.5)
        else:
            subseg_bboxes = out_latlon_bbox2.subsegments(subseg_size=0.25)


        dim0_minmax=[1,12]
        dim1_minmax=[outslot_min,outslot_max]
        
        counter=0
        for ss_box in subseg_bboxes:
            counter+=1
            if not(Subset_box is None) and not(ss_box.intersect(Subset_box)):
                logger.info('Skipping subsegment: %d/%d. Out of Subset_box' %( counter,len(subseg_bboxes)))
                continue
            logger.info('Processing subsegment %d/%d',counter,len(subseg_bboxes))
            res = out_latlon_bbox.pixel_coords_of_bbox(ss_box)
            dim2_minmax = res[2:4]
            dim3_minmax = res[0:2]
            
            
            # resampling             
            projgrids = ss_box.px_idx_grid_of_second_bbox(lowres_bbox)
            DTs = datetime.datetime.now()
            
            a0_dissag = data_resample(a0_grid, projgrids, None, interpolation=hires_interpol)
            h0_dissag = data_resample(h0_grid, projgrids, None, interpolation=hires_interpol)

            if not inclination_aspect_highres:
                #standard version module geomoetry precalculated in lowres - resample irradiation components
                cDIF_iso_skydome_dissag = data_resample(cDIF_iso_skydome, projgrids, None, interpolation=hires_interpol)
                cDIF_iso_refl_dissag = data_resample(cDIF_iso_refl, projgrids, None, interpolation=hires_interpol)
                cDIF_horiz_dissag = data_resample(cDIF_horiz, projgrids, None, interpolation=hires_interpol)
                cDIF_circ_dissag = data_resample(cDIF_circ, projgrids, None, interpolation=hires_interpol)
                cREFL_incl_dissag = data_resample(cREFL_incl, projgrids, None, interpolation=hires_interpol)
                cDNI_incl_dissag = data_resample(cDNI_incl, projgrids, None, interpolation=hires_interpol)

                if (modul_incl_r.ndim == 2):
                    modul_incl_r_dissag = data_resample(modul_incl_r, projgrids, None, interpolation=hires_interpol)
                else:
                    modul_incl_r_dissag = modul_incl_r
                
                if (modul_asp_r.ndim == 2):
                    modul_asp_r_dissag = data_resample(modul_asp_r, projgrids, None, interpolation=hires_interpol)
                else:
                    modul_asp_r_dissag = modul_asp_r
            
            
            else:
                #highres version of module geomoetry - resample input data
                DNI_lowres_dissag = data_resample(DNI_lowres, projgrids, None, interpolation=hires_interpol)
                GHI_lowres_dissag = data_resample(GHI_lowres, projgrids, None, interpolation=hires_interpol)
                GHI_lowres_mean_dissag = data_resample(GHI_lowres_mean, projgrids, None, interpolation=hires_interpol)

            if doDNI:
                DNI_dissag = data_resample(DNI_lowres_mean, projgrids, None, interpolation=hires_interpol)


#            print 'TIME: lowres->highres resampling', datetime.datetime.now() - DTs
            DTs = datetime.datetime.now()


            # 
            if inclination_aspect_highres:
                #read lowres data
                if inclination_from_file:
                    #read lowres data
                    logger.info('Reading lowres inclination data')
                    incl = latlon_nctools.latlon_read_lat_lon_nc_bbox(inclination_filename, inclination_var_name, ss_box, interpolate='bilinear')
                    if incl is None: sys.exit()
                    modul_incl_r_dissag=numpy.radians(incl)
                else:
                    modul_incl_r_dissag=numpy.radians(inclination)
        
                #read lowres data
                if azimuth_from_file:
                    #read lowres data
                    logger.info('Reading lowres azim data')
                    azim = latlon_nctools.latlon_read_lat_lon_nc_bbox(azimuth_filename, azimuth_var_name, ss_box, interpolate='bilinear')
                    if azim is None: sys.exit()
                    azim[azim>360]=azim[azim>360]-360. 
                    azim[azim<0]=azim[azim<0]+360. 
                    modul_asp_r_dissag=numpy.radians(azim -180.)
                else:
                    modul_asp_r_dissag=numpy.radians(azimuth-180.)
                
                
                logger.info('Calculating module geometry')
                latitude_2d, longitude_2d = make_lat_lon_grids(ss_box)
                dummy, GammaNV_dissag, dummy, inc_angle_cos_grid_dissag, dummy,dummy, dummy, dummy = mounting_geom.mounting_geom_angles(mounting, a0_dissag, h0_dissag, GN=modul_incl_r_dissag, AN=modul_asp_r_dissag, latitude=latitude_2d)
            
                logger.info('Calculating diffuse components')
                
                cDIF_iso_skydome_dissag, cDIF_iso_refl_dissag, cDIF_horiz_dissag, cDIF_circ_dissag, cREFL_incl_dissag, cDNI_incl_dissag = diffinc_PerezFast_shadingGcomponents_percentiles_GHInormalized(GHI_lowres_dissag, GHI_lowres_mean_dissag, DNI_lowres_dissag, h0_dissag, GammaNV_dissag, Albedo, inc_angle_cos_grid_dissag, percentiles, doPVAngularCorr=False)
                
                print 'TIME: inclination_aspect_highres', datetime.datetime.now() - DTs
                DTs = datetime.datetime.now()

                
            #read horizons
            horizons = read_horizon_nc_file(NC_horiz_filename,dim3_minmax[0],dim3_minmax[1],dim2_minmax[0],dim2_minmax[1],'horizons',logger)
            if horizons is None: continue
            
            #calculate horizons for given azimuth
            #shading (0/1) for direct and diffuse circumsolar component
            horizons_direct =  horizons_interpolate_for_a0(horizons, a0_dissag, ss_box, outslot_min, outslot_max)
            shading_direct = numpy.zeros_like(horizons_direct)                                
            wh = h0_dissag < horizons_direct
            shading_direct[wh] = 1

#            print 'TIME: shading direct', datetime.datetime.now() - DTs
            DTs = datetime.datetime.now()

            #shading factor (0.0-1.0) for isotropic diffuse
            # define model of skydome and calculate which part is shaded. this is later used to calculate  
            if mounting == 1:

                sinGammaNV = numpy.sin(modul_incl_r_dissag)
                cosGammaNV = numpy.cos(modul_incl_r_dissag)
                sinANV = numpy.sin(modul_asp_r_dissag)
                cosANV = numpy.cos(modul_asp_r_dissag)
                
                skydomeAspectsNum=48
                skydomeHeightsNum=60
                skydome_a0_arr,skydome_h0_arr,skydome_sina0_arr,skydome_cosa0_arr,skydome_sinh0_arr,skydome_cosh0_arr = shading_utils.diffuse_isotropic_shading_meshgrids(skydomeAzimsNum=skydomeAspectsNum, skydomeHeightsNum=skydomeHeightsNum)
    
                skydomeAspectStep = 2.0*numpy.pi/skydomeAspectsNum
                AspectHor=numpy.arange(-numpy.pi+skydomeAspectStep/2.,numpy.pi,skydomeAspectStep)
                horizons_isotropic = horizons_interpolate_for_dif_isotropic(horizons, AspectHor, ss_box)
                
                if (modul_incl_r_dissag.ndim <2) and (modul_asp_r_dissag.ndim <2):
                    #fixed version of inclination or aspect - one for whole segment
                    
                    #azimuth and inclination (tilt) is scalar  
                    skydome_incidence_angle_arr = mounting_geom.Rel_sunpos_V1(sinGammaNV,cosGammaNV,sinANV,cosANV,skydome_sina0_arr,skydome_cosa0_arr,skydome_sinh0_arr,skydome_cosh0_arr)  # calculate incidence angle for all skydome points
                    aux = skydome_incidence_angle_arr * skydome_cosh0_arr
                    
                    # here starts the fun  - this must be done for each pixel individually - brute force
                    isotropic_shading_factor=numpy.ones((ss_box.height,ss_box.width))
                    for c in range(0,ss_box.width):
                        for r in range(0,ss_box.height):
                            horiz_isotrop_vect = horizons_isotropic[:,r,c]
                            horiz_isotrop_arr = numpy.reshape(numpy.tile(horiz_isotrop_vect,skydomeHeightsNum),(skydomeHeightsNum,skydomeAspectsNum))
                    
                            skydome_shading_isotrop = numpy.zeros((skydomeHeightsNum,skydomeAspectsNum),dtype=numpy.int16)
                            wh = skydome_h0_arr < horiz_isotrop_arr
                            skydome_shading_isotrop[wh] = 1
                            
                            isotropic_shading_factor_pixel = ((1.0-skydome_shading_isotrop)*aux).sum()/aux.sum()
                            isotropic_shading_factor[r,c] = isotropic_shading_factor_pixel
                
                    #expand it from 2D (r,c) to 4D (month,slot,r,c)
                    shp = cDNI_incl_dissag.shape
                    isotropic_shading_factor = numpy.tile(isotropic_shading_factor.flatten(),shp[0]*shp[1]).reshape((shp[0],shp[1],ss_box.height,ss_box.width))
                else:
                    #raster version of inclination or aspect
                    
                    #cast it to 2D array
                    if modul_asp_r_dissag.ndim < 2:
                        aux = numpy.empty((ss_box.height, ss_box.width))
                        aux[:,:] = modul_asp_r_dissag
                        modul_asp_r_dissag = aux
                        sinANV = numpy.sin(modul_asp_r_dissag)
                        cosANV = numpy.cos(modul_asp_r_dissag)
                    if modul_incl_r_dissag.ndim < 2:
                        aux = numpy.empty((ss_box.height, ss_box.width))
                        aux[:,:] = modul_incl_r_dissag
                        modul_incl_r_dissag = aux
                        sinGammaNV = numpy.sin(modul_incl_r_dissag)
                        cosGammaNV = numpy.cos(modul_incl_r_dissag)

                    # here starts the fun  - this must be done for each pixel individually - brute force
                    isotropic_shading_factor=numpy.ones((ss_box.height,ss_box.width))
                    for c in range(0,ss_box.width):
                        for r in range(0,ss_box.height):

                            skydome_incidence_angle_arr = mounting_geom.Rel_sunpos_V1(sinGammaNV[r,c],cosGammaNV[r,c],sinANV[r,c],cosANV[r,c],skydome_sina0_arr,skydome_cosa0_arr,skydome_sinh0_arr,skydome_cosh0_arr)  # calculate incidence angle for all skydome points
                            aux = skydome_incidence_angle_arr * skydome_cosh0_arr
                            
                            horiz_isotrop_vect = horizons_isotropic[:,r,c]
                            horiz_isotrop_arr = numpy.reshape(numpy.tile(horiz_isotrop_vect,skydomeHeightsNum),(skydomeHeightsNum,skydomeAspectsNum))
                    
                            skydome_shading_isotrop = numpy.zeros((skydomeHeightsNum,skydomeAspectsNum),dtype=numpy.int16)
                            wh = skydome_h0_arr < horiz_isotrop_arr
                            skydome_shading_isotrop[wh] = 1
                            
                            isotropic_shading_factor_pixel = ((1.0-skydome_shading_isotrop)*aux).sum()/aux.sum()
                            isotropic_shading_factor[r,c] = isotropic_shading_factor_pixel
                
                    #expand it from 2D (r,c) to 4D (month,slot,r,c)
                    shp = cDNI_incl_dissag.shape
                    isotropic_shading_factor = numpy.tile(isotropic_shading_factor.flatten(),shp[0]*shp[1]).reshape((shp[0],shp[1],ss_box.height,ss_box.width))
                        
            else:
                print 'WARNING: shading correction for isotropic DIF component not implemented for trackers'
                isotropic_shading_factor = 1.0
                
#            print 'TIME: shading diffuse', datetime.datetime.now() - DTs
            DTs = datetime.datetime.now()


            #dissagregate (apply shading)
            DIF_incl_dissag_sh = (cDIF_iso_skydome_dissag*isotropic_shading_factor) + (cDIF_iso_refl_dissag*(1.-isotropic_shading_factor)) + cDIF_horiz_dissag + (cDIF_circ_dissag*(1.-shading_direct))
            DNI_incl_dissag_sh = cDNI_incl_dissag*(1.-shading_direct) #DNI in inlined plane
            GHI_incl_dissag_sh = DIF_incl_dissag_sh + cREFL_incl_dissag + DNI_incl_dissag_sh 
            
            if doDNI:
                DNI_dissag_sh = DNI_dissag * (1.-shading_direct)

            del(horizons,a0_dissag)
            
            
            #chack for nightime angles
            wh = h0_dissag < 0.
            GHI_incl_dissag_sh[wh]=numpy.nan
            DIF_incl_dissag_sh[wh]=numpy.nan
            if doDNI:
                DNI_dissag_sh[wh]=numpy.nan
            
            
            #calculate monthly
            #for MSG the data are in 15 min (0.25 hour). for monthly summariation it hast to be considered
            
            
            GHI_ma=numpy.ma.masked_where(numpy.isnan(GHI_incl_dissag_sh),GHI_incl_dissag_sh)
            GHI_ma_sum=GHI_ma.sum(axis=1)*outtime_step_hours
            if doDNI:
                DNI_ma=numpy.ma.masked_where(numpy.isnan(DNI_dissag_sh),DNI_dissag_sh)
                DNI_ma_sum=DNI_ma.sum(axis=1)*outtime_step_hours
            if doDiffI:
                DIF_ma=numpy.ma.masked_where(numpy.isnan(DIF_incl_dissag_sh),DIF_incl_dissag_sh)
                DIF_ma_sum=DIF_ma.sum(axis=1)*outtime_step_hours
                
#            print 'TIME: post-process', datetime.datetime.now() - DTs
            DTs = datetime.datetime.now()
              
            #write otputs
            var_name = 'mean'
            write_proj_model_output_disaggreg_4dim(NC_out_GHI_filename, var_name, dim0_minmax, dim1_minmax, dim2_minmax, dim3_minmax, GHI_incl_dissag_sh, logger)
            write_proj_model_output_disaggreg_3dim(NC_out_GHI_filename_m, var_name, dim0_minmax, dim2_minmax, dim3_minmax, GHI_ma_sum, logger)
            if doDNI:
                write_proj_model_output_disaggreg_4dim(NC_out_DNI_filename, var_name, dim0_minmax, dim1_minmax, dim2_minmax, dim3_minmax, DNI_dissag_sh, logger)
                write_proj_model_output_disaggreg_3dim(NC_out_DNI_filename_m, var_name, dim0_minmax, dim2_minmax, dim3_minmax, DNI_ma_sum, logger)
            if doDiffI:
                write_proj_model_output_disaggreg_4dim(NC_out_DiffI_filename, var_name, dim0_minmax, dim1_minmax, dim2_minmax, dim3_minmax, DIF_incl_dissag_sh, logger)
                write_proj_model_output_disaggreg_3dim(NC_out_DiffI_filename_m, var_name, dim0_minmax, dim2_minmax, dim3_minmax, DIF_ma_sum, logger)
            
#            if counter>20:break
        logger.info( 'finished seg: %d %d' %( seg_row,seg_col))
    logger.info("finished")
    if mail_notification is not None:
        basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='disagregation finished.' )
    
    sys.exit()
        
