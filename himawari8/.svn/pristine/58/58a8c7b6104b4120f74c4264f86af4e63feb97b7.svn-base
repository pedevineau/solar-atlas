#! /usr/bin/env python
# himawari_model_out_merge_segments
#
# last revision: 06/05/2017
#


import os
#import logging
import math
import sys
import numpy

from general_utils import daytimeconv
from general_utils import basic_mail
from general_utils import latlon
from general_utils import latlon_nctools
from himawari8.sat_model.utils import himawari_nc_latlontools
from himawari8.himawari_postprocess import himawari_merge_common

from general_utils import multiprocess


#logger section
from general_utils.basic_logger import make_logger
logger = make_logger(__name__)
import logging
logger.setLevel(logging.DEBUG)


def calc_15min_stats_for_slots(data_monthly,stats15,percentiles,percentiles_name,aslot_begin,aslot_end,seg_height,seg_width):
    slots=aslot_end-aslot_begin+1
    min15_m_stats_onemonth=numpy.empty((len(stats15), slots, seg_height, seg_width), dtype=numpy.float32)
    for slot in range(aslot_begin, aslot_end+1):
        slot_idx=slot-aslot_begin
        adata=data_monthly[:,slot_idx,:,:]

        #mean
        p_idx=stats15.index('mean')
        min15_m_stats_onemonth[p_idx, slot_idx, :,:]=adata.mean(axis=0)
        
        #percentiles
        per_out_list = scoreatpercentile_multi(adata, percentiles)
        for perc_name in percentiles_name:
            p_idx=stats15.index(perc_name)
            min15_m_stats_onemonth[p_idx, slot_idx, :,:] = per_out_list[p_idx]
    return min15_m_stats_onemonth



def _interpolate(a, b, fraction):
    """Returns the point at the given fraction between a and b, where
    'fraction' must be between 0 and 1.
    """
    return a + (b - a)*fraction;

def scoreatpercentile_multi(a, per_list):
    """Calculate the score at the given 'per' percentile of the
    sequence a.  For example, the score at per=50 is the median.
    
    If the desired quantile lies between two data points, we
    interpolate between them.
    
    """
    values = numpy.sort(a,axis=0)
    
    per_out_list=[]

    num_vals = (values.shape[0] - 1)
    for per in per_list:
        idx = per /100. * num_vals
        if (idx % 1 == 0):
            per_out_list.append(values[idx])
        else:
            per_out_list.append( _interpolate(values[int(idx)], values[int(idx) + 1], idx % 1))
    
    return per_out_list





#------------------------------------------------------------
# main
#------------------------------------------------------------

if __name__ == "__main__":
    mail_notification=['tomas.cebecauer@solargis.com'] #email addresses to send finish notification to, Use '' to avoid mail notification
    
    dfb_begin = daytimeconv.yyyymmdd2dfb('20160101')
    dfb_end = daytimeconv.yyyymmdd2dfb('20161231')
    
    slot_begin, slot_end = 1,144
    slot_time_step_min=10
    
    #processing segments to postprocess (5x5 deg segments)
    segments_to_calculate=latlon.expand_segments([[71, 71, 20, 20]])
    segments_to_calculate=latlon.expand_segments([[0, 0, 21, 21]])
    model_out_dir_pool=[ "/net/loge/data/model_data_himawari/data_output/v20b/"]
#    model_out_dir_pool=[ "/net/loge/data/model_data_himawari/data_output/v20b/","/net/pan/volume2/model_data2/HIMAWARI/data_output/v20b/"]
    file_time_segmentation='month'
    


    version="v20b"
    sat_suff=""
    
    
    res=2./60.  #final value 2/60. == 00:02:00
    buff=3.*res

#    w, e, s, n = 90-buff, 180+buff, 0.-buff, 65.+buff  #pan
#    region_suffix_out='_pan'
    w, e, s, n = 85-buff, 180+buff, -60.-buff, 0.+buff  #pas
    region_suffix_out='_pas'
    
    out_bbox=latlon.bounding_box(w, e, s, n, int(math.floor(((e-w)/res)+0.5)), int(math.floor(((n-s)/res)+0.5)), res)

    #model summary NC files
    overwrite=False
    out_dir = '/data/model_data_himawari/data_output_wgs84/v20b/'
    out_dir = '/home1/model_data_himawari/data_output_wgs84/v20b/'
    
    do_GHI, do_GHIc, do_DNI, do_DNIc = True, True, True, True
    
    
    processing_subseg_size=16

    #parallel processing - parallel each month for 10 min stats 
    ncpus = 12
    
    #do not change!
    percentiles = [1, 10, 25, 50, 75, 90, 99]
    #######################################################

    
    #percentiles_names
    percentiles_name=[]
    for p in percentiles:
        percentiles_name.append("P"+str(p))
    logger.info('processing percentiles:' + str(percentiles_name))


    #multiprocessng
    my_multiproc_funct = multiprocess.multiprocess(ncpus=ncpus, funct=calc_15min_stats_for_slots)
    my_multiproc_funct.init()
    request_queue = my_multiproc_funct.request_queue
    output_queue = my_multiproc_funct.output_queue
    
    
    #make model summary NC files
    result=himawari_merge_common.make_model_output_summary_files(out_dir, do_GHI, do_GHIc, do_DNI, do_DNIc, dfb_min=dfb_begin, dfb_max=dfb_end, slot_min=slot_begin, slot_max=slot_end, slot_time_step_min=slot_time_step_min , bbox=out_bbox, overwrite=overwrite, percentiles_name=percentiles_name, version=version, region_suffix=region_suffix_out)
    logger.info('Creation of output files: '+ str(result))


    year_min=daytimeconv.dfb2ymd(dfb_begin)[0]
    year_max=daytimeconv.dfb2ymd(dfb_end)[0]
    years=year_max-year_min+1
    month_min=1
    month_max=12
    months=month_max-month_min+1
    slots=slot_end-slot_begin+1
    
    #create arrays representing month and year for each dfb - later used for query and summarizing
    dfb_month_arr=numpy.zeros((dfb_end-dfb_begin+1), dtype=numpy.int16)
    dfb_year_arr=numpy.zeros_like(dfb_month_arr)
    for i in range(0, dfb_end-dfb_begin+1):
        y,m,d = daytimeconv.dfb2ymd(dfb_begin+i)
        dfb_month_arr[i]=m
        dfb_year_arr[i]=y
    
    for x_seg, y_seg in segments_to_calculate:
            logger.info("Merging segment r%d c%d" % (y_seg, x_seg))

            # identify path from path pool where model data for given segment reside
            out_data_path = himawari_nc_latlontools.identify_model_output_segment_path(y_seg, x_seg, model_out_dir_pool)
            if out_data_path is None:
                logger.warning("No segmented model output data files found. Skipping segment...")
                continue
            logger.info("Segmented model output data read from: %s" % (out_data_path))
        
            #suffix added to output NETCDF file names
            seg_suffix="_c%d_r%d" % (x_seg, y_seg)
            if sat_suff=='':
                outdata_suffix=seg_suffix
            else:
                outdata_suffix="_%s%s" % (sat_suff, seg_suffix)
            
            outdata_path_dict={"GHIc": out_data_path, "GHI": out_data_path, "DNIc": out_data_path, "DNI": out_data_path}
            

            #make data file dict for given segment
            nc_var_names=['GHI', 'GHIc', 'DNI', 'DNIc']

            seg_bbox_5x5 = latlon.get_5x5_seg_bbox(y_seg, x_seg, res)
            out_files_dict = himawari_nc_latlontools.outdata_existingncfile_dict(dfb_begin, dfb_end, nc_var_names, outdata_path_dict, outdata_suffix, file_time_segmentation=file_time_segmentation)
            
            roll=0
            if (seg_bbox_5x5.center()[0] < 0) and (out_bbox.center()[0] > 0):
                roll=+360
                logger.info( 'Western hemisphere segment, will try to roll the longitudes by 360 deg.')
            if (seg_bbox_5x5.center()[0] > 0) and (out_bbox.center()[0] < 0):
                roll=-360
                logger.info(  'Eastern hemisphere segment, will try to roll the longitudes by 360 deg.')
                
            if roll!=0:                
                seg_bbox_5x5_roll=seg_bbox_5x5.move(lon_shift=roll, lat_shift=0)
                seg_bbox = seg_bbox_5x5_roll.intersect(out_bbox)
            else:
                seg_bbox = seg_bbox_5x5.intersect(out_bbox)

            if seg_bbox is None:
                print 'Segment c%d r%d out of output bbox' %(x_seg, y_seg)
                continue
            
            seg_xmin, seg_xmax, seg_ymin, seg_ymax = out_bbox.pixel_coords_of_bbox(seg_bbox)
            subsegments = seg_bbox.subsegments_by_pxsize_xy(processing_subseg_size, processing_subseg_size)


            #PROCESSING
            ###########################
            #GHI
            ###########################
            if do_GHI:
                logger.info("Processing %d subsegments of GHI"% len(subsegments) )
                seg_GHI_d_m=numpy.empty((years, months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                statss=percentiles_name + ['mean', 'std_d', 'std_m']
                seg_GHI_d_m_stats=numpy.empty((len(statss), months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                stats15=percentiles_name + ['mean']
                seg_GHI_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='GHI'
                counter=0
                
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    subseg_bbox_read=subseg_bbox.move(lon_shift=-roll, lat_shift=0)
                    #relative position of subsegment within segment 

                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, slot_begin, slot_end, subseg_bbox_read, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue
                    
                    GHI_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    #calculate daily sum of irradiation
                    GHI_d_ma=GHI_ma.sum(axis=1)/6.

                    #calculate monthly mean of daily irradiation (for each year)
                    for year in range(year_min, year_max+1):
                        for month in range(month_min, month_max+1):
                            wh=(dfb_year_arr == year) & (dfb_month_arr == month)
                            aux=GHI_d_ma[wh,:,:].mean(axis=0)
                            seg_GHI_d_m[year-year_min, month-month_min, ymin:ymax+1,xmin:xmax+1]=aux
                    
                    #interannual variability of monthly mean of daily sum
                    p_idx=statss.index('std_m')
                    aux=seg_GHI_d_m[:, : , ymin:ymax+1,xmin:xmax+1].std(axis=0,ddof=1)
                    seg_GHI_d_m_stats[p_idx, : , ymin:ymax+1,xmin:xmax+1] = aux
                    
                    #calculate monthly percentiles of daily irradiation (longterm)
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        adata=GHI_d_ma[wh,:,:]
                        p_idx=statss.index('mean')
                        seg_GHI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.mean(axis=0)
                        p_idx=statss.index('std_d')
                        seg_GHI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.std(axis=0,ddof=1)
                        
                        per_out_list = scoreatpercentile_multi(adata, percentiles)
                        for perc_name in percentiles_name:
                            p_idx=statss.index(perc_name)
                            seg_GHI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] = per_out_list[p_idx]
                    

                    #calculate monthly mean and percentiles of 10min irradiance
                    #parallel version
                    seg_height,seg_width = ymax-ymin+1, xmax-xmin+1
                    #put each month processing into request queue
                    for month in range(month_min, month_max+1):
                        wh_m=(dfb_month_arr == month)
                        adata_monthly=GHI_ma[wh_m,:,:,:]
                        month_idx=month-month_min
                        
                        job_id = month_idx
                        args = [adata_monthly,stats15,percentiles,percentiles_name,slot_begin,slot_end,seg_height,seg_width]
                        kwargs = {}
                        request_queue.put((job_id,args,kwargs) )
                    #wait for jobs to finish        
                    request_queue.join()
    
                    #process outputs from 
                    while output_queue.qsize()>0:
                        #get job
                        job = output_queue.get()
                        job_key, job_output = job[0],job[1]
                        if job_output is  None:
                            print "job results empty", job_key 
                        else:
                            month_idx = job_key
                            seg_GHI_15min_m_stats[:,month_idx,:,ymin:ymax+1,xmin:xmax+1] = job_output
                        #remove job from output queue
                        output_queue.task_done() #remove job outputs form queue


                    
                    counter+=1
#                    if counter>3: break

                ncfile= os.path.join(out_dir,'GHI_d_m'+region_suffix_out+'.nc')
                channel = 'GHI_d_m'
                latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_GHI_d_m[:,:,:,:])
                
                ncfile= os.path.join(out_dir,'GHI_d_m_stats'+region_suffix_out+'.nc')
                for channel in statss:
                    p_idx=statss.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_GHI_d_m_stats[p_idx,:,:,:])

                ncfile= os.path.join(out_dir,'GHI_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_GHI_15min_m_stats[p_idx,:,:,:,:])                    
                    
                    
                del (seg_GHI_15min_m_stats, seg_GHI_d_m_stats, seg_GHI_d_m)
                
            ###########################
            #GHIc
            ###########################
            if do_GHIc:
                logger.info("Processing %d subsegments of GHIc"% len(subsegments) )
                stats15=['mean']
                seg_GHIc_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='GHIc'
                counter=0
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    subseg_bbox_read=subseg_bbox.move(lon_shift=-roll, lat_shift=0)
                    
                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, slot_begin, slot_end, subseg_bbox_read, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue

                    GHIc_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    
                    #calculate monthly mean and percentiles of 15min irradiance
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        for slot in range(slot_begin, slot_end+1):
                            slot_idx=slot-slot_begin
                            adata=GHIc_ma[wh,slot_idx,:,:]

                            p_idx=stats15.index('mean')
                            aux=adata.mean(axis=0)
                            seg_GHIc_15min_m_stats[p_idx, month-month_min, slot_idx, ymin:ymax+1,xmin:xmax+1]=aux
                            
                    counter+=1
#                    if counter>3: break

                ncfile= os.path.join(out_dir,'GHIc_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox,seg_GHIc_15min_m_stats[p_idx,:,:,:,:])
                    
                del (seg_GHIc_15min_m_stats)
                
            ###########################
            #DNI
            ###########################
            if do_DNI:
                logger.info("Processing %d subsegments of DNI"% len(subsegments) )
                seg_DNI_d_m=numpy.empty((years, months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                statss=percentiles_name+['mean', 'std_d', 'std_m']
                seg_DNI_d_m_stats=numpy.empty((len(statss), months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                stats15=percentiles_name+['mean']
                seg_DNI_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='DNI'
                counter=0
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    subseg_bbox_read=subseg_bbox.move(lon_shift=-roll, lat_shift=0)
                    
                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, slot_begin, slot_end, subseg_bbox_read, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue

                    DNI_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    #calculate daily sum of irradiation
                    DNI_d_ma=DNI_ma.sum(axis=1)/6.
                    
                    #calculate monthly mean of daily irradiation (for each year)
                    for year in range(year_min, year_max+1):
                        for month in range(month_min, month_max+1):
                            wh=(dfb_year_arr == year) & (dfb_month_arr == month)
                            aux=DNI_d_ma[wh,:,:].mean(axis=0)
                            seg_DNI_d_m[year-year_min, month-month_min, ymin:ymax+1,xmin:xmax+1]=aux
                    
                    #interannual variability of monthly mean of daily sum
                    p_idx=statss.index('std_m')
                    aux=seg_DNI_d_m[:, : , ymin:ymax+1,xmin:xmax+1].std(axis=0,ddof=1)
                    seg_DNI_d_m_stats[p_idx, : , ymin:ymax+1,xmin:xmax+1] = aux
                    
                    #calculate monthly percentiles of daily irradiation (longterm)
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        adata=DNI_d_ma[wh,:,:]
                        p_idx=statss.index('mean')
                        seg_DNI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.mean(axis=0)
                        p_idx=statss.index('std_d')
                        seg_DNI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.std(axis=0,ddof=1)
                        
                        per_out_list = scoreatpercentile_multi(adata, percentiles)
                        for perc_name in percentiles_name:
                            p_idx=statss.index(perc_name)
                            seg_DNI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] = per_out_list[p_idx]
                    
                    
                    #parallel version
                    #calculate monthly mean and percentiles of 10min irradiance
                    seg_height,seg_width = ymax-ymin+1, xmax-xmin+1
                    #put each month processing into request queue
                    for month in range(month_min, month_max+1):
                        wh_m=(dfb_month_arr == month)
                        adata_monthly=DNI_ma[wh_m,:,:,:]
                        month_idx=month-month_min
                        
                        job_id = month_idx
                        args = [adata_monthly,stats15,percentiles,percentiles_name,slot_begin,slot_end,seg_height,seg_width]
                        kwargs = {}
                        request_queue.put((job_id,args,kwargs) )
                    #wait for jobs to finish        
                    request_queue.join()
    
                    #process outputs from 
                    while output_queue.qsize()>0:
                        #get job
                        job = output_queue.get()
                        job_key, job_output = job[0],job[1]
                        if job_output is  None:
                            print "job results empty", job_key 
                        else:
                            month_idx = job_key
                            seg_DNI_15min_m_stats[:,month_idx,:,ymin:ymax+1,xmin:xmax+1] = job_output
                        #remove job from output queue
                        output_queue.task_done() #remove job outputs form queue
                    
                    counter+=1
#                    if counter>3: break
                
                ncfile= os.path.join(out_dir,'DNI_d_m'+region_suffix_out+'.nc')
                channel = 'DNI_d_m'
                latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNI_d_m[:,:,:,:])
                
                ncfile= os.path.join(out_dir,'DNI_d_m_stats'+region_suffix_out+'.nc')
                for channel in statss:
                    p_idx=statss.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNI_d_m_stats[p_idx,:,:,:])

                ncfile= os.path.join(out_dir,'DNI_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNI_15min_m_stats[p_idx,:,:,:,:])
                    
                del (seg_DNI_15min_m_stats, seg_DNI_d_m_stats, seg_DNI_d_m)
    
            ###########################
            #DNIc
            ###########################
            if do_DNIc:
                logger.info("Processing %d subsegments of DNIc"% len(subsegments) )
                stats15=['mean']
                seg_DNIc_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='DNIc'
                counter=0
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    subseg_bbox_read=subseg_bbox.move(lon_shift=-roll, lat_shift=0)
                    
                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, slot_begin, slot_end, subseg_bbox_read, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue
                    DNIc_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    
                    #calculate monthly mean and percentiles of 15min irradiance
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        for slot in range(slot_begin, slot_end+1):
                            slot_idx=slot-slot_begin
                            adata=DNIc_ma[wh,slot_idx,:,:]

                            p_idx=stats15.index('mean')
                            aux=adata.mean(axis=0)
                            seg_DNIc_15min_m_stats[p_idx, month-month_min, slot_idx,  ymin:ymax+1,xmin:xmax+1]=aux
                            
                    counter+=1
#                    if counter>3: break

                ncfile= os.path.join(out_dir,'DNIc_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    try:
                        latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNIc_15min_m_stats[p_idx,:,:,:,:])
                    except:
                        print sys.exc_info()
                        print 'cannot write',ncfile
                    

                del (seg_DNIc_15min_m_stats)

            
            logger.info("Finished segment merge r%d c%d" % (y_seg, x_seg))
            basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='Finished segment merge r%d c%d' % (y_seg, x_seg) )
    logger.info("Finished all segments merge")
    basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='Finished all segments merge' )

    #destroy workers
    my_multiproc_funct.destroy()

