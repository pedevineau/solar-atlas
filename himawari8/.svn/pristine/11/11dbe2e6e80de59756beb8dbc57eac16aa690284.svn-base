#! /usr/bin/env python
# combine merged data (aggregated statistics) from two and more satellites
#
# last revision: 01/04/2017
#


import os
import math

import numpy
import netCDF4

from general_utils import daytimeconv
from general_utils import basic_mail
from general_utils import latlon
from general_utils import latlon_nctools
from general_utils import multiprocess

#logger section
from general_utils.basic_logger import make_logger
logger = make_logger(__name__)
import logging
logging.getLogger().setLevel(logging.DEBUG)



#make model summary NC files
def make_model_output_summary_files(out_dir, do_GHI, do_GHIc, do_DNI, do_DNIc, dfb_min, dfb_max, slot_min, slot_max, bbox, overwrite=False, percentiles_name=[], version=None, region_suffix=''):
	slot_time_step_min = 15
	
	year_min=daytimeconv.dfb2ymd(dfb_begin)[0]
	year_max=daytimeconv.dfb2ymd(dfb_end)[0]
	
	result = True
	if do_GHI:
		#GHI_d_m [year,month,lat,lon] - monthly average of daily sum
		file_name = os.path.join(out_dir,'GHI_d_m'+region_suffix+'.nc')
		description='SolarGIS irradiation - GHI monthly statistics by year, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels=['GHI_d_m']
		img_types=["NC_SHORT"]
		img_units=['Wh']
		img_long_names=['GHI monthly average of daily sum by year']
		novals=[-9.]
		chunksizes=[[1,1,64,64]]
		result&=latlon_nctools.latlon_make_params_year_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, year_min=year_min, year_max=year_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False)


		#GHI_d_m_stats[month,lat,lon] - long term monthly stats of daily value P5, P25, P50, P75, P95, mean, std_d, std_m
		file_name = os.path.join(out_dir,'GHI_d_m_stats'+region_suffix+'.nc')
		description='SolarGIS irradiation - GHI monthly statistics, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels, img_types, img_units, img_long_names, novals, chunksizes = [], [], [], [], [], []
		for perc_name in percentiles_name:#add percentiles
			img_channels.append(perc_name)
			img_types.append("NC_SHORT")
			img_units.append('Wh')
			img_long_names.append('GHI daily sum longterm '+perc_name+' by month')
			novals.append(-9.)
			chunksizes.append([1,64,64])
		img_channels=img_channels+['mean', 'std_d', 'std_m']
		img_types=img_types+["NC_SHORT","NC_SHORT","NC_SHORT"]
		img_units=img_units+['Wh', 'Wh', 'Wh']
		img_long_names=img_long_names+['GHI daily sum longterm mean by month', 'GHI daily sum STD(daily) by month', 'GHI daily sum STD(interannual monthly mean) by month']
		novals=novals+[-9., -9., -9.]
		chunksizes=chunksizes+[[1,64,64],[1,64,64],[1,64,64]]
		result&=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False)


		#GHI_15min_m_stats[month,slot,lat,lon] - long term monthly stats of 15 min value P5, P25, P50, P75, P95, mean
		file_name = os.path.join(out_dir,'GHI_15min_m_stats'+region_suffix+'.nc')
		description='SolarGIS irradiance - GHI monthly statistics by 15 min, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels, img_types, img_units, img_long_names, novals, chunksizes = [], [], [], [], [], []
		for perc_name in percentiles_name:#add percentiles
			img_channels.append(perc_name)
			img_types.append("NC_SHORT")
			img_units.append('W')
			img_long_names.append('GHI 15min longterm '+perc_name+' by month')
			novals.append(-9.)
			chunksizes.append([1,8,64,64])
		img_channels=img_channels+['mean']
		img_types=img_types+["NC_SHORT"]
		img_units=img_units+['W']
		img_long_names=img_long_names+['GHI 15min longterm mean by month']
		novals=novals+[-9.]
		chunksizes=chunksizes+[[1,8,64,64]]
		result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False, slot_represents_center=True, slot_time_step_min=slot_time_step_min)

	
	if do_GHIc:
		#GHIc_15min_m_mean[month,slot,lat,lon] - long term monthly mean of 15 min value
		file_name = os.path.join(out_dir,'GHIc_15min_m_stats'+region_suffix+'.nc')
		description='SolarGIS irradiance - GHIc monthly statistics by 15 min, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels=['mean']
		img_types=["NC_SHORT"]
		img_units=['W']
		img_long_names=['GHIc 15min longterm mean by month']
		chunksizes=[[1,8,64,64]]
		novals=[-9.]
		result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False, slot_represents_center=True, slot_time_step_min=slot_time_step_min)

	
	if do_DNI:
		#DNI_d_m [year,month,lat,lon] - monthly average of daily sum
		file_name = os.path.join(out_dir,'DNI_d_m'+region_suffix+'.nc')
		description='SolarGIS irradiation - DNI monthly statistics by year, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels=['DNI_d_m']
		img_types=["NC_SHORT"]
		img_units=['Wh']
		img_long_names=['DNI monthly average of daily sum by year']
		novals=[-9.]
		chunksizes=[[1,1,64,64]]
		result&=latlon_nctools.latlon_make_params_year_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, year_min=year_min, year_max=year_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False)


		#DNI_d_m_stats[month,lat,lon] - long term monthly stats of daily value P5, P25, P50, P75, P95, mean, std_d, std_m
		file_name = os.path.join(out_dir,'DNI_d_m_stats'+region_suffix+'.nc')
		description='SolarGIS irradiation - DNI monthly statistics, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels, img_types, img_units, img_long_names, novals, chunksizes = [], [], [], [], [], []
		for perc_name in percentiles_name:#add percentiles
			img_channels.append(perc_name)
			img_types.append("NC_SHORT")
			img_units.append('Wh')
			img_long_names.append('DNI daily sum longterm '+perc_name+' by month')
			novals.append(-9.)
			chunksizes.append([1,64,64])
		img_channels=img_channels+['mean', 'std_d', 'std_m']
		img_types=img_types+["NC_SHORT","NC_SHORT","NC_SHORT"]
		img_units=img_units+['Wh', 'Wh', 'Wh']
		img_long_names=img_long_names+['DNI daily sum longterm mean by month', 'DNI daily sum STD(daily) by month', 'DNI daily sum STD(interannual monthly mean) by month']
		novals=novals+[-9., -9., -9.]
		chunksizes=chunksizes+[[1,64,64],[1,64,64],[1,64,64]]
		result&=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False)


		#DNI_15min_m_stats[month,slot,lat,lon] - long term monthly stats of 15 min value P5, P25, P50, P75, P95, mean
		file_name = os.path.join(out_dir,'DNI_15min_m_stats'+region_suffix+'.nc')
		description='SolarGIS irradiance - DNI monthly statistics by 15 min, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels, img_types, img_units, img_long_names, novals, chunksizes = [], [], [], [], [], []
		for perc_name in percentiles_name:#add percentiles
			img_channels.append(perc_name)
			img_types.append("NC_SHORT")
			img_units.append('W')
			img_long_names.append('DNI 15min longterm '+perc_name+' by month')
			novals.append(-9.)
			chunksizes.append([1,8,64,64])
		img_channels=img_channels+['mean']
		img_types=img_types+["NC_SHORT"]
		img_units=img_units+['W']
		img_long_names=img_long_names+['DNI 15min longterm mean by month']
		novals=novals+[-9.]
		chunksizes=chunksizes+[[1,8,64,64]]
		result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False, slot_represents_center=True, slot_time_step_min=slot_time_step_min)
	
	if do_GHIc:
		#GHIc_15min_m_mean[month,slot,lat,lon] - long term monthly mean of 15 min value
		file_name = os.path.join(out_dir,'DNIc_15min_m_stats'+region_suffix+'.nc')
		description='SolarGIS irradiance - DNIc monthly statistics by 15 min, combination of data from more satellites'
		metadata=[['description',description],['projection',"geographic coordinates"]]
		if version is not None:
			metadata.append(['version', version])
		img_channels=['mean']
		img_types=["NC_SHORT"]
		img_units=['W']
		img_long_names=['DNIc 15min longterm mean by month']
		chunksizes=[[1,8,64,64]]
		novals=[-9.]
		result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False, slot_represents_center=True, slot_time_step_min=slot_time_step_min)

	return result




def calculate_sources_weights(sources_dict):
	keys=sources_dict.keys()
	total_years=0
	for key in keys:
		total_years+=sources_dict[key]['year_end']-sources_dict[key]['year_begin']+1
	for key in keys:
		sources_dict[key]['weight']=(sources_dict[key]['year_end']-sources_dict[key]['year_begin']+1)/float(total_years)
#	for key in keys:
#		print key, 'weight', sources_dict[key]['weight']
	return sources_dict


#adapt subset_bbox to the pixels of latlon_bbox (then exact subset can be clipped)
def adapt_subset_bbox(process_bbox, latlon_bbox):
	if process_bbox is None:
		return None
	else:
		process_bbox2 = latlon_bbox.intersect(process_bbox)
		if not(process_bbox.equals(process_bbox2)):
			logger.debug("process_bbox adapted to output bbox")
	return process_bbox2



def _interp_2d(out_time_arr,in_time_arr,in_data):
	
	rr = in_data.shape[1]        
	cc = in_data.shape[2]

	out_time_step_min = out_time_arr[1]-out_time_arr[0]
	in_time_step_min = in_time_arr[1]-in_time_arr[0]

	time_change_ratio = in_time_step_min/out_time_step_min
	
	#extend the in_time_arr and in_data to allow correct interpolation at the tails
	in_time_arr_ext=numpy.hstack([in_time_arr[0]-(in_time_arr[1]-in_time_arr[0]), in_time_arr, in_time_arr[-1]+(in_time_arr[1]-in_time_arr[0])])
	in_data_ext=numpy.vstack([in_data[-1,:,:].reshape((1,rr,cc)),in_data,in_data[0,:,:].reshape((1,rr,cc))]).astype(numpy.float64)
	
	
	#output data matrix
	out_data = numpy.empty((out_time_arr.shape[0],rr,cc))

	#process by pixel	    
	for r in range(0,rr):
	    for c in range(0,cc):
	        in_data_ext_px = in_data_ext[:,r,c]
	        out_data_px = numpy.interp(out_time_arr, in_time_arr_ext, in_data_ext_px)
	        #normalize to get same value as from input 
	        aux=in_data_ext_px[1:-1]
	        wh_in=(aux==aux)
	        wh_out=(out_data_px==out_data_px)
	        if (wh_in.sum() >0) and (wh_out.sum() >0) and ((out_data_px[wh_out]).sum()>0):
	            out_data_px*=aux[wh_in].sum()/((out_data_px[wh_out]).sum()/time_change_ratio)
	        out_data[:,r,c]=out_data_px
	return out_data


def time_interpolate_mtrc_30min(bbox, in_data, multiproc_interp_2d=None):
	# time interpolation arrays
	in_time_arr=numpy.arange(0.25,24.0,0.5) # goes output 30 min slot mapping - slot is centered for each 30 min segment 
	out_time_arr=numpy.arange(0.125,24.0,0.25) # output 15 min slot mapping - slot is centered for each 30 min segment 

	#output (interpolated) array
	mm,dummy,rr,cc = in_data.shape
	out_data = numpy.empty((mm,96,rr,cc), dtype=in_data.dtype)

	if multiproc_interp_2d is None:
		#single processing
		for m in range(0,mm):
			out_data[m,:,:,:]=_interp_2d(out_time_arr,in_time_arr, in_data[m,:,:,:])
	else:
		#multiprocessing
		request_queue = multiproc_interp_2d.request_queue
		output_queue = multiproc_interp_2d.output_queue
		for m in range(0,mm):
			job_id = m
			args = [out_time_arr,in_time_arr, in_data[m,:,:,:]]
			kwargs = {}
			request_queue.put((job_id,args,kwargs) )
 		
 		#wait for jobs to finish		
		request_queue.join()

		#process outputs from 
		while output_queue.qsize()>0:
			#get job
			job = output_queue.get()
			job_key, job_output = job[0],job[1]
			if job_output is  None:
				print "job results empty", job_key 
			else:
				m = job_key
				out_data[m,:,:,:]=job_output
			#remove job from output queue
			output_queue.task_done() #remove job outputs form queue
		
	return out_data

def time_interpolate_mtrc_10min(bbox, in_data, multiproc_interp_2d=None):
	# time interpolation arrays
	in_time_step_dh = 10./60.
	in_time_arr=numpy.arange(in_time_step_dh/2.,24.0,in_time_step_dh) # goes output 30 min slot mapping - slot is centered for each 10 min segment
	out_time_arr=numpy.arange(0.125,24.0,0.25) # output 15 min slot mapping - slot is centered for each 30 min segment 
	#output (interpolated) array
	mm,dummy,rr,cc = in_data.shape
	out_data = numpy.empty((mm,96,rr,cc), dtype=in_data.dtype)

#	for m in range(0,mm):
#		out_data[m,:,:,:]=_interp_2d(out_time_arr,in_time_arr, in_data[m,:,:,:])
	if multiproc_interp_2d is None:
		#single processing
		for m in range(0,mm):
			out_data[m,:,:,:]=_interp_2d(out_time_arr,in_time_arr, in_data[m,:,:,:])
	else:
		#multiprocessing
		request_queue = multiproc_interp_2d.request_queue
		output_queue = multiproc_interp_2d.output_queue
		for m in range(0,mm):
			job_id = m
			args = [out_time_arr,in_time_arr, in_data[m,:,:,:]]
			kwargs = {}
			request_queue.put((job_id,args,kwargs) )
 		
 		#wait for jobs to finish		
		request_queue.join()

		#process outputs from 
		while output_queue.qsize()>0:
			#get job
			job = output_queue.get()
			job_key, job_output = job[0],job[1]
			if job_output is  None:
				print "job results empty", job_key 
			else:
				m = job_key
				out_data[m,:,:,:]=job_output
			#remove job from output queue
			output_queue.task_done() #remove job outputs form queue
	
	return out_data



#------------------------------------------------------------
# main
#------------------------------------------------------------

if __name__ == "__main__":
	mail_notification='tomas.cebecauer@solargis.com' #email addres to send finish notification to, Use '' to avoid mail notification
	
	dfb_begin = daytimeconv.yyyymmdd2dfb('20070101')
	dfb_end = daytimeconv.yyyymmdd2dfb('20161231')	   
	

	sources_dict={\
				  'MTSAT': {'type':'MTSAT','minutes':30, 'suffix':'', 'year_begin': 2007, 'year_end': 2015,'path':'/net/kale/data/model_data_mtsat/data_output_wgs84/v20_2007_2015/'},\
				  'HIM': {'type':'HIM','minutes':10, 'suffix':'', 'year_begin': 2016, 'year_end': 2016,'path':'/net/kale/data/model_data_himawari/data_output_wgs84/v20/'},\
				  }

	version="v20_2007_2016"
	

	#projected NC file params
	res=2./60.  #final value 2/60. == 00:02:00
	buff=3.*res

	w, e, s, n = 90-buff, 180, 0.-buff, 65.+buff  #pan
	region_suffix_out='_pan'
#	w, e, s, n = 85-buff, 180, -60.-buff, 0.+buff  #pas
#	region_suffix_out='_pas'

	latlon_bbox=latlon.bounding_box(w, e, s, n, int(math.floor(((e-w)/res)+0.5)), int(math.floor(((n-s)/res)+0.5)), res)

	#model summary NC files
	overwrite=False

	out_dir = '/data/model_data_himawari/data_output_wgs84/v20_combined_2007_2016/'
#	out_dir = '/home1/model_data_himawari/data_output_wgs84/v20_combined_2007_2016/'
	
	do_GHI, do_GHIc, do_DNI, do_DNIc = True, True, True, True
	
	
	#processing region where to combine data
	#region by 5x5 degree latlon tiles  
	segments_to_calculate=latlon.expand_segments([[59, 59, 7, 7]])
	
	#parallel processing - parallel each month for 10 min stats 
	ncpus = 12
	
	#do not edit!!!
	percentiles = [1, 10, 25, 50, 75, 90, 99]
	aslot_begin, aslot_end = 1,96

	
	#######################################################

	#multiprocessng
	multiproc_interp_2d = multiprocess.multiprocess(ncpus=ncpus, funct=_interp_2d)
	multiproc_interp_2d.init()


	file_suffix=region_suffix_out+'.nc'
	
	#percentiles_names
	percentiles_name=[]
	for p in percentiles:
		percentiles_name.append("P"+str(p))
	logger.info('processing percentiles:' + str(percentiles_name))


	#make model summary NC files
	result=make_model_output_summary_files(out_dir, do_GHI, do_GHIc, do_DNI, do_DNIc, dfb_min=dfb_begin, dfb_max=dfb_end, slot_min=aslot_begin, slot_max=aslot_end , bbox=latlon_bbox, overwrite=overwrite, percentiles_name=percentiles_name, version=version, region_suffix=region_suffix_out)
	logger.info('Creation of output files: '+ str(result))

	sources_dict = calculate_sources_weights(sources_dict)

	year_min=daytimeconv.dfb2ymd(dfb_begin)[0]
	year_max=daytimeconv.dfb2ymd(dfb_end)[0]
	years=year_max-year_min+1
	month_min=1
	month_max=12
	months=month_max-month_min+1
	slots=aslot_end-aslot_begin+1


	#segmented processing
	for x_seg, y_seg in segments_to_calculate:
		seg_bbox = latlon.get_5x5_seg_bbox(y_seg, x_seg, res)
		#adapt segment box to latlongrid
		subset_bbox = adapt_subset_bbox(seg_bbox, latlon_bbox)
		if subset_bbox is None:
			logger.warning("Skipping segment r%d c%d out of output bbox %s" % (y_seg, x_seg, str(latlon_bbox)))
			continue
		logger.info("Combining segment r%d c%d" % (y_seg, x_seg))

		
		if do_GHI:
			dim0_range=[year_min,year_max]
			dim1_range=[1,12]
			logger.info('Processing GHI_d_m' )
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['GHI_d_m','GHI_d_m'+file_suffix,['GHI_d_m']]
			for var_name in in_variab_names:
				totalData=None
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_suff=src_dict['suffix']
					nc_in_mdl_file = nc_in_mdl_file_pref+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
					if totalData is None:
						totalData = aData
					else:
						totalData = numpy.vstack((totalData,aData))
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
	
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['GHI_d_m_stats','GHI_d_m_stats'+file_suffix, percentiles_name+[ 'mean', 'std_d', 'std_m']]
			logger.info('Processing GHI_d_m_stats' )
			for var_name in in_variab_names:
				totalData=None
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_wght=src_dict['weight']
					in_suff=src_dict['suffix']
					nc_in_mdl_file = nc_in_mdl_file_pref+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
					if totalData is None:
						totalData = aData*in_wght
					else:
						totalData += aData*in_wght
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
	
			dim0_range=[1,12]
			dim1_range=[aslot_begin, aslot_end]
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['GHI_%dmin_m_stats','GHI_15min_m_stats'+file_suffix, percentiles_name+[ 'mean']]
			logger.info('Processing GHI_15min_m_stats')
			for var_name in in_variab_names:
				totalData=numpy.zeros((months, slots, subset_bbox.height, subset_bbox.width))
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_wght=src_dict['weight']
					in_suff=src_dict['suffix']
					in_minutes=src_dict['minutes']
					in_type=src_dict['type']
					nc_in_mdl_file = nc_in_mdl_file_pref%(in_minutes)+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
	
					#time interpolation from in satellite to 15 min
	#				logger.debug(in_type+' '+var_name) 
					if in_type == 'MTSAT':
						aData=time_interpolate_mtrc_30min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
					elif in_type == 'HIM':
						aData=time_interpolate_mtrc_10min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
	
					slot_idx_begin = 0
					slot_idx_end = slots
					totalData[:,slot_idx_begin:slot_idx_end,:,:] += aData[:,:,:,:]*in_wght
	
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
			
		if do_GHIc:
			dim0_range=[1,12]
			dim1_range=[aslot_begin, aslot_end]
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['GHIc_%dmin_m_stats','GHIc_15min_m_stats'+file_suffix, [ 'mean']]
			logger.info('Processing GHIc_15min_m_stats')
			for var_name in in_variab_names:
				totalData=numpy.zeros((months, slots, subset_bbox.height, subset_bbox.width))
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_wght=src_dict['weight']
					in_suff=src_dict['suffix']
					in_minutes=src_dict['minutes']
					in_type=src_dict['type']
					nc_in_mdl_file = nc_in_mdl_file_pref%(in_minutes)+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
	
					#time interpolation from in satellite to 15 min 
					if in_type == 'MTSAT':
						aData=time_interpolate_mtrc_30min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
					if in_type == 'HIM':
						aData=time_interpolate_mtrc_10min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
	
	
					slot_idx_begin = 0
					slot_idx_end = slots
					totalData[:,slot_idx_begin:slot_idx_end,:,:] += aData[:,:,:,:]*in_wght
	
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
			
		if do_DNI:
			dim0_range=[year_min,year_max]
			dim1_range=[1,12]
			logger.info('Processing DNI_d_m' )
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['DNI_d_m','DNI_d_m'+file_suffix,['DNI_d_m']]
			for var_name in in_variab_names:
				totalData=None
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_suff=src_dict['suffix']
					nc_in_mdl_file = nc_in_mdl_file_pref+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
					if totalData is None:
						totalData = aData
					else:
						totalData = numpy.vstack((totalData,aData))
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
				
				
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['DNI_d_m_stats','DNI_d_m_stats'+file_suffix, percentiles_name+[ 'mean', 'std_d', 'std_m']]
			logger.info('Processing DNI_d_m_stats' )
			for var_name in in_variab_names:
				totalData=None
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_wght=src_dict['weight']
					in_suff=src_dict['suffix']
					nc_in_mdl_file = nc_in_mdl_file_pref+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
					if totalData is None:
						totalData = aData*in_wght
					else:
						totalData += aData*in_wght
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
	
	
			dim0_range=[1,12]
			dim1_range=[aslot_begin, aslot_end]
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['DNI_%dmin_m_stats','DNI_15min_m_stats'+file_suffix, percentiles_name+[ 'mean']]
			logger.info('Processing DNI_15min_m_stats')
			for var_name in in_variab_names:
				totalData=numpy.zeros((months, slots, subset_bbox.height, subset_bbox.width))
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_wght=src_dict['weight']
					in_suff=src_dict['suffix']
					in_minutes=src_dict['minutes']
					in_type=src_dict['type']
					nc_in_mdl_file = nc_in_mdl_file_pref%(in_minutes)+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
	
					#time interpolation from in satellite to 15 min 
	#				logger.debug(in_type+' '+var_name) 
					if in_type == 'MTSAT':
						aData=time_interpolate_mtrc_30min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
					if in_type == 'HIM':
						aData=time_interpolate_mtrc_10min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
	
	
					slot_idx_begin = 0
					slot_idx_end = slots
					totalData[:,slot_idx_begin:slot_idx_end,:,:] += aData[:,:,:,:]*in_wght
	
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)
			
			
		if do_DNIc:
			dim0_range=[1,12]
			dim1_range=[aslot_begin, aslot_end]
			nc_in_mdl_file_pref, nc_out_mdl_file, in_variab_names = ['DNIc_%dmin_m_stats','DNIc_15min_m_stats'+file_suffix, [ 'mean']]
			logger.info('Processing DNIc_15min_m_stats')
			for var_name in in_variab_names:
				totalData=numpy.zeros((months, slots, subset_bbox.height, subset_bbox.width))
				for src_key in sources_dict.keys():
					src_dict=sources_dict[src_key]
					in_dir=src_dict['path']
					in_wght=src_dict['weight']
					in_suff=src_dict['suffix']
					in_minutes=src_dict['minutes']
					in_type=src_dict['type']
					nc_in_mdl_file = nc_in_mdl_file_pref%(in_minutes)+in_suff+file_suffix
					aData = latlon_nctools.latlon_read_lat_lon_nc_bbox(os.path.join(in_dir, nc_in_mdl_file), var_name, seg_bbox=subset_bbox, interpolate='nearest')
					if aData is None:
						logger.error('Problem reading variable %s from %s' % (var_name, nc_in_mdl_file ))
						continue
	
					#time interpolation from in satellite to 15 min 
					if in_type == 'MTSAT':
						aData=time_interpolate_mtrc_30min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
					if in_type == 'HIM':
						aData=time_interpolate_mtrc_10min(subset_bbox, aData, multiproc_interp_2d=multiproc_interp_2d)
	
	
					slot_idx_begin = 0
					slot_idx_end = slots
					totalData[:,slot_idx_begin:slot_idx_end,:,:] += aData[:,:,:,:]*in_wght
	
				nc_out_mdl_file2 = os.path.join(out_dir,nc_out_mdl_file)
				result &= latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(nc_out_mdl_file2, var_name, subset_bbox,totalData)

			
	logger.info("Finished merged combine "+str(result))
	basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='Finished merged combine ' + str(result) )

	#destroy workers
	multiproc_interp_2d.destroy()
