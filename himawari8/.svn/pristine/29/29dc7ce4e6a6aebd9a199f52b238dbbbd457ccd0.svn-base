#! /usr/bin/env python
# himawari_model_out_merge_segments
#
# last revision: 31/03/2017
#


import os
#import logging
import math
import sys
import numpy
import datetime

from general_utils import daytimeconv
from general_utils import basic_mail
from general_utils import latlon
from general_utils import latlon_nctools
#from mtsat.mtsat_sat_model.mtsat_nc_latlontools import LatLonSatModelOutNcDbFactory
#from mtsat.mtsat_sat_model import mtsat_nc_latlontools
from himawari8.sat_model.utils import himawari_nc_latlontools

from general_utils import multiprocess


#logger section
from general_utils.basic_logger import make_logger
logger = make_logger(__name__)
import logging
logger.setLevel(logging.DEBUG)


def calc_15min_stats_for_slots(data_monthly,stats15,percentiles,percentiles_name,aslot_begin,aslot_end,seg_height,seg_width):
    slots=aslot_end-aslot_begin+1
    min15_m_stats_onemonth=numpy.empty((len(stats15), slots, seg_height, seg_width), dtype=numpy.float32)
    for slot in range(aslot_begin, aslot_end+1):
        slot_idx=slot-aslot_begin
        adata=data_monthly[:,slot_idx,:,:]

        #mean
        p_idx=stats15.index('mean')
        min15_m_stats_onemonth[p_idx, slot_idx, :,:]=adata.mean(axis=0)
        
        #percentiles
        per_out_list = scoreatpercentile_multi(adata, percentiles)
        for perc_name in percentiles_name:
            p_idx=stats15.index(perc_name)
            min15_m_stats_onemonth[p_idx, slot_idx, :,:] = per_out_list[p_idx]
    return min15_m_stats_onemonth


#make model summary NC files
def make_model_output_summary_files(out_dir, do_GHI, do_GHIc, do_DNI, do_DNIc, dfb_min, dfb_max, slot_min, slot_max, bbox, overwrite=False, percentiles_name=[], version=None, region_suffix=''):
    slot_time_step_min = 10
    year_min=daytimeconv.dfb2ymd(dfb_min)[0]
    year_max=daytimeconv.dfb2ymd(dfb_max)[0]
    
    result = True
    if do_GHI:
        #GHI_d_m [year,month,lat,lon] - monthly average of daily sum
        file_name = os.path.join(out_dir,'GHI_d_m'+region_suffix+'.nc')
        description='SolarGIS irradiation - GHI monthly statistics by year'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels=['GHI_d_m']
        img_types=["NC_FLOAT"]
        img_units=['Wh']
        img_long_names=['GHI monthly average of daily sum by year']
        least_significant_digits=[1]
        novals=[-9.]
        chunksizes=[[1,1,64,64]]
        result&=latlon_nctools.latlon_make_params_year_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, year_min=year_min, year_max=year_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits,dims_name_colrow=False)


        #GHI_d_m_stats[month,lat,lon] - long term monthly stats of daily value P5, P25, P50, P75, P95, mean, std_d, std_m
        file_name = os.path.join(out_dir,'GHI_d_m_stats'+region_suffix+'.nc')
        description='SolarGIS irradiation - GHI monthly statistics'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels, img_types, img_units, img_long_names, novals, chunksizes, least_significant_digits = [], [], [], [], [], [], []
        for perc_name in percentiles_name:#add percentiles
            img_channels.append(perc_name)
            img_types.append("NC_FLOAT")
            img_units.append('Wh')
            img_long_names.append('GHI daily sum longterm '+perc_name+' by month')
            novals.append(-9.)
            chunksizes.append([1,64,64])
            least_significant_digits.append(1)
        img_channels=img_channels+['mean', 'std_d', 'std_m']
        img_types=img_types+["NC_FLOAT","NC_FLOAT","NC_FLOAT"]
        img_units=img_units+['Wh', 'Wh', 'Wh']
        img_long_names=img_long_names+['GHI daily sum longterm mean by month', 'GHI daily sum STD(daily) by month', 'GHI daily sum STD(interannual monthly mean) by month']
        novals=novals+[-9., -9., -9.]
        chunksizes=chunksizes+[[1,64,64],[1,64,64],[1,64,64]]
        least_significant_digits=least_significant_digits+[1,1,1]
        result&=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False)


        #GHI_10min_m_stats[month,slot,lat,lon] - long term monthly stats of 30 min value P5, P25, P50, P75, P95, mean
        file_name = os.path.join(out_dir,'GHI_10min_m_stats'+region_suffix+'.nc')
        description='SolarGIS irradiance - GHI monthly statistics by 10 min'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels, img_types, img_units, img_long_names, novals, chunksizes, least_significant_digits = [], [], [], [], [], [], []
        for perc_name in percentiles_name:#add percentiles
            img_channels.append(perc_name)
            img_types.append("NC_FLOAT")
            img_units.append('W')
            img_long_names.append('GHI 30min longterm '+perc_name+' by month')
            novals.append(-9.)
            chunksizes.append([1,8,64,64])
            least_significant_digits.append(1)
        img_channels=img_channels+['mean']
        img_types=img_types+["NC_FLOAT"]
        img_units=img_units+['W']
        img_long_names=img_long_names+['GHI 10min longterm mean by month']
        novals=novals+[-9.]
        chunksizes=chunksizes+[[1,8,64,64]]
        least_significant_digits=least_significant_digits+[1]
        result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False, slot_time_step_min=slot_time_step_min)

    
    if do_GHIc:
        #GHIc_10min_m_mean[month,slot,lat,lon] - long term monthly mean of 30 min value
        file_name = os.path.join(out_dir,'GHIc_10min_m_stats'+region_suffix+'.nc')
        description='SolarGIS irradiance - GHIc monthly statistics by 10 min'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels=['mean']
        img_types=["NC_FLOAT"]
        img_units=['W']
        img_long_names=['GHIc 10min longterm mean by month']
        chunksizes=[[1,8,64,64]]
        least_significant_digits=[1]
        novals=[-9.]
        result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False, slot_time_step_min=slot_time_step_min)

    
    if do_DNI:
        #DNI_d_m [year,month,lat,lon] - monthly average of daily sum
        file_name = os.path.join(out_dir,'DNI_d_m'+region_suffix+'.nc')
        description='SolarGIS irradiation - DNI monthly statistics by year'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels=['DNI_d_m']
        img_types=["NC_FLOAT"]
        img_units=['Wh']
        img_long_names=['DNI monthly average of daily sum by year']
        novals=[-9.]
        least_significant_digits=[1]
        chunksizes=[[1,1,64,64]]
        result&=latlon_nctools.latlon_make_params_year_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, year_min=year_min, year_max=year_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False)


        #DNI_d_m_stats[month,lat,lon] - long term monthly stats of daily value P5, P25, P50, P75, P95, mean, std_d, std_m
        file_name = os.path.join(out_dir,'DNI_d_m_stats'+region_suffix+'.nc')
        description='SolarGIS irradiation - DNI monthly statistics'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels, img_types, img_units, img_long_names, novals, chunksizes, least_significant_digits = [], [], [], [], [], [], []
        for perc_name in percentiles_name:#add percentiles
            img_channels.append(perc_name)
            img_types.append("NC_FLOAT")
            img_units.append('Wh')
            img_long_names.append('DNI daily sum longterm '+perc_name+' by month')
            novals.append(-9.)
            chunksizes.append([1,64,64])
            least_significant_digits.append(1)
        img_channels=img_channels+['mean', 'std_d', 'std_m']
        img_types=img_types+["NC_FLOAT","NC_FLOAT","NC_FLOAT"]
        img_units=img_units+['Wh', 'Wh', 'Wh']
        img_long_names=img_long_names+['DNI daily sum longterm mean by month', 'DNI daily sum STD(daily) by month', 'DNI daily sum STD(interannual monthly mean) by month']
        novals=novals+[-9., -9., -9.]
        chunksizes=chunksizes+[[1,64,64],[1,64,64],[1,64,64]]
        least_significant_digits=least_significant_digits+[1,1,1]
        result&=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False)


        #DNI_10min_m_stats[month,slot,lat,lon] - long term monthly stats of 30 min value P5, P25, P50, P75, P95, mean
        file_name = os.path.join(out_dir,'DNI_10min_m_stats'+region_suffix+'.nc')
        description='SolarGIS irradiance - DNI monthly statistics by 10 min'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels, img_types, img_units, img_long_names, novals, chunksizes, least_significant_digits = [], [], [], [], [], [], []
        for perc_name in percentiles_name:#add percentiles
            img_channels.append(perc_name)
            img_types.append("NC_FLOAT")
            img_units.append('W')
            img_long_names.append('DNI 10min longterm '+perc_name+' by month')
            novals.append(-9.)
            chunksizes.append([1,8,64,64])
            least_significant_digits.append(1)
        img_channels=img_channels+['mean']
        img_types=img_types+["NC_FLOAT"]
        img_units=img_units+['W']
        img_long_names=img_long_names+['DNI 10min longterm mean by month']
        novals=novals+[-9.]
        chunksizes=chunksizes+[[1,8,64,64]]
        least_significant_digits=least_significant_digits+[1]
        result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False, slot_time_step_min=slot_time_step_min)
    
    if do_DNIc:
        #GHIc_10min_m_mean[month,slot,lat,lon] - long term monthly mean of 30 min value
        file_name = os.path.join(out_dir,'DNIc_10min_m_stats'+region_suffix+'.nc')
        description='SolarGIS irradiance - DNIc monthly statistics by 10 min'
        metadata=[['description',description],['projection',"geographic coordinates"]]
        if version is not None:
            metadata.append(['version', version])
        img_channels=['mean']
        img_types=["NC_FLOAT"]
        img_units=['W']
        img_long_names=['DNIc 10min longterm mean by month']
        chunksizes=[[1,8,64,64]]
        least_significant_digits=[1]
        novals=[-9.]
        result&=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=bbox, compression=True, chunksizes=chunksizes, least_significant_digits=least_significant_digits, dims_name_colrow=False, slot_time_step_min=slot_time_step_min)

    return result



def _interpolate(a, b, fraction):
    """Returns the point at the given fraction between a and b, where
    'fraction' must be between 0 and 1.
    """
    return a + (b - a)*fraction;

def scoreatpercentile_multi(a, per_list):
    """Calculate the score at the given 'per' percentile of the
    sequence a.  For example, the score at per=50 is the median.
    
    If the desired quantile lies between two data points, we
    interpolate between them.
    
    """
    values = numpy.sort(a,axis=0)
    
    per_out_list=[]

    num_vals = (values.shape[0] - 1)
    for per in per_list:
        idx = per /100. * num_vals
        if (idx % 1 == 0):
            per_out_list.append(values[idx])
        else:
            per_out_list.append( _interpolate(values[int(idx)], values[int(idx) + 1], idx % 1))
    
    return per_out_list





#------------------------------------------------------------
# main
#------------------------------------------------------------

if __name__ == "__main__":
    mail_notification=['tomas.cebecauer@solargis.com'] #email addresses to send finish notification to, Use '' to avoid mail notification
    
    dfb_begin = daytimeconv.yyyymmdd2dfb('20160101')
    dfb_end = daytimeconv.yyyymmdd2dfb('20161231')
    
    aslot_begin, aslot_end = 1,144

    #processing segments to postprocess (5x5 deg segments)
    segments_to_calculate=latlon.expand_segments([[59, 59, 7, 7]])
    model_out_dir_pool=[ "/net/loge/data/model_data_himawari/data_output/v20/","/net/pan/volume2/model_data2/HIMAWARI/data_output/v20/"]
    file_time_segmentation='month'

    version="v20"
    sat_suff=""
    
    
    res=2./60.  #final value 2/60. == 00:02:00
    buff=3.*res

    w, e, s, n = 90-buff, 180, 0.-buff, 65.+buff  #pan
    region_suffix_out='_pan'
#    w, e, s, n = 85-buff, 180, -60.-buff, 0.+buff  #pas
#    region_suffix_out='_pas'
    
    out_bbox=latlon.bounding_box(w, e, s, n, int(math.floor(((e-w)/res)+0.5)), int(math.floor(((n-s)/res)+0.5)), res)

    #model summary NC files
    overwrite=False
    out_dir = '/data/model_data_himawari/data_output_wgs84/v20/'
#    out_dir = '/home1/model_data_himawari/data_output_wgs84/v20/'
    
    do_GHI, do_GHIc, do_DNI, do_DNIc = True, True, True, True
    
    
    processing_subseg_size=16

    #parallel processing - parallel each month for 10 min stats 
    ncpus = 12
    
    #do not change!
    percentiles = [1, 10, 25, 50, 75, 90, 99]
    #######################################################

    
    #percentiles_names
    percentiles_name=[]
    for p in percentiles:
        percentiles_name.append("P"+str(p))
    logger.info('processing percentiles:' + str(percentiles_name))


    #multiprocessng
    my_multiproc_funct = multiprocess.multiprocess(ncpus=ncpus, funct=calc_15min_stats_for_slots)
    my_multiproc_funct.init()
    request_queue = my_multiproc_funct.request_queue
    output_queue = my_multiproc_funct.output_queue
    
    
    #make model summary NC files
    result=make_model_output_summary_files(out_dir, do_GHI, do_GHIc, do_DNI, do_DNIc, dfb_min=dfb_begin, dfb_max=dfb_end, slot_min=aslot_begin, slot_max=aslot_end , bbox=out_bbox, overwrite=overwrite, percentiles_name=percentiles_name, version=version, region_suffix=region_suffix_out)
    logger.info('Creation of output files: '+ str(result))


    year_min=daytimeconv.dfb2ymd(dfb_begin)[0]
    year_max=daytimeconv.dfb2ymd(dfb_end)[0]
    years=year_max-year_min+1
    month_min=1
    month_max=12
    months=month_max-month_min+1
    slots=aslot_end-aslot_begin+1
    
    #create arrays representing month and year for each dfb - later used for query and summarizing
    dfb_month_arr=numpy.zeros((dfb_end-dfb_begin+1), dtype=numpy.int16)
    dfb_year_arr=numpy.zeros_like(dfb_month_arr)
    for i in range(0, dfb_end-dfb_begin+1):
        y,m,d = daytimeconv.dfb2ymd(dfb_begin+i)
        dfb_month_arr[i]=m
        dfb_year_arr[i]=y
    
    for x_seg, y_seg in segments_to_calculate:
            logger.info("Merging segment r%d c%d" % (y_seg, x_seg))

            # identify path from path pool where model data for given segment reside
            out_data_path = himawari_nc_latlontools.identify_model_output_segment_path(y_seg, x_seg, model_out_dir_pool)
            if out_data_path is None:
                logger.warning("No segmented model output data files found. Skipping segment...")
                continue
            logger.info("Segmented model output data read from: %s" % (out_data_path))
        
            #suffix added to output NETCDF file names
            seg_suffix="_c%d_r%d" % (x_seg, y_seg)
            if sat_suff=='':
                outdata_suffix=seg_suffix
            else:
                outdata_suffix="_%s%s" % (sat_suff, seg_suffix)
            
            outdata_path_dict={"GHIc": out_data_path, "GHI": out_data_path, "DNIc": out_data_path, "DNI": out_data_path}
            

            #make data file dict for given segment
            nc_var_names=['GHI', 'GHIc', 'DNI', 'DNIc']

            seg_bbox_5x5 = latlon.get_5x5_seg_bbox(y_seg, x_seg, res)
            out_files_dict = himawari_nc_latlontools.outdata_existingncfile_dict(dfb_begin, dfb_end, nc_var_names, outdata_path_dict, outdata_suffix, file_time_segmentation=file_time_segmentation)
            

            seg_bbox = seg_bbox_5x5.intersect(out_bbox)
            seg_xmin, seg_xmax, seg_ymin, seg_ymax = out_bbox.pixel_coords_of_bbox(seg_bbox)
            subsegments = seg_bbox.subsegments_by_pxsize_xy(processing_subseg_size, processing_subseg_size)


            #PROCESSING
            ###########################
            #GHI
            ###########################
            if do_GHI:
                logger.info("Processing %d subsegments of GHI"% len(subsegments) )
                seg_GHI_d_m=numpy.empty((years, months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                statss=percentiles_name + ['mean', 'std_d', 'std_m']
                seg_GHI_d_m_stats=numpy.empty((len(statss), months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                stats15=percentiles_name + ['mean']
                seg_GHI_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='GHI'
                counter=0
                
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    #relative position of subsegment within segment 

                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, aslot_begin, aslot_end, subseg_bbox, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue
                    
                    GHI_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    #calculate daily sum of irradiation
                    GHI_d_ma=GHI_ma.sum(axis=1)/6.

                    #calculate monthly mean of daily irradiation (for each year)
                    for year in range(year_min, year_max+1):
                        for month in range(month_min, month_max+1):
                            wh=(dfb_year_arr == year) & (dfb_month_arr == month)
                            aux=GHI_d_ma[wh,:,:].mean(axis=0)
                            seg_GHI_d_m[year-year_min, month-month_min, ymin:ymax+1,xmin:xmax+1]=aux
                    
                    #interannual variability of monthly mean of daily sum
                    p_idx=statss.index('std_m')
                    aux=seg_GHI_d_m[:, : , ymin:ymax+1,xmin:xmax+1].std(axis=0,ddof=1)
                    seg_GHI_d_m_stats[p_idx, : , ymin:ymax+1,xmin:xmax+1] = aux
                    
                    #calculate monthly percentiles of daily irradiation (longterm)
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        adata=GHI_d_ma[wh,:,:]
                        p_idx=statss.index('mean')
                        seg_GHI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.mean(axis=0)
                        p_idx=statss.index('std_d')
                        seg_GHI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.std(axis=0,ddof=1)
                        
                        per_out_list = scoreatpercentile_multi(adata, percentiles)
                        for perc_name in percentiles_name:
                            p_idx=statss.index(perc_name)
                            seg_GHI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] = per_out_list[p_idx]
                    
#                    #calculate monthly mean and percentiles of 10min irradiance
#                    for month in range(month_min, month_max+1):
#                        wh=(dfb_month_arr == month)
##                        print 'month:', month, datetime.datetime.now()
#                        for slot in range(aslot_begin, aslot_end+1):
#                            slot_idx=slot-aslot_begin
#                            adata=GHI_ma[wh,slot_idx,:,:]
#
#                            p_idx=stats15.index('mean')
#                            aux=adata.mean(axis=0)
#                            seg_GHI_15min_m_stats[p_idx, month-month_min, slot_idx, ymin:ymax+1,xmin:xmax+1]=aux
#                            
#                            per_out_list = scoreatpercentile_multi(adata, percentiles)
#                            for perc_name in percentiles_name:
#                                p_idx=stats15.index(perc_name)
#                                seg_GHI_15min_m_stats[p_idx, month-month_min, slot_idx, ymin:ymax+1,xmin:xmax+1] = per_out_list[p_idx]
#

                    #calculate monthly mean and percentiles of 10min irradiance
                    #parallel version
                    seg_height,seg_width = ymax-ymin+1, xmax-xmin+1
                    #put each month processing into request queue
                    for month in range(month_min, month_max+1):
                        wh_m=(dfb_month_arr == month)
                        adata_monthly=GHI_ma[wh_m,:,:,:]
                        month_idx=month-month_min
                        
                        job_id = month_idx
                        args = [adata_monthly,stats15,percentiles,percentiles_name,aslot_begin,aslot_end,seg_height,seg_width]
                        kwargs = {}
                        request_queue.put((job_id,args,kwargs) )
                    #wait for jobs to finish        
                    request_queue.join()
    
                    #process outputs from 
                    while output_queue.qsize()>0:
                        #get job
                        job = output_queue.get()
                        job_key, job_output = job[0],job[1]
                        if job_output is  None:
                            print "job results empty", job_key 
                        else:
                            month_idx = job_key
                            seg_GHI_15min_m_stats[:,month_idx,:,ymin:ymax+1,xmin:xmax+1] = job_output
                        #remove job from output queue
                        output_queue.task_done() #remove job outputs form queue


                    
                    counter+=1
#                    if counter>3: break

                ncfile= os.path.join(out_dir,'GHI_d_m'+region_suffix_out+'.nc')
                channel = 'GHI_d_m'
                latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_GHI_d_m[:,:,:,:])
                
                ncfile= os.path.join(out_dir,'GHI_d_m_stats'+region_suffix_out+'.nc')
                for channel in statss:
                    p_idx=statss.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_GHI_d_m_stats[p_idx,:,:,:])

                ncfile= os.path.join(out_dir,'GHI_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_GHI_15min_m_stats[p_idx,:,:,:,:])                    
                    
                    
                del (seg_GHI_15min_m_stats, seg_GHI_d_m_stats, seg_GHI_d_m)
                
            ###########################
            #GHIc
            ###########################
            if do_GHIc:
                logger.info("Processing %d subsegments of GHIc"% len(subsegments) )
                stats15=['mean']
                seg_GHIc_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='GHIc'
                counter=0
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    
                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, aslot_begin, aslot_end, subseg_bbox, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue

                    GHIc_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    
                    #calculate monthly mean and percentiles of 15min irradiance
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        for slot in range(aslot_begin, aslot_end+1):
                            slot_idx=slot-aslot_begin
                            adata=GHIc_ma[wh,slot_idx,:,:]

                            p_idx=stats15.index('mean')
                            aux=adata.mean(axis=0)
                            seg_GHIc_15min_m_stats[p_idx, month-month_min, slot_idx, ymin:ymax+1,xmin:xmax+1]=aux
                            
                    counter+=1
#                    if counter>3: break

                ncfile= os.path.join(out_dir,'GHIc_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox,seg_GHIc_15min_m_stats[p_idx,:,:,:,:])
                    
                del (seg_GHIc_15min_m_stats)
                
            ###########################
            #DNI
            ###########################
            if do_DNI:
                logger.info("Processing %d subsegments of DNI"% len(subsegments) )
                seg_DNI_d_m=numpy.empty((years, months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                statss=percentiles_name+['mean', 'std_d', 'std_m']
                seg_DNI_d_m_stats=numpy.empty((len(statss), months, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)
                stats15=percentiles_name+['mean']
                seg_DNI_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='DNI'
                counter=0
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    
                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, aslot_begin, aslot_end, subseg_bbox, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue

                    DNI_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    #calculate daily sum of irradiation
                    DNI_d_ma=DNI_ma.sum(axis=1)/6.
                    
                    #calculate monthly mean of daily irradiation (for each year)
                    for year in range(year_min, year_max+1):
                        for month in range(month_min, month_max+1):
                            wh=(dfb_year_arr == year) & (dfb_month_arr == month)
                            aux=DNI_d_ma[wh,:,:].mean(axis=0)
                            seg_DNI_d_m[year-year_min, month-month_min, ymin:ymax+1,xmin:xmax+1]=aux
                    
                    #interannual variability of monthly mean of daily sum
                    p_idx=statss.index('std_m')
                    aux=seg_DNI_d_m[:, : , ymin:ymax+1,xmin:xmax+1].std(axis=0,ddof=1)
                    seg_DNI_d_m_stats[p_idx, : , ymin:ymax+1,xmin:xmax+1] = aux
                    
                    #calculate monthly percentiles of daily irradiation (longterm)
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        adata=DNI_d_ma[wh,:,:]
                        p_idx=statss.index('mean')
                        seg_DNI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.mean(axis=0)
                        p_idx=statss.index('std_d')
                        seg_DNI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] =adata.std(axis=0,ddof=1)
                        
                        per_out_list = scoreatpercentile_multi(adata, percentiles)
                        for perc_name in percentiles_name:
                            p_idx=statss.index(perc_name)
                            seg_DNI_d_m_stats[p_idx, month-month_min, ymin:ymax+1,xmin:xmax+1] = per_out_list[p_idx]
                    
                    
#                    #calculate monthly mean and percentiles of 10min irradiance
#                    for month in range(month_min, month_max+1):
#                        wh=(dfb_month_arr == month)
#                        for slot in range(aslot_begin, aslot_end+1):
#                            slot_idx=slot-aslot_begin
#                            adata=DNI_ma[wh,slot_idx,:,:]
#
#                            p_idx=stats15.index('mean')
#                            aux=adata.mean(axis=0)
#                            seg_DNI_15min_m_stats[p_idx, month-month_min, slot_idx, ymin:ymax+1,xmin:xmax+1]=aux
#                            
#                            per_out_list = scoreatpercentile_multi(adata, percentiles)
#                            for perc_name in percentiles_name:
#                                p_idx=stats15.index(perc_name)
#                                seg_DNI_15min_m_stats[p_idx, month-month_min, slot_idx, ymin:ymax+1,xmin:xmax+1] = per_out_list[p_idx]

                    #parallel version
                    #calculate monthly mean and percentiles of 10min irradiance
                    seg_height,seg_width = ymax-ymin+1, xmax-xmin+1
                    #put each month processing into request queue
                    for month in range(month_min, month_max+1):
                        wh_m=(dfb_month_arr == month)
                        adata_monthly=DNI_ma[wh_m,:,:,:]
                        month_idx=month-month_min
                        
                        job_id = month_idx
                        args = [adata_monthly,stats15,percentiles,percentiles_name,aslot_begin,aslot_end,seg_height,seg_width]
                        kwargs = {}
                        request_queue.put((job_id,args,kwargs) )
                    #wait for jobs to finish        
                    request_queue.join()
    
                    #process outputs from 
                    while output_queue.qsize()>0:
                        #get job
                        job = output_queue.get()
                        job_key, job_output = job[0],job[1]
                        if job_output is  None:
                            print "job results empty", job_key 
                        else:
                            month_idx = job_key
                            seg_DNI_15min_m_stats[:,month_idx,:,ymin:ymax+1,xmin:xmax+1] = job_output
                        #remove job from output queue
                        output_queue.task_done() #remove job outputs form queue
                    
                    counter+=1
#                    if counter>3: break
                
                ncfile= os.path.join(out_dir,'DNI_d_m'+region_suffix_out+'.nc')
                channel = 'DNI_d_m'
                latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNI_d_m[:,:,:,:])
                
                ncfile= os.path.join(out_dir,'DNI_d_m_stats'+region_suffix_out+'.nc')
                for channel in statss:
                    p_idx=statss.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNI_d_m_stats[p_idx,:,:,:])

                ncfile= os.path.join(out_dir,'DNI_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNI_15min_m_stats[p_idx,:,:,:,:])
                    
                del (seg_DNI_15min_m_stats, seg_DNI_d_m_stats, seg_DNI_d_m)
    
            ###########################
            #DNIc
            ###########################
            if do_DNIc:
                logger.info("Processing %d subsegments of DNIc"% len(subsegments) )
                stats15=['mean']
                seg_DNIc_15min_m_stats=numpy.empty((len(stats15),months, slots, seg_bbox.height, seg_bbox.width), dtype=numpy.float32)

                
                nc_var_name='DNIc'
                counter=0
                for subseg_bbox in subsegments:
                    xmin,xmax,ymin,ymax = seg_bbox.pixel_coords_of_bbox(subseg_bbox)
                    
                    logger.debug('processing subsegment %d/%d' % (counter+1,len(subsegments)))
                    data=himawari_nc_latlontools.outdata_nc_read(nc_var_name, out_files_dict, outdata_suffix, dfb_begin, dfb_end, aslot_begin, aslot_end, subseg_bbox, file_time_segmentation=file_time_segmentation)
                    if data is None:
                        logger.warning("No data read for subsegment" )
                        continue
                    DNIc_ma=numpy.ma.masked_where(numpy.isnan(data),data)
                    
                    #calculate monthly mean and percentiles of 15min irradiance
                    for month in range(month_min, month_max+1):
                        wh=(dfb_month_arr == month)
                        for slot in range(aslot_begin, aslot_end+1):
                            slot_idx=slot-aslot_begin
                            adata=DNIc_ma[wh,slot_idx,:,:]

                            p_idx=stats15.index('mean')
                            aux=adata.mean(axis=0)
                            seg_DNIc_15min_m_stats[p_idx, month-month_min, slot_idx,  ymin:ymax+1,xmin:xmax+1]=aux
                            
                    counter+=1
#                    if counter>3: break

                ncfile= os.path.join(out_dir,'DNIc_10min_m_stats'+region_suffix_out+'.nc')
                for channel in stats15:
                    p_idx=stats15.index(channel)
                    try:
                        latlon_nctools.latlon_write_whole_lat_lon_nc_bbox(ncfile, channel, seg_bbox, seg_DNIc_15min_m_stats[p_idx,:,:,:,:])
                    except:
                        print sys.exc_info()
                        print 'cannot write',ncfile
                    

                del (seg_DNIc_15min_m_stats)

            
            logger.info("Finished segment merge r%d c%d" % (y_seg, x_seg))
            basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='Finished segment merge r%d c%d' % (y_seg, x_seg) )
    logger.info("Finished all segments merge")
    basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='Finished all segments merge' )

    #destroy workers
    my_multiproc_funct.destroy()

