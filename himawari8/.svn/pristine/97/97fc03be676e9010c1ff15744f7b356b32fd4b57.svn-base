#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Himawari8 downloader
@author: Milos Korenciak"""

from __future__ import print_function

import datetime as DT
import os
import time
import traceback
from threading import Thread

from himawari8 import data_classes as DC
from himawari8 import slotmapping
from himawari8.utils import *

from general_utils import basic_mail
from general_utils.basic_logger import *
from general_utils.basic_ftp import FTPConnection, GeneratorDrivenThread, FileNotFoundError, GeneralFtpError, \
    file_exists, shell_w_timeout
from general_utils.daytimeconv import date2dfb


logger = make_logger(__name__)
logger.setLevel(11)

# default config ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
CONSTANTS = {
    # 'Local' mirror directories. Will be searched recursively before the core download from FTP. If the correct file(name)
    #  found, the mirror will be used. NOTE: Must be absolute paths on given machine to work!
    "MIRRORS": [
           "/net/himalia/data/HIMAWARI8_OPERATIONAL/",
           "/net/cupid/data/HIMAWARI8_OPERATIONAL",
           "/net/ariel/data/HIMAWARI8_OPERATIONAL",
           "/net/mab/data/HIMAWARI8_OPERATIONAL",
           ],
    # Search these local directories. If the file is there, it is in processing = do not download again!
    "LOCAL_CHECK_EXISTENCE_DIRS": [
        "/data/HIMAWARI8_OPERATIONAL/BACKUP", "/data/HIMAWARI8_OPERATIONAL/CORRUPTED",
        "/data/HIMAWARI8_OPERATIONAL/PROCESSED", "/data/HIMAWARI8_OPERATIONAL/TO_PROCESS",
           ],
    # COMMENT channels you do not want to download. They will be selected through listing
    "CHANNELS_TO_DOWNLOAD": [
        '01',  # VIS047_2000
        '02',  # VIS051_2000
        '03',  # VIS064_2000
        '04',  # VIS086_2000
        '05',  # VIS160_2000
        '06',  # VIS229_2000
        '07',  # IR390_2000
        '08',  # IR620_2000
        '09',  # IR690_2000
        '10',  # IR730_2000
        '11',  # IR860_2000
        '12',  # IR960_2000
        '13',  # IR104_2000
        '14',  # IR112_2000
        '15',  # IR124_2000
        '16',  # IR133_2000
        '18',  # VIS047_1000
        '19',  # VIS051_1000
        '20',  # VIS064_0500
        '21',  # VIS086_1000
    ],
    # Mail the error stacktrace to this people if the downloader crashes
    "EMAIL_RECEIVERS": ['milos.korenciak@solargis.com', 'ioan.ferencik@solargis.com', 'tomas.cebecauer@solargis.com'],
    # Credentials to connect to given FTP
    "HOST": "ftp.bom.gov.au",
    # "HOST": "ftp-reg.cloud.bom.gov.au",  # cloud source
    "USER": 'bom560',
    "PASSWORD": 'S3frD1Ad',
    "FTP_DIRS": ["/register/bom560/gms/"],
    # Where to download the files
    "LOCAL_DESTINATION_DIR": "/data/HIMAWARI8_OPERATIONAL/INCOMING",

    # For downloading, use this count of connections - each in its own thread
    "OVERRIDE_CONNECTIONS_COUNT": None,  # not to override
    # DB connection credentials
    "DB_NAME": "himawari_archive",
    "DB_USER": "sat_oper",
    "DB_PASSWORD": "itNov6",
    "DB_HOST": "localhost",
    # Override the table name for downloaded records (None =default = 'downloaded')
    "DB_TABLE_NAME": None,
    # Latency = download the files old at least this timespan
    "LATENCY": DT.timedelta(0, 20 * 60),
    # Max age = maximum age of file to download; 2016-08-09 was published 2016-04-21 data
    "MAX_AGE": DT.timedelta(10, 0),  # 10 days is maximum age of file to be downloaded from FTP
    "WAIT_BEFORE_NEXT_ATTEMPT": 4,
    "MAX_ATTEMPTS": 4,
    "CONNECTION_TIMEOUT": 60,
}
#
# end of config ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# if you want to tweak the downloader, you probably want to change the last section if __name__ == "__main__":


#
# ### The app logic = working classes
class JustDownloadedElsewhereException(Exception):
    """Exception when another machine is jut downloading tha same file"""
    pass


class GeneratorDrivenThread(Thread):
    """The thread for implementing USER_LIMIT for multiThreaded download"""

    def __init__(self, task_list, fail_list=None):
        """Creates Thread running functions from queue
        :param task_list: list of task in form: [[callable, arg_1_for_callable, ...], ...]
        :param fail_list: list containing args for callable which failed
        :return: None"""
        fail_list = fail_list or []  # mutables cannot be in method call
        assert type(task_list) == list, "Constructor takes LIST only as list.pop is thread safe!"
        self.list_ = task_list
        self.fail_list = fail_list
        super(GeneratorDrivenThread, self).__init__()

    def run(self):
        """Runs the functions from list_ until it is empty"""
        while self.list_:
            execution_data = None
            try:
                execution_data = self.list_.pop()  # take the last element
                function_ = execution_data["function"]
                logger.debug("going to call callback")
                function_(**execution_data)
            except JustDownloadedElsewhereException as e:
                # append once more at the end (= beginning of the list)
                execution_data["postponable_count"] -= 1
                self.list_.insert(0, execution_data)
            except IndexError:  # if self.list_.pop in another thread was before us; or internal function_() error
                if execution_data:
                    self.fail_list.append(execution_data)
            except (SystemError, SystemExit, KeyboardInterrupt) as e:
                self.fail_list.append(execution_data)
                raise e  # Provides Ctrl-C responsive processing
            except Exception as e:
                self.fail_list.append(execution_data)
                logger.error(str(self) + " thread had error: " + str(type(e)) + " : " + str(e))


class Downloader:
    """Class to download the data
    To manipulate this class you need to understand THREADING, as process_one_file method is called in another thread.
    The idea is: __init__() the object + kick-off by download().
    download() perform this: get_file_list() and for each generate"""

    def __init__(self, host, user, password, ftp_dir, local_dir, mirrors, local_check_exisence_dirs=None,
                 connection_limit=None, patterns=None, latency=DT.timedelta(0)):
        """Constructor method for the Downloader"""
        patterns = patterns or ["*.nc"]  # mutables cannot be in method call
        local_check_exisence_dirs = local_check_exisence_dirs or []
        logger.info('Going to silently create the table')
        DC.downloaded.create_table(fail_silently=True)
        DC.database.close()
        logger.debug('Table existence ensured')
        self.f = FTPConnection(host=host, user=user, password=password, connection_limit=connection_limit,
                               timeout=CONSTANTS["CONNECTION_TIMEOUT"])
        self.ftp_dir = ftp_dir
        self.local_dir = local_dir
        self.mirrors = mirrors
        self.patterns = patterns
        self.local_check_exisence_dirs = local_check_exisence_dirs
        self.latency = latency

    def process_one_file(self, file_, anticipated_file_size, postponable_count=0, latency=DT.timedelta(0), **kwargs):
        """Processing of one file: download it and write it to the DB
        :param file_: name of file to download
        :param anticipated_file_size: the presumed size of the file - if the file have the same name and size,
          it is treated as correctly downloaded
        :param postponable_count: the number of times the download of this file can be postponed to the end of task list
          because another thread downloads the same file = now we see {file_}.tmp file
        :param latency: download the files old at least this time
        :return: None"""
        # at 1st - download the file
        logger.debug("1 running process one file for file: " + file_)

        full_filename = os.path.join(self.local_dir, file_)
        # IDE00221.201510090850.nc
        # AAAAAACC.YYYYMMDDHHmm.nc
        channel = file_[6:8]
        channel_name = H08_CHANNEL_NAMES[channel]
        year = int(file_[9:13])
        month = int(file_[13:15])
        day = int(file_[15:17])
        hour = file_[17:19]  # we will need this formatted in string
        minute = file_[19:21]  # we will need this formatted in string
        date_time = DT.datetime(year, month, day, int(hour), int(minute))
        slot = slotmapping.hm2slot(hour, minute)
        dfb = date2dfb(date_time.date())

        # check age - if the file is too old enough, probably BOM published bad data
        if date_time < DT.datetime.utcnow() - CONSTANTS["MAX_AGE"]:
            return

        # check latency - if the file is not old enough, skip it
        if date_time > DT.datetime.utcnow() - latency:
            return

        for mirror in self.mirrors:
            tmp_filename = os.path.join(mirror, file_, ".tmp")
            if file_exists(tmp_filename) and postponable_count > 0:
                raise JustDownloadedElsewhereException("The file " + file_ + " is just downloaded on mirror " + mirror)

        f_downloader = self.f.clone()  # create ftp object (for now no connection is opened)
        f_downloader.get(file_=file_, ftp_dir=self.ftp_dir, local_dir=self.local_dir, mirrors=self.mirrors,
                         anticipated_file_size=anticipated_file_size)  # download the file - if needed, use FTP
        f_downloader.quit_no_exception()  # disconnect

        # process the downloaded file!
        try:
            file_size = os.path.getsize(full_filename)
            logger.debug("2 size get successfully: " + str(file_size))
            ddict = {'file_name': file_, 'datetime': date_time, 'slot': slot, 'dfb': dfb, 'file_size': file_size,
                     'channel_name': channel_name}

            # write to the DB and immediately close!
            try:
                DC.downloaded.bulk_upsert(data=[ddict])
                DC.database.close()
            except DC.pw.PeeweeException as e:
                hostname = os.uname()[1]
                estr = 'Exception "{0}" occurred when writing to database one data file of Himawari 8 ftp download. Other info: {1}'.format(
                    traceback.print_exc(e), str(e))
                logger.error(estr)
                basic_mail.mail_process_message_ssl(sender_from=hostname + "@solargis.com",
                                                    reciever_to=CONSTANTS["EMAIL_RECEIVERS"],
                                                    subject='Himawari8 ftp download error on ' + hostname,
                                                    message=estr)
            logger.info("3 File {} was downloaded and recorded into DB".format(os.path.join(self.ftp_dir, file_)))
        except (SystemError, SystemExit, KeyboardInterrupt) as e:
            raise e  # Provides Ctrl-C responsive processing
        except DC.IntegrityError as e:
            logger.warning(
                "Problem: the record for file " + os.path.join(self.ftp_dir, file_) + " exists yet.\nError " + str(e))
        except (OSError, FileNotFoundError) as e:
            logger.error("File " + os.path.join(self.ftp_dir, file_) + " not get successfully?\nError " + str(e))
        except Exception as e:
            logger.error("Unspecific error occured: " + str(type(e)) + str(e) + "when downloading file " + os.path.join(
                self.ftp_dir, file_))
            raise e

    def get_file_size(self, file_, ftp_dir):
        """Tries to get file size for ftp file_ . If error occurs, return -1 (this in bacis_ftp lib means: ignore
        file size checking)
        :param file_: file in ftp_dir on ftp server
        :param ftp_dir: ftp_dir
        :return: file size in bytes or -1 (=ignore file size checking)"""
        try:
            return self.f.size(file_, ftp_dir)
        except GeneralFtpError:
            logger.warning(
                "Getting file_size for file " + file_ + " was not successful. Fallback to -1. Maybe the server does not support it.")
            return -1

    def get_file_list(self):
        """Coroutine iterating over the files to be downloaded at FTP directory"""
        # Iterate over ftp directory at second
        for pattern in self.patterns:
            try:  # add to chain
                generator = self.f.list_files(ftp_dir=self.ftp_dir, pattern=pattern)
                for entry in generator:
                    # logger.debug("The file processing: " + entry)
                    if not entry.startswith("-"):  # download files only
                        continue
                    file_name = entry.split()[-1]  # get entry name only
                    ftp_file_size = int(entry.split()[4])

                    for check_dir in self.local_check_exisence_dirs:
                        if file_exists(os.path.join(check_dir, file_name)):
                            break
                    else:  # this is for..else; is run only if the break is not used
                        yield file_name,ftp_file_size
            except GeneralFtpError as e:
                logger.error("*********\nProblem - it was even not possible to list the files!\nError: " + str(type(e)) + str(e))
                # raise e  # silenced - we just do the best effort, we informed FTP is not responsible
        DC.database.close()

    def download(self):
        """Method to download the data and write info about them to the DB"""
        # files = ['IDE00201.201511040410.nc', 'IDE00201.201511040420.nc',]

        # ## This is inspired by the FTPConnection.get_in_threads_multiple
        task_list = []
        for file_name, ftp_file_size in self.get_file_list():
            task_list.append({"function": self.process_one_file, "file_": file_name, "latency": self.latency,
                              "anticipated_file_size": ftp_file_size, "postponable_count": 1})
        # optimize the download order; oldest first!
        task_list = sorted(task_list, key=lambda x: x["file_"].split(".")[1], reverse=True)

        fail_list = []
        worker_list = []
        self.f.quit_no_exception()  # we can now close the initial listing connection

        for _ in range(self.f.get_connection_limit()):
            worker = GeneratorDrivenThread(task_list=task_list, fail_list=fail_list)
            logger.debug("starting " + str(worker))
            worker_list.append(worker)
            worker.start()

        for worker in worker_list:
            try:
                while worker.isAlive(): # Waiting for the thread to finish
                    worker.join(2)
            except (SystemError, SystemExit, KeyboardInterrupt) as e:
                while task_list:
                    task_list.pop()
                raise e  # Provides Ctrl-C responsive processing

        if fail_list:
            logger.error("This files were not downloaded (see logs above): " + str(fail_list))
        else:
            logger.info("All files were downloaded correctly!")


def is_running(name=None, ipid=os.getpid()):
    """Checks is the python  script "name" is running. Basically this functions should be used
    from within the same script
    If the script is running:
        returns True, pid, string representing the running time in format [[dd-]hh:]mm:ss
    else
        If is not running returns False, None, None

    @args:
        @name, str, the name of program|script
        @ipid, int, the rocess id of the"""
    if not os.path.isabs(name):
        raise ValueError, 'The script name "%s" is not an absolute path' % name
    py_processes = os.popen("ps aux |grep python").read()
    exists, pid, start_time_string = False, None, None
    for pline in py_processes.splitlines():
        if name in pline:
            pid = int(pline.rsplit()[1])
            if pid != ipid:
                start_time_string = os.popen('ps -p %s -o etime=' % pid).read().strip()
                exists = True
                break
        if exists:
            break
    return exists, pid, start_time_string


def main(main_file_path):
    """If run from the console"""
    if not CONSTANTS["FTP_DIRS"]:
        raise Exception("""You are going to download no channels! This is not supported! Uncoment some of them!""")

    # ## Process locking - The process must be SINGLETON = max 1 instance in any time!
    hostname = os.uname()[1]
    try:
        logger.info('Checking if %s is running already...' % main_file_path)
        ipid = os.getpid()
        isrunning, pid, start_s_time = is_running(main_file_path, ipid)
        if isrunning:
            if '-' in start_s_time:  # script is running for more than one day, send message
                sday, stime = start_s_time.split('-')
                basic_mail.mail_process_message_ssl(sender_from=hostname + "@solargis.com",
                                                    reciever_to=CONSTANTS["EMAIL_RECEIVERS"],
                                                    subject='Himawari ftp download warning on ' + hostname,
                                                    message='The script {} is running for {} day(s) and {} on {}'.format(
                                                        __file__, sday, stime, hostname))
            logger.error('The script is already running... bailing out!')
            sys.exit(1)

        # set the custom table name in the database
        DC.downloaded._meta.db_table = CONSTANTS["DB_TABLE_NAME"] \
            if CONSTANTS["DB_TABLE_NAME"] is not None else "downloaded"
        DC.database.initialize(DC.PostgresqlDatabase(CONSTANTS["DB_NAME"], user=CONSTANTS["DB_USER"],
                                                     password=CONSTANTS["DB_PASSWORD"], host=CONSTANTS["DB_HOST"]))
        # DC.database.initialize(DC.SqliteDatabase("small_db.sqlite"))

        # set files to be downloaded
        if not CONSTANTS["CHANNELS_TO_DOWNLOAD"]:
            raise Exception("""You are going to download no channels! This is not supported! Uncoment some of them!""")
        patterns = []
        for channel_no in CONSTANTS["CHANNELS_TO_DOWNLOAD"]:
            patterns.append("IDE002" + channel_no + "*.nc")
        logger.debug("Downloader - go go go!")

        # expand mirrors
        MIRRORS = []
        for mirror_dir in CONSTANTS["MIRRORS"]:
            try:
                returncode_, stdout, stderr_, timeouted_ = shell_w_timeout(
                    ["find", mirror_dir, "%s", "-maxdepth", "4", "-type", "d"], 4 * 60)
                if (not stdout) or timeouted_:
                    logger.error("Problem to list the mirror %s - no stdout", mirror_dir)
                MIRRORS.extend((line.strip() for line in stdout.splitlines() if line.startswith("/")))
            except OSError as e:
                logger.error("Problem to list the mirror %s error : %s : %s ", mirror_dir, type(e), e)

        # expand local directories
        LOCAL_CHECK_EXISTENCE_DIRS = []
        for dir_ in CONSTANTS["LOCAL_CHECK_EXISTENCE_DIRS"]:
            for dirpath, _, _ in os.walk(dir_):
                LOCAL_CHECK_EXISTENCE_DIRS.append(dirpath)

        for ftp_dir in CONSTANTS["FTP_DIRS"]:
            d = Downloader(host=CONSTANTS["HOST"], user=CONSTANTS["USER"], password=CONSTANTS["PASSWORD"],
                           ftp_dir=ftp_dir, local_dir=CONSTANTS["LOCAL_DESTINATION_DIR"], mirrors=MIRRORS,
                           local_check_exisence_dirs=LOCAL_CHECK_EXISTENCE_DIRS, latency=CONSTANTS["LATENCY"],
                           connection_limit=CONSTANTS["OVERRIDE_CONNECTIONS_COUNT"], patterns=patterns)
            error = None
            for attemptNo in range(CONSTANTS["MAX_ATTEMPTS"]):  # try MAX_ATTEMPTS to download without IO errors
                try:
                    d.download()
                    break
                except (StandardError, GeneralFtpError) as e:
                    logger.warning("The grace attempt No. {}. Error gracefully forgiven type: {}, {}", attemptNo,
                                   type(e), e)
                    error = e
                    time.sleep(CONSTANTS["WAIT_BEFORE_NEXT_ATTEMPT"])
            else:  # if MAX_ATTEMPTS run out and was not enough
                logger.error("Last grace attempt lost. Error type: {}, {}", type(e), e)
                raise error  # if the MAX_ATTEMPTS was not enough to download the files needed, raise the error

            logger.debug("Downloader - finished without exceptions")
    except Exception as e:
        estr = '''Exception "{}" occurred on Himawari 8 ftp download
                    Host: {}.
                    Exception: {}
                    Exception type: {}'''.format(traceback.print_exc(e), hostname, str(e), str(type(e)))
        logger.error(estr)
        basic_mail.mail_process_message_ssl(sender_from=hostname + "@solargis.com",
                                            reciever_to=CONSTANTS["EMAIL_RECEIVERS"],
                                            subject='Himawari8 ftp download error on ' + hostname,
                                            message=estr)
        sys.exit(1)


if __name__ == "__main__":
    main(os.path.abspath(__file__))
