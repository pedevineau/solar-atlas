#! /usr/bin/env python
'''
Created on Aug 24, 2009
Updated in Oct 7, 2016 (isotropic)

@author: tomas
disaggregation of lowres GHI and DNI to highres inclined surface - PV version
inputs: DNI, GHI monthly time slot percentiles
    Era Temperatures monthly means (5x5 degree tiles)
    horizons (5x5 degree tiles)
output:
    highres 5x5 deg. PV output on inclined or 2-axis tracker (considering angular and temperature loses and high resolution shadowing)    
'''

from string import zfill
import os, sys
import math

import numpy
import netCDF4

from general_utils import latlon_nctools
from general_utils import latlon

from general_utils import mounting_geom
from general_utils import daytimeconv
from general_utils import basic_mail
import general_utils.solar_geom_v5 as solar_geom
import datetime
from rast_model_postprocess import disaggregate_common

#logger section
from general_utils.basic_logger import make_logger
logger = make_logger(__name__)
import logging
logging.getLogger().setLevel(logging.DEBUG)



def make_model_output_disaggreg_ms_latlon(file_name, latlon_bbox, overwrite = False, slot_min=10, slot_max=80, logger=None, version=None):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return False
    
    #[month,slot,row,col] - long term monthly stats of 15 min value mean
    description='solargis PV model output  monthly statistics by 15 min dissagregated by terrain'
    metadata=[['description',description],['projection',"geographic coordinates"]]
    if version is not None:
        metadata.append(['version', version])
    img_channels=['mean']
    img_types=["NC_SHORT"]
    img_units=['W']
    img_long_names=['15min longterm mean by month']
    chunksizes=[[1,1,128,128]]
    novals=[-9.]
    result=latlon_nctools.latlon_make_params_month_slot_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, tslot_min=slot_min, tslot_max=slot_max, nc_extent=latlon_bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False, slot_represents_center=True)
    
    logger.info('Create dissagreg output grid NetCDF: '+str(result))
    
    if result==False:
        logger.error('Failed to create dissagreg output grid NetCDF')
        return False
        
    return True

def make_model_output_disaggreg_m_latlon(file_name, latlon_bbox, overwrite = False, logger=None, version=None):
    if (file_name is None) or (file_name==''):
        logger.error( "No NC filename set")
        return False
    
    #[month,row,col] - long term monthly stats of 15 min value mean
    description='solargis PV model output  monthly statistics by 15 min dissagregated by terrain'
    metadata=[['description',description],['projection',"geographic coordinates"]]
    if version is not None:
        metadata.append(['version', version])
    img_channels=['mean']
    img_types=["NC_SHORT"]
    img_units=['W']
    img_long_names=['daily sum of PV longterm mean by month']
    chunksizes=[[1,128,128]]
    novals=[-9.]
    result=latlon_nctools.latlon_make_params_month_lat_lon_nc(nc_file_name=file_name, metadata=metadata, force_overwrite=overwrite, img_channels=img_channels, img_types=img_types, img_units=img_units,img_long_names=img_long_names, novals=novals, nc_extent=latlon_bbox, compression=True, chunksizes=chunksizes, dims_name_colrow=False)
    
    logger.info('Create dissagreg output grid NetCDF: '+str(result))
    
    if result==False:
        logger.error('Failed to create dissagreg output grid NetCDF')
        return False
        
    return True



def make_lat_lon_grids(abbox):
    lons=abbox.longitudes()
    lats=abbox.latitudes()
    lon_grid = numpy.zeros((abbox.height,abbox.width),dtype=numpy.float32)
    lat_grid = numpy.zeros((abbox.height,abbox.width),dtype=numpy.float32)
    for c in range (0, abbox.width):
        lat_grid[:,c]=lats
    for r in range (0, abbox.height):
        lon_grid[r,:]=lons
    return lat_grid, lon_grid


#def make_LAT_grid_time_r(slot_min,slot_max,longitudes_2d, latitudes_2d):
#    #calculate MSG scan time offset
##    v_lonlat2toffset_h = numpy.vectorize(mfg_geom.lonlat2toffset_h)
##    msg_time_offset_2d = v_lonlat2toffset_h(longitudes_2d, latitudes_2d)
##    msg_time_offset_2d[msg_time_offset_2d<0] = numpy.nan
#
#    rows = longitudes_2d.shape[0]
#    cols = longitudes_2d.shape[1]
#    
#    LAT=numpy.empty((12,slot_max-slot_min+1,rows,cols), dtype=numpy.float32)
#    longitudes_LAT_constant_2d = ( (longitudes_2d)/15. )
#    
#    ET_2d = numpy.empty((rows,cols), dtype=numpy.float32)
#
#    for month_idx in range(0,11+1):
#        doy=daytimeconv.month_representativedoys[0][month_idx+1]
#        ET_2d[:,:]= solar_geom.perturbation(doy)
#        for slot in range(slot_min, slot_max+1):
#            slot_idx = slot - slot_min
#            utc=(slot/4.) - 0.125
#
#
#            LAT[month_idx, slot_idx, :,:] = utc + ET_2d + longitudes_LAT_constant_2d
#
#    del (ET_2d, longitudes_LAT_constant_2d)
#    res=((LAT - 12)*15)*math.pi/180
#    res[res>math.pi]-=2*math.pi
#    return res

def make_LAT_grid_time_min15_r(longitudes_2d, latitudes_2d):
    #calculate MSG scan time offset
#    v_lonlat2toffset_h = numpy.vectorize(mfg_geom.lonlat2toffset_h)
#    msg_time_offset_2d = v_lonlat2toffset_h(longitudes_2d, latitudes_2d)
#    msg_time_offset_2d[msg_time_offset_2d<0] = numpy.nan

    rows = longitudes_2d.shape[0]
    cols = longitudes_2d.shape[1]
    
    LAT=numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    longitudes_LAT_constant_2d = ( (longitudes_2d)/15. )
    
    ET_2d = numpy.empty((rows,cols), dtype=numpy.float32)

    for month_idx in range(0,11+1):
        doy=daytimeconv.month_representativedoys[0][month_idx+1]
        ET_2d[:,:]= solar_geom.perturbation(doy)
        for slot in range(1, 96+1):
            slot_idx = slot -1
            utc=(slot/4.) - 0.125
#            utc_h=daytimeconv.dh2hms(utc)[0]  
#            utc_m=daytimeconv.dh2hms(utc)[1]  
#            utc=utc_h+utc_m/60.
#            utc_msg_2d= msg_time_offset_2d + utc

            LAT[month_idx, slot_idx, :,:] = utc + ET_2d + longitudes_LAT_constant_2d

    del (ET_2d, longitudes_LAT_constant_2d)
    res=((LAT - 12)*15)*math.pi/180
    res[res>math.pi]-=2*math.pi
    return res



#def make_declin_grid(year, longitudes_2d, slot_min, slot_max):
#    rows = longitudes_2d.shape[0]
#    cols = longitudes_2d.shape[1]
#    
#    declin=numpy.empty((12,slot_max-slot_min+1,rows,cols), dtype=numpy.float32)
#
#    b=[0, 0.0064979, 0.4059059, 0.0020054, -0.0029880, -0.0132296, 0.0063809, 0.0003508]
#    year_dif = year - 1957
#    n0 = 78.8946 + (0.2422 * year_dif) - int(0.25 * year_dif)
#    t1 = -0.5 - n0 - (longitudes_2d/(360))
#    omega0 = (math.pi*2.)/365.2422
#
#    for month_idx in range(0,11+1):
#        doy=daytimeconv.month_representativedoys[0][month_idx+1]
#        omegat = omega0 * (doy + t1)
#        decl = b[1] + b[2]*numpy.sin(omegat) + b[3]*numpy.sin(2.*omegat) + b[4]*numpy.sin(3.*omegat) + b[5]*numpy.cos(omegat) + b[6]*numpy.cos(2.*omegat) + b[7]*numpy.cos(3.*omegat)
#        for slot in range(slot_min, slot_max+1):
#            slot_idx = slot - slot_min
#            declin[month_idx, slot_idx, :,:] = decl
#    del (t1, omegat, decl)
#    return declin

def make_sunposit_grids_min15(lowres_bbox):
    latitude_2d, longitude_2d = make_lat_lon_grids(lowres_bbox)

    time_r = make_LAT_grid_time_min15_r(longitude_2d, latitude_2d)
    declin_grid = disaggregate_common.make_declin_grid_min15(2006, longitude_2d)

    rows = latitude_2d.shape[0]
    cols = latitude_2d.shape[1]

    sinfi_2d = numpy.sin(latitude_2d*math.pi/180)
    cosfi_2d = numpy.cos(latitude_2d*math.pi/180)

    del(latitude_2d, longitude_2d)
    sinfi = numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    cosfi = numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    for month_idx in range(0,11+1):
        for slot in range(1, 96+1):
            slot_idx = slot - 1
            sinfi[month_idx, slot_idx, :,:] = sinfi_2d
            cosfi[month_idx, slot_idx, :,:] = cosfi_2d
    del (sinfi_2d,cosfi_2d )
    
#    epsilon=0.000001
    sinde = numpy.sin(declin_grid)
    
    sinh0 = (sinfi*sinde) + (cosfi*numpy.cos(declin_grid)*numpy.cos(time_r))
    del(declin_grid)
    h0_r = numpy.arcsin(sinh0)
    cosh0 = numpy.cos(h0_r)
    cecl=cosfi*cosh0
    del (cosfi, cosh0 )
    a0_r=numpy.empty((12,96,rows,cols), dtype=numpy.float32)
    a0_r[:,:,:,:] = math.pi                #toto je pre J a S pol - nie je definovana - da sa nahradit "time in radians" ???
    wh1 = numpy.abs(cecl) >= 0.001
    
    cosas = ((sinfi[wh1]*sinh0[wh1]) - sinde[wh1])/(cecl[wh1])
    cosas[cosas>1.] =1.
    cosas[cosas<-1.] =-1.
    a0_r[wh1]=math.pi - numpy.arccos(cosas)
    del(cosas, sinfi, sinh0, sinde, cecl)
    wh1 = time_r > 0
    a0_r[wh1] =  - a0_r[wh1]           # correction 360 deg
    a0_r = a0_r + math.pi               # correction to have a0 in range from -180 to 180
    wh1=a0_r > math.pi
    a0_r[wh1] = a0_r[wh1] - (2*math.pi)

    #refraction correction
    h0_r2 = h0_r*h0_r
    delta_h0refr = 0.061359*(0.1594+(1.1230*h0_r)+(0.065656*h0_r2))/(1.+(28.9344*h0_r)+(277.3971*h0_r2))
    h0_r += delta_h0refr
    
    del(time_r,delta_h0refr)
    return([a0_r,h0_r])


def _interp_2d(out_time_arr,in_time_arr_ext,adata,extrapolate_size=1,normalize=True):
    adata=adata.copy()
    rr=    adata.shape[1]        
    cc=    adata.shape[2]
    res=numpy.empty((out_time_arr.shape[0],rr,cc))    
#    adata=numpy.roll(adata,shift=-1,axis=0)
    adata=numpy.vstack([adata[-extrapolate_size:,:,:],adata,adata[:extrapolate_size,:,:]])
    adata=adata.astype(numpy.float64)
    for r in range(0,rr):
        for c in range(0,cc):
            adat = adata[:,r,c]
            odat = numpy.interp(out_time_arr, in_time_arr_ext, adat)
            if normalize:
                aux=adat[extrapolate_size:-extrapolate_size]
                wh_in=(aux==aux)
                wh_out=(odat==odat)
                if (wh_in.sum() >0) and (wh_out.sum() >0) and ((odat[wh_out]).sum()>0):
                    odat*=aux[wh_in].sum()/((odat[wh_out]).sum()/2.)
            res[:,r,c]=odat
    return res







# Equation for c-Si,a-Si CdTe and CIS  
def PVModule(P_STC,Gin,Tin,ModuleType):
    Tstc=25.
    T=Tin-Tstc
    G=Gin/1000.
    G[G<=0]=1e-10
    lG=numpy.log(G)
    lG2=numpy.power(lG,2) 
    
    if ModuleType in ['CSI',1]:# Crystalline Silicon
#        logger.debug('using Crystalline Silicon')
        k_MT=[0, -0.017162, -0.04028, -0.00468, 1.48e-4, 1.69e-4, 5.0e-6]
    if ModuleType in ['CDTE',3]:#CdTe
#        logger.debug('using CdTe')
        k_MT=[0, -0.103251, -0.040446, -0.001667, -0.002075, -0.001445, -0.000023]
    if ModuleType in ['CIS',4]:#CIS
#        logger.debug('using CIS')
        k_MT=[0, -0.005521, -0.038492, -0.003701, -0.000899, -0.001248, 0.000001]
    if ModuleType in ['ASI',2]:# Amorphous Silicon
        k_MT=[0, -0.017162, -0.04028, -0.00468, 1.48e-4, 1.69e-4, 5.0e-6]
        T=T/2.2      
    return (G*P_STC*(1.+((k_MT[1]*lG) + (k_MT[2]*lG2) + (k_MT[3]*T) + (k_MT[4]*T*lG) + (k_MT[5]*T*lG2) + (k_MT[6]*numpy.power(T,2)))))


# Equation for c-Si,a-Si CdTe and CIS  
def aSicorectorMonthly(Gin,Tin):
    MinANTemp=36
    Gin=Gin.copy()
    Gin[Gin!=Gin]=0
    Tin=Tin.copy()
    Tin[Tin!=Tin]=MinANTemp
    Tin[Tin<MinANTemp]=MinANTemp
    percs=Gin.shape[0]
    months=Gin.shape[1]
    rows=Gin.shape[3]
    cols=Gin.shape[4]
    aSi_corr=numpy.empty((percs,months,rows,cols))
    aSi_corr[:,:,:,:]=1.
    for i in range(0,2):
        for month_idx in range(months):
            for perc_idx in range(percs):
                perc_prev_idx=percs-1
                if perc_idx==-1:
                        month_prev_idx=month_idx-1
                else:
                        month_prev_idx=month_idx+i*0
                aSi_corr[perc_idx,month_idx,:,:]=aSicorector(Gin[perc_idx,month_idx,:,:,:],Tin[perc_idx,month_idx,:,:,:],aSi_corr[perc_prev_idx,month_prev_idx,:,:])
    return aSi_corr
            

def aSicorector(Gin,Tin,aSi_corr):
    tms2percs=365/(12.*7.)
    UppEff=1.04
    LowEff=0.94
    MinANTemp=36
    LS_Coeff=-1.5*10**-7 
    AN_Coeff=1.3*10**-6    
    dnLS=Gin.sum(axis=0)*LS_Coeff
    dnAN=(Tin-MinANTemp).sum(axis=0)*AN_Coeff
    dnAN[dnAN!=dnAN]=0.
    Tinmax=10*(Tin.max(axis=0)-MinANTemp)+1
    wh=dnAN>0
    dnLS[wh]=dnLS[wh]/Tinmax[wh]
    dnLS[dnLS!=dnLS]=0

    dTot=dnLS+dnAN
    wh=dTot>0
    proxim=numpy.empty_like(aSi_corr)
    proxim[wh]=(UppEff-aSi_corr[wh])/(UppEff-LowEff)
    aSi_corr[wh]+=tms2percs*(dTot[wh]*proxim[wh]*5)
    wh=dTot<0
    proxim[wh]=(aSi_corr[wh]-LowEff)/(UppEff-LowEff)
    aSi_corr[wh]+=tms2percs*(dTot[wh]*proxim[wh]*2)

    aSi_corr[aSi_corr>UppEff]=UppEff
    aSi_corr[aSi_corr<LowEff]=LowEff
    return aSi_corr
    

def percentiles_weights_dict(percentiles):
    if len(percentiles)==0:
        return {}
    if len(percentiles)==1:
        return {percentiles[0]:1.0}
    
    #make sorted percentiles
    spercentiles=list(percentiles)
    spercentiles.sort()

    if spercentiles[0] < 0:
        return None
    if spercentiles[-1] > 100:
        return None

    percentile_wghts={}
    for indx in range(0,len(spercentiles)):
        if indx==0:
            first_half=spercentiles[indx]-0
        else:
            first_half=(spercentiles[indx]-spercentiles[indx-1])/2.
            
        if indx==(len(spercentiles)-1):
            second_half=100-spercentiles[indx]
        else:
            second_half=(spercentiles[indx+1]-spercentiles[indx])/2.
        
        weight=(first_half+second_half)/100.
        percentile_wghts[spercentiles[indx]]=weight
    
    return percentile_wghts

def diffinc_PerezFast_shadingGcomponents_percentiles_GHInormalized(GHI_perc, GHI_mean, DNI_perc, h0, GammaN, Albedo, sinDeltaexp, percentiles, doPVAngularCorr = True):
    #this is "percentiles" version
    #returns components of GHIincl: 
    # cDIF_iso_skydome, cDIF_iso_refl, cDIF_horiz, cDIF_circ, cREFL_incl, cDNI_incl

    
    sinGammaN=numpy.sin(GammaN)
    cosGammaN=numpy.cos(GammaN)
    # from the paper
    F11R=numpy.array([ 0.041, 0.054, 0.227, 0.486, 0.819, 1.020, 1.009, 0.936])
    F12R=numpy.array([ 0.621, 0.966, 0.866, 0.670, 0.106,-0.260,-0.708,-1.121])
    F13R=numpy.array([-0.105,-0.166,-0.250,-0.373,-0.465,-0.514,-0.433,-0.352])
    F21R=numpy.array([-0.040,-0.016, 0.069, 0.148, 0.268, 0.306, 0.287, 0.226])
    F22R=numpy.array([ 0.074, 0.114,-0.002,-0.137,-0.497,-0.804,-1.286,-2.449])
    F23R=numpy.array([-0.031,-0.045,-0.062,-0.056,-0.029, 0.046, 0.166, 0.383])
    EPSBINS=numpy.array([ 1.056, 1.253, 1.586, 2.134, 3.23, 5.98, 10.08,99.99])
    
    # R. Perez naming style conversion______________________________________________________________________
#    DiffHor = GHI - DNI*numpy.sin(h0)

    
#    percentile_coefs={'P1':0.025, 'P5':0.125, 'P25':0.225, 'P50':0.250, 'P75':0.225, 'P95':0.125, 'P99':0.025}
    percentile_coefs=percentiles_weights_dict(percentiles)
    Z=(math.pi/2.)-h0 # rad!!
    Z[Z<0.4]=0.4 
    
    B2 = 5.534e-6
    
    CZ = numpy.sin(h0)
    ZENITH = (math.pi/2. - h0) * 180./math.pi
    wh_cz=CZ <= 0.0
    CZ2=CZ.copy()
    CZ2[CZ2<0.0871557]=0.0871557
    
    AIRMASS=numpy.zeros_like(h0)
    wh1=ZENITH<93.9
    AIRMASS[wh1]=1.0/(CZ[wh1] + (0.15* numpy.power((93.9 - ZENITH[wh1]),-1.253)))
    wh1=(ZENITH>=93.9)
    AIRMASS[wh1]=999
    
    TB2 = B2*numpy.power(ZENITH,3)
    I= numpy.empty(GHI_perc[0,:,:,:,:].shape, dtype=numpy.int8)
    sinDeltaexp[sinDeltaexp< 0.0]=0.0
    
    
    
    
    #angular correction coefficients
    if doPVAngularCorr:
        isScalar = (cosGammaN.ndim == 0)
        # based on the PV_AngularDependence function direct Thomas PVGIS implementation (Martin and Ruiz 2001 approach)
        #from Artur's PV_Angular function in solar_geom_v6.py 
        ar=0.16 # The algorithm used in PVGIS uses that value
        ar_exp=math.exp(-1./ar)

        cosGammaN2=cosGammaN
        if isScalar:  #if working with scalar (fixed system)
            if cosGammaN >0.98:
                cosGammaN2 = 0.98
        else:
            wh_g = cosGammaN2 > 0.98
            cosGammaN2[wh_g] = 0.98
#        wh_g = cosGammaN > 0.98
#        cosGammaN2[wh_g] = 0.98
#        if cosGammaN >0.98:
#            cosGammaN2 = 0.98
        c1=4./(3.*math.pi)
        c2=ar/2.-0.154
        
        #beam correction
        Bcorr=(1.-(numpy.exp(-sinDeltaexp/ar)-ar_exp)/(1.-ar_exp))
        #reflected correction
        fr=sinGammaN + (GammaN-sinGammaN)/(1.-cosGammaN2)
#        Rcorr=max(0.,(1.-numpy.exp((-c1*fr-c2*fr*fr)/ar)))
        Rcorr=(1.-numpy.exp((-c1*fr-c2*fr*fr)/ar))
        if isScalar: #scalar
            if Rcorr<0.:
                Rcorr=0.
        else:
            Rcorr[Rcorr<0.] = 0.
        #diffused correction 
        fd=sinGammaN + (math.pi-GammaN-sinGammaN)/(1.+cosGammaN2)
#        Dcorr = max(0.,(1.-math.exp((-c1*fd-c2*fd*fd)/ar)))
        Dcorr = (1.-numpy.exp((-c1*fd-c2*fd*fd)/ar))
        if isScalar:
            if Dcorr < 0.:
                Dcorr=0.
        else:
            Dcorr[Dcorr<0.] = 0.
        del (fd,fr)
    else:
        Bcorr=1.0
        Rcorr=1.0
        Dcorr=1.0

    

    
    
    
    #empty arrays for results
    #used for normalization 
    GHIp = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    
    # irradiation components
    cDNI_incl = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cREFL_incl = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_horiz = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_circ = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_iso_skydome = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    cDIF_iso_refl = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    
    
    for perc in percentiles:
        logger.info('Percentile: '+str(perc))
        #get data for given percentile
        perc_idx = percentiles.index(perc)
        GHI = GHI_perc[perc_idx, :,:,:,:]
        DNI = DNI_perc[perc_idx, :,:,:,:]
        #weight of percentile in total average
        perc_wght = percentile_coefs[perc]

        DiffHor = GHI - (DNI* CZ)
        DiffHor[wh_cz] = GHI[wh_cz]
        DELTA = DiffHor * AIRMASS / 1367. #Solar constant
        
#        EPS = (DNI + DiffHor) / DiffHor
#        EPS = (EPS + TB2) / (1.0 + TB2)
        EPS=numpy.zeros_like(DiffHor)
        #added to avoid zero division
        wh_diff_no0=DiffHor!=0
        EPS[wh_diff_no0] = (DNI[wh_diff_no0] + DiffHor[wh_diff_no0]) / DiffHor[wh_diff_no0]
        EPS = (EPS + TB2) / (1.0 + TB2)
#        EPS = (((DNI + DiffHor) / DiffHor) + TB2) / (1.0 + TB2)
        
        I[:,:,:,:]=7
        I[(EPS<=EPSBINS[6]) & (EPS>EPSBINS[5])]=6
        I[(EPS<=EPSBINS[5]) & (EPS>EPSBINS[4])]=5
        I[(EPS<=EPSBINS[4]) & (EPS>EPSBINS[3])]=4
        I[(EPS<=EPSBINS[3]) & (EPS>EPSBINS[2])]=3
        I[(EPS<=EPSBINS[2]) & (EPS>EPSBINS[1])]=2
        I[(EPS<=EPSBINS[1]) & (EPS>EPSBINS[0])]=1
        I[(EPS<=EPSBINS[0])]=0
        
        F1 = F11R[I] + F12R[I]*DELTA + F13R[I] * Z
        F1[F1<0.]=0.
        F2 = F21R[I] + F22R[I] * DELTA + F23R[I] * Z
        
        
        #GHI derived from percentiles - used for normalization
        GHIp += ((DiffHor) + (CZ*DNI)) * perc_wght

        cDIF_iso_skydome += Dcorr * DiffHor * (( 1.0 + cosGammaN) / 2.0) * (1-F1)  * perc_wght
        cDIF_iso_refl += Dcorr * Albedo * GHI * perc_wght
        cDIF_horiz += Dcorr * DiffHor * sinGammaN * F2 * perc_wght
        cDIF_circ += Bcorr * DiffHor * (sinDeltaexp/ CZ2) * F1 * perc_wght 
        cREFL_incl += (Rcorr * Albedo * GHI * (1.0 - cosGammaN)/2.0) * perc_wght
        cDNI_incl += Bcorr * sinDeltaexp * DNI * perc_wght
        
        del(F1, F2, DELTA, EPS, DiffHor)


    # normalize the percentile derived statistics by mean. in other words the percentiles are used only in relative way,
    # the output mean from percentiles is corrected to be equal to real mean from the data
    wh_corr = GHIp>0.0
    corr = numpy.zeros(GHI_perc[0,:,:,:,:].shape,dtype=numpy.float32)
    corr[wh_corr] = GHI_mean[wh_corr]/GHIp[wh_corr]
    cDIF_iso_skydome *= corr
    cDIF_iso_refl *= corr
    cDIF_horiz *= corr
    cDIF_circ *= corr
    cREFL_incl *= corr
    cDNI_incl *= corr
    
    del(AIRMASS, corr)
    del(Z,I)

    return cDIF_iso_skydome, cDIF_iso_refl, cDIF_horiz, cDIF_circ, cREFL_incl, cDNI_incl


#------------------------------------------------------------
# main
#------------------------------------------------------------

if __name__ == "__main__":
    
    mail_notification='tomas.cebecauer@solargis.com' #email addres to send finish notification to, Use '' to avoid mail notification
#    mail_notification=None
    
    version='v21'
    
    lowres_data_path='/data/model_data_himawari/data_output_wgs84/v20_combined_2007_2016/'

    horizon_path='/net/atlas/data/horizon/horiz_dir48_30arcsec/'  # /net/hydra/home1/horiz/
    horiz_name_prefix,horiz_name_suffix =horizon_path+'horizon_', '_dir48'

    
    #temperature
    temperature_filename='/net/sponde/data/weather_params/Longterm_CFSR/CFSR_t2_monthly_24h_longterm.nc' 
    temperature_varname='t2_mean'
    orography_filename='/net/sponde/data/weather_params/Longterm_CFSR/CFSR_orogr.nc'
    orography_varname='orog'
    srtm30_filename_pattern='/net/sponde/data/srtm30/srtm30_ns%d_ew%d.nc'    
    srtm30_varname='srtm30'
    temp_corr_coeff=0.37
    
    #output
    highres_data_path='/data/model_data_himawari/data_output_dissagr/v20_combined_2007_2016/'


    # 5x5 degree latlon tiles to calculate 
    region_suffix='_pan'
#    region_suffix='_pas'
    segments_to_calculate=latlon.expand_segments([[55, 55, 16, 16]])

    force_overwrite = True
    
    save_15_min_results = True #otherwise only montly will be saved
    
    resolution=10 # 3x3, 5x5, 10x10 pixels; original pixels have 3 arcsec res

    inclination_from_file=True
    inclination_filename = lowres_data_path+'OPTA%s.nc' % (region_suffix)
    inclination_var_name = 'opta'

    inclination=30 #module/axis inclination
    azimuth=180 #module azimuth 180-south
#    azimuth=90 #module azimuth 180-south
    
    if len(sys.argv) == 3:
        inclination = int(sys.argv[1])
        azimuth = int(sys.argv[2])
    elif len(sys.argv) != 1:
        print 'ERROR: only 0 or two arguments allowed. EXIT. \nUSAGE:\nmfg_model_out_dissaggregate_PV.py inclination azimuth\nmfg_model_out_dissaggregate_PV.py #inclination/azimuth are defined in the script '
        exit()
        
    mounting=1 
#            1 - fixed
#            5 - t1xV 1-axis tracker, vertical axis, inclined module 
#            6 - t1xI 1-axis tracker, inclined axis
#            7 - t1xNS 1-axis tracker, horizontal NS axis
#            8 - t1xEW 1-axis tracker, horizontal EW axis
#            9 - t2x 2-axis tracker

    #PV parameters
    ModuleType = 1 # 1-Crystalline Silicon; 3-CdTe; 4-CIS
    #DEPRICATED 0.020 - standalone, 0.045 - highly integrated; recommended standalone #    CdTe=0.030,    cSi=0.025
    #20100202: free standing:, cSi=0.030,
    #             CdTe= cSi + 0.005 = 0.035
    ModuleTemp_coeff = 0.0325 #+ 0.01 #+0.01 is for roof mounted   ; NOCT=46; TempCoef = NOCT-20/800
    
    other_losses_coef = 0.91 #coefficient for other losses e.g. 0.9 for 10% losses; 1.0 for no other losses
#    other_losses_coef = 1.0 #coefficient for other losses e.g. 0.9 for 10% losses; 1.0 for no other losses

    RotationRange_r=numpy.radians(45)
    Backtrack=True
    BacktrackRelativeSpacing=2.5
    
    hires_interpol='bilinear'

    specific_year=None # None

    print 'Disaggregation PV: inclination:%d, azimuth:%d, mounting:%d ModuleTemp_coeff:%.5f other_losses_coef:%.3f' % (inclination, azimuth, ModuleType,ModuleTemp_coeff,other_losses_coef)

    #make subset only. if Subset_bos  set to None, then do whole segments
#    sub_xmin, sub_xmax, sub_ymin, sub_ymax, sub_res = 80, 81, 9, 10, 0.25
#    sub_xmin, sub_xmax, sub_ymin, sub_ymax, sub_res = 51, 57, 22, 27, 0.25
#    sub_xmin, sub_xmax, sub_ymin, sub_ymax, sub_res = 54, 55, 24, 26, 0.25
#    sub_xmin, sub_xmax, sub_ymin, sub_ymax, sub_res = 54, 54+(4./60.), 25.-(4./60.), 25+(4./60.), 2./60.
#    Subset_box=latlon.bounding_box(xmin=sub_xmin, xmax=sub_xmax, ymin=sub_ymin, ymax=sub_ymax, width=int(math.floor(((sub_xmax-sub_xmin)/sub_res)+0.5)), height=int(math.floor(((sub_ymax-sub_ymin)/sub_res)+0.5)), resolution=sub_res)
    Subset_box = None


    percentiles = [1, 10, 25, 50, 75, 90, 99] #MUST be same as those within ...merge_segments.py

#-------------------------------------------------
    Albedo = 0.125
    
    #inputs
    time_step_hours = 0.25
    inslot_min, inslot_max = 1, 96  # for input
    outtime_step_hours = 0.25
    outslot_min, outslot_max = 1, 96

    #inputs
    NC_in_GHI_name=lowres_data_path+'GHI_15min_m_stats%s.nc' % (region_suffix)
    NC_in_DNI_name=lowres_data_path+'DNI_15min_m_stats%s.nc' % (region_suffix)
    
    if specific_year is not None:
        NC_year_GHI_name=lowres_data_path+'GHI_d_m'+region_suffix+'.nc'
        NC_year_DNI_name=lowres_data_path+'DNI_d_m'+region_suffix+'.nc'

    #outputs - resolution
    if resolution == 1:#1 arcsec pixels == 9 arcsec
        out_res_suffix='3arcsec_'+str(ModuleType)
        horiz_name_suffix=horiz_name_suffix+'.nc'
    elif resolution == 3:#3 arcsec pixels == 9 arcsec
        out_res_suffix='9arcsec_'+str(ModuleType)
        horiz_name_suffix=horiz_name_suffix+'_resc3.nc'
    elif resolution == 5:#5 arcsec pixels == 15 arcsec
        out_res_suffix='15arcsec_'+str(ModuleType)
        horiz_name_suffix=horiz_name_suffix+'_resc5.nc'
    elif resolution == 10:#10 arcsec pixels == 30 arcsec
        out_res_suffix='30arcsec_'+str(ModuleType)
        horiz_name_suffix=horiz_name_suffix+'_resc10.nc'
    
    #outputs - specific year
    if specific_year is not None:
        out_res_suffix+='_%d'%(specific_year)

    #outputs - inclinationand mounting
    if (mounting == 1):
        if inclination_from_file:
            out_Gincl_str='opta'
        elif inclination>0:
            out_Gincl_str='I'+str(inclination)+'A'+str(azimuth)
        else:
            out_Gincl_str='H'
    elif (mounting == 5) or (mounting == 6):
        out_Gincl_str=mounting_geom.mounting_shortname(mounting, preffix="t")+str(inclination)
    else:
        out_Gincl_str=mounting_geom.mounting_shortname(mounting, preffix="t")

    if save_15_min_results:
        out_PV_name_prefix,out_PV_name_suffix =highres_data_path+'PV_'+out_Gincl_str+'_15min_m_', '_'+out_res_suffix+'.nc' # 
    out_PV_name_prefix_m,out_PV_name_suffix_m =highres_data_path+'PV_'+out_Gincl_str+'_m_', '_'+out_res_suffix+'.nc' # 
    
    
    modul_asp_r = numpy.radians(azimuth -180)

    out_res= resolution * 1./1200. #240. for 15arcsec, 400. for 9arcsec
    in_res = 2./60.
    
    for seg_col, seg_row in segments_to_calculate:
        logger.info( 'seg: %d %d' %( seg_row,seg_col))
        out_latlon_bbox=latlon.get_5x5_seg_bbox(seg_row, seg_col , out_res, seg_size=5.)
        in_latlon_bbox=latlon.get_5x5_seg_bbox(seg_row, seg_col , in_res, seg_size=5.)


        #check if only subsegment has to be calculated
        if not(Subset_box is None) and not(out_latlon_bbox.intersect(Subset_box)):
            logger.info('Skipping seg: %d %d. Out of Subset_box' %( seg_row,seg_col))
            continue

        if Subset_box is not None:
            read_lowres_bbox = out_latlon_bbox.intersect(Subset_box)
        else:
            read_lowres_bbox = out_latlon_bbox

        #SRTM30 (for temperature dissagregation) bbox 
        srtm30_filename=srtm30_filename_pattern%(seg_row,seg_col)
        srtm30_res=1./120.
        srtm30_bbox = latlon.get_5x5_seg_bbox(seg_row, seg_col , srtm30_res)
        read_lowres_temp_bbox = srtm30_bbox.intersect(read_lowres_bbox)
        
            
        #check existence of horizon file           
        NC_horiz_filename=horiz_name_prefix+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+horiz_name_suffix
        if not(os.access(NC_horiz_filename, os.F_OK)):
            logger.warning("Input horizon NetCDF file %s not found. skipping segment",NC_horiz_filename)
            continue

        #check existence of temperature file           
        if not(os.access(temperature_filename, os.F_OK)):
            logger.warning("Input CFSR Temper NetCDF file %s not found. skipping segment",temperature_filename)
            continue

        
        #create output NC files
        if save_15_min_results:
            NC_out_PV_filename=out_PV_name_prefix+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_PV_name_suffix
            result = make_model_output_disaggreg_ms_latlon(NC_out_PV_filename,out_latlon_bbox,overwrite = force_overwrite, slot_min=outslot_min, slot_max=outslot_max,logger=logger, version=version)
        NC_out_PV_filename_m=out_PV_name_prefix_m+"ns"+zfill(str(seg_row),1)+"_ew"+zfill(str(seg_col),0)+out_PV_name_suffix_m
        result &= make_model_output_disaggreg_m_latlon(NC_out_PV_filename_m,out_latlon_bbox,overwrite = force_overwrite,logger=logger, version=version)
        if result==False: 
            logger.error("Unable to create output files. Exit")
            sys.exit()
        

        #read lowres data
        logger.info('Reading lowres GHI data')
        var_names=disaggregate_common.percentiles_names_list(percentiles)
        result = disaggregate_common.read_lowres_multi_data_for_highres_bbox(NC_in_GHI_name, var_names, read_lowres_bbox, inslot_min, inslot_max,logger)
        if result is None: 
            sys.exit()
        GHI_lowres, lowres_bbox = result
        var_name='mean'
        result = disaggregate_common.read_lowres_data_for_highres_bbox(NC_in_GHI_name, var_name, read_lowres_bbox, inslot_min, inslot_max,logger)
        if result is None: 
            sys.exit()
        GHI_lowres_mean, lowres_bbox = result


        logger.info('Reading lowres DNI data')
        var_names=disaggregate_common.percentiles_names_list(percentiles)
        result = disaggregate_common.read_lowres_multi_data_for_highres_bbox(NC_in_DNI_name, var_names, read_lowres_bbox, inslot_min, inslot_max,logger)
        if result is None: 
            sys.exit()
        DNI_lowres, lowres_bbox = result
        var_name='mean'
        result = disaggregate_common.read_lowres_data_for_highres_bbox(NC_in_DNI_name, var_name, read_lowres_bbox, inslot_min, inslot_max,logger)
        if result is None: 
            sys.exit()
        DNI_lowres_mean, lowres_bbox = result


        if specific_year is not None:
            logger.info('Reading lowres data for year %s' % (specific_year))
            var_name='GHI_d_m'
            result = disaggregate_common.read_lowres_data_year_for_highres_bbox(NC_year_GHI_name, var_name, read_lowres_bbox, specific_year,logger)
            if result is None: 
                sys.exit()
            GHI_lowres_year_mean, lowres_bbox = result
            var_name='DNI_d_m'
            result = disaggregate_common.read_lowres_data_year_for_highres_bbox(NC_year_DNI_name, var_name, read_lowres_bbox, specific_year,logger)
            if result is None: 
                sys.exit()
            DNI_lowres_year_mean, lowres_bbox = result
            #adapt_mean_percentile to year mean
            for m in range(0,12):
                mmeanG=GHI_lowres_mean[m,:,:,:].sum(axis=0)*time_step_hours
                whG = mmeanG != 0
                rescG=GHI_lowres_year_mean[m,whG]/mmeanG[whG]
                mmeanD=DNI_lowres_mean[m,:,:,:].sum(axis=0)*time_step_hours
                whD = mmeanD != 0
                rescD=DNI_lowres_year_mean[m,whD]/mmeanD[whD]
                for s in range(0,inslot_max-inslot_min+1):
                    GHI_lowres_mean[m,s,whG]*=rescG
                    DNI_lowres_mean[m,s,whD]*=rescD
        
        
        #inclination
        if inclination_from_file:
            #read lowres data
            logger.info('Reading lowres opta data')
            incl = latlon_nctools.latlon_read_lat_lon_nc_bbox(inclination_filename, inclination_var_name, lowres_bbox, interpolate='nearest')
            if result is None: 
                sys.exit()
            modul_incl_r=numpy.radians(incl)
        else:
            modul_incl_r=numpy.radians(inclination)

#        print lowres_bbox
        
        
        #read temperatures
        logger.info('Reading temperature data')
        result = latlon_nctools.latlon_read_month_hour_lat_lon_nc_bbox(temperature_filename, temperature_varname, Hours=[0,23], Months=[1,12], bbox=read_lowres_temp_bbox, interpolate='bilinear')
        if result is None: 
            sys.exit()
        temper_hourly = result

  
        logger.info('Reading orography data')
        result = latlon_nctools.latlon_read_lat_lon_nc_bbox(orography_filename, orography_varname, read_lowres_temp_bbox, interpolate='bilinear')
        if result is None: 
            sys.exit()
        orog = result

        logger.info('Reading srtm30 data')
        result = latlon_nctools.latlon_read_lat_lon_nc_bbox(srtm30_filename, srtm30_varname, read_lowres_temp_bbox, interpolate='bilinear')
        if result is None: 
            sys.exit()
        srtm30 = result



        logger.info('Apply temperature correction')
        temp_correction=-temp_corr_coeff*0.01*(srtm30-orog)
        mm,hh,rr,cc = temper_hourly.shape
        for m in range(mm):
            for h in range(hh):
                temper_hourly[m,h,:,:]=temper_hourly[m,h,:,:]+temp_correction 

        logger.info('Interpolate temperature data 24>96')
        in_time_arr=numpy.empty((24),dtype=numpy.float64)
        for slot in range(0,23+1):
            in_time_arr[slot]=slot
        out_time_arr=numpy.empty((96),dtype=numpy.float64)
        for slot in range(1,96+1):
            out_time_arr[slot-1]=(slot/4.) - (outtime_step_hours/2.)
        extrapolate_size = 1
        in_time_arr_ext=numpy.hstack([in_time_arr[0]-1, in_time_arr, in_time_arr[-1]+1])
        mm,dummy,rr,cc = temper_hourly.shape
        temper_15min = numpy.empty((mm,96,rr,cc), dtype=temper_hourly.dtype)
        for month in range(1,12+1):
            temper_15min[month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,temper_hourly[month-1,:,:,:], extrapolate_size, normalize=False)


#        logger.info('Interpolate irrad data 48>96 time slots')
##        aS=datetime.datetime.now()
##        longit, latit = out_latlon_bbox.center()
##        mfg_scann_offset = mfg_geom.lonlat2toffset_h(longit, latit, lon0=sat_lon0)
#        in_time_arr=numpy.arange(0.25,24.0,0.5) # goes output 30 min slot mapping 
#        out_time_arr=numpy.empty((96),dtype=numpy.float64)
#        for slot in range(1,96+1):
#            out_time_arr[slot-1]=(slot/4.) - 0.125
#
#        #rotate in data and time array    
##        in_time_arr_ext=numpy.roll(in_time_arr,shift=-1,axis=0)  #never use this for PRIME and IODC !!!!!!!
#        in_time_arr_ext=numpy.hstack([numpy.array(-0.25), in_time_arr, numpy.array(24.25)])
#        
#        mm,dummy,rr,cc = GHI_lowres_mean.shape
#        GHI_lowres_mean96 = numpy.empty((mm,96,rr,cc), dtype=GHI_lowres_mean.dtype)
#        DNI_lowres_mean96 = numpy.empty((mm,96,rr,cc), dtype=DNI_lowres_mean.dtype)
#        pp,mm,dummy,rr,cc = GHI_lowres.shape
#        GHI_lowres96 = numpy.empty((pp,mm,96,rr,cc), dtype=GHI_lowres.dtype)
#        DNI_lowres96 = numpy.empty((pp,mm,96,rr,cc), dtype=DNI_lowres.dtype)
#            
#        for month in range(1,12+1):
#            GHI_lowres_mean96[month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,GHI_lowres_mean[month-1,:,:,:])
#            DNI_lowres_mean96[month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,DNI_lowres_mean[month-1,:,:,:])
#            for p_idx in range(0,pp):
#                GHI_lowres96[p_idx,month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,GHI_lowres[p_idx,month-1,:,:,:])
#                DNI_lowres96[p_idx,month-1,:,:,:]=_interp_2d(out_time_arr,in_time_arr_ext,DNI_lowres[p_idx,month-1,:,:,:])
#        
#        GHI_lowres=GHI_lowres96
#        DNI_lowres=DNI_lowres96
#        GHI_lowres_mean=GHI_lowres_mean96
#        DNI_lowres_mean=DNI_lowres_mean96
        

        logger.info('Calculating solar geometry')
        a0_grid_15min, h0_grid_15min = make_sunposit_grids_min15(lowres_bbox)

        
        logger.info('Calculating module geometry')
#        latitude_2d, longitude_2d = make_lat_lon_grids(lowres_bbox)
        sina0_grid = numpy.sin(a0_grid_15min)
        cosa0_grid = numpy.cos(a0_grid_15min)
        sinh0_grid = numpy.sin(h0_grid_15min)
        cosh0_grid = numpy.cos(h0_grid_15min)
        rotation_limit = [None, None]
        rotation_limit2 = [None, None]
        backtrack = False
        relative_spacing_rows = 0
        relative_spacing_columns = 0
#        inc_angle_cos_grid, GammaNV = mounting_geom.mounting_incidencecos_gamma(mounting, a0_grid_15min, h0_grid_15min, modul_incl_r, modul_asp_r, latitude_2d)
        latitude_2d=lowres_bbox.latitudes(array2d=True)
#        dummy, GammaNV, dummy, inc_angle_cos_grid, dummy,dummy, dummy, dummy = mounting_geom.mounting_geom_angles(mounting, a0_grid_15min, h0_grid_15min, GN=modul_incl_r, AN=modul_asp_r, latitude=latitude_2d)
        dummy, inc_angle_cos_grid, GammaNV ,dummy, dummy, dummy, dummy, dummy, dummy, dummy, dummy = mounting_geom.mounting_geom_angles(mounting, sina0_grid, cosa0_grid, a0_grid_15min, sinh0_grid, cosh0_grid, h0_grid_15min, GN=modul_incl_r, AN=modul_asp_r, latitude=latitude_2d, rotation_limit=rotation_limit, rotation_limit2=rotation_limit2, backtrack=backtrack, relative_spacing_rows=relative_spacing_rows, relative_spacing_columns=relative_spacing_columns)
        
        
        logger.info('Calculating diffuse components')

    
        cDIF_iso_skydome_p, cDIF_iso_refl_p, cDIF_horiz_p, cDIF_circ_p, cREFL_incl_p, cDNI_incl_p = disaggregate_common.diffinc_PerezFast_shadingGcomponents_percentiles_GHInormalized(GHI_lowres, GHI_lowres_mean, DNI_lowres, h0_grid_15min, GammaNV, Albedo, inc_angle_cos_grid, percentiles, doPVAngularCorr=True, output_percentiles=True)


        #test if lowres box covers whole out_latlon_bbox
        res=out_latlon_bbox.intersect(read_lowres_bbox)
        if not res.equals(out_latlon_bbox):
            logger.warning("lowres data does not cover whole segment bbox, reducing")
            out_latlon_bbox2=res
        else:
            out_latlon_bbox2=out_latlon_bbox
        

        #resampling
        if resolution > 3:
            subseg_bboxes = out_latlon_bbox2.subsegments(subseg_size=0.5)
        elif resolution == 3:
            subseg_bboxes = out_latlon_bbox2.subsegments(subseg_size=0.25)
        else:
            subseg_bboxes = out_latlon_bbox2.subsegments(subseg_size=0.1)
    
        
        dim0_minmax=[1,12]
        dim1_minmax=[outslot_min, outslot_max]
        
        counter=0
        for ss_box in subseg_bboxes:
            counter+=1
            if not(Subset_box is None) and not(ss_box.intersect(Subset_box)):
                logger.info('Skipping subsegment: %d/%d. Out of Subset_box' %( counter,len(subseg_bboxes)))
                continue
            logger.info('Processing subsegment %d/%d',counter,len(subseg_bboxes))
            res = out_latlon_bbox.pixel_coords_of_bbox(ss_box)
            dim2_minmax = res[2:4]
            dim3_minmax = res[0:2]
            
            
            

            
            
            projgrids = ss_box.px_idx_grid_of_second_bbox(lowres_bbox)
            a0_dissag = disaggregate_common.data_resample(a0_grid_15min, projgrids, interpolation=hires_interpol)
            h0_dissag = disaggregate_common.data_resample(h0_grid_15min, projgrids, interpolation=hires_interpol)
            cDIF_iso_skydome_p_dissag = disaggregate_common.data_resample(cDIF_iso_skydome_p, projgrids, interpolation=hires_interpol)
            cDIF_iso_refl_p_dissag = disaggregate_common.data_resample(cDIF_iso_refl_p, projgrids, interpolation=hires_interpol)
            cDIF_horiz_p_dissag = disaggregate_common.data_resample(cDIF_horiz_p, projgrids, interpolation=hires_interpol)
            cDIF_circ_p_dissag = disaggregate_common.data_resample(cDIF_circ_p, projgrids, interpolation=hires_interpol)
            cREFL_incl_p_dissag = disaggregate_common.data_resample(cREFL_incl_p, projgrids, interpolation=hires_interpol)
            cDNI_incl_p_dissag = disaggregate_common.data_resample(cDNI_incl_p, projgrids, interpolation=hires_interpol)


            if (modul_incl_r.ndim == 2):
                modul_incl_r_dissag = disaggregate_common.data_resample(modul_incl_r, projgrids, interpolation=hires_interpol)
            else:
                modul_incl_r_dissag = modul_incl_r
                
            #disaggregate temperatures            
            T_projgrids = ss_box.px_idx_grid_of_second_bbox(read_lowres_temp_bbox)
            
            Temper_ss = disaggregate_common.data_resample(temper_15min, T_projgrids, interpolation=hires_interpol)
                
            #read horizons
            horizons = disaggregate_common.read_horizon_nc_file(NC_horiz_filename,dim3_minmax[0],dim3_minmax[1],dim2_minmax[0],dim2_minmax[1],'horizons',logger)
            if horizons is None: continue
            num_direct=horizons.shape[0]
            
            #shading for direct and circumsolar diffuse            
            shading_direct = disaggregate_common.shading_direct(horizons,h0_dissag,a0_dissag,ss_box,outslot_min,outslot_max)

            #shading for isotropic diffuse            
            out_shape = cDNI_incl_p_dissag.shape[1:]
            modul_asp_r_dissag=modul_asp_r
            isotropic_shading_factor = disaggregate_common.shading_isotropic(horizons,mounting,modul_incl_r_dissag,modul_asp_r_dissag,ss_box, out_shape)

            
            #dissagregate (apply shading) GHI and module temperature 
            GHI_incl_p_dissag_sh = numpy.zeros_like(cDNI_incl_p_dissag)
            Temper_module_p=numpy.zeros_like(GHI_incl_p_dissag_sh)
            
            for perc in percentiles:
                perc_idx = percentiles.index(perc)
                DIF_incl_dissag_sh = (cDIF_iso_skydome_p_dissag[perc_idx,:, :, :, :]*isotropic_shading_factor) + (cDIF_iso_refl_p_dissag[perc_idx,:, :, :, :]*(1.-isotropic_shading_factor)) + cDIF_horiz_p_dissag[perc_idx,:, :, :, :] + (cDIF_circ_p_dissag[perc_idx,:, :, :, :]*(1.-shading_direct))
                DNI_incl_dissag_sh = cDNI_incl_p_dissag[perc_idx,:, :, :, :]*(1.-shading_direct) #DNI in inlined plane
                GHI_incl_p_dissag_sh[perc_idx,:, :, :, :] = DIF_incl_dissag_sh + cREFL_incl_p_dissag[perc_idx,:, :, :, :] + DNI_incl_dissag_sh 
                #module temperature
                Temper_module_p[perc_idx,:, :, :, :] = Temper_ss[:,:,:,:] + ModuleTemp_coeff*GHI_incl_p_dissag_sh[perc_idx,:, :, :, :]



            #calculate PV
            PV_incl_p_dissag_sh = numpy.zeros_like(GHI_incl_p_dissag_sh)
            P_STC=1000.
            if ModuleType==2: #aSi
                aSi_corr=aSicorectorMonthly(GHI_incl_p_dissag_sh,Temper_module_p)
                P_STC*=aSi_corr
            for slot_idx in range(0, outslot_max-outslot_min +1):
                res=PVModule(P_STC=P_STC,Gin=GHI_incl_p_dissag_sh[:,:,slot_idx,:,:],Tin=Temper_module_p[:,:,slot_idx,:,:], ModuleType=ModuleType)
                PV_incl_p_dissag_sh[:,:,slot_idx,:,:] = res*other_losses_coef
            
           
            #sum result over percentiles
            PV_incl_dissag_sh=numpy.zeros_like(PV_incl_p_dissag_sh[0,:,:,:,:])
            percentile_coefs=disaggregate_common.percentiles_weights_dict(percentiles)#            {'P1':0.025, 'P5':0.125, 'P25':0.225, 'P50':0.250, 'P75':0.225, 'P95':0.125, 'P99':0.025}
            for perc in percentiles:
                perc_wght = percentile_coefs[perc]
                perc_idx = percentiles.index(perc)
                PV_incl_dissag_sh += PV_incl_p_dissag_sh[perc_idx,:,:,:,:]*perc_wght
            
            PV_ma=numpy.ma.masked_where(numpy.isnan(PV_incl_dissag_sh),PV_incl_dissag_sh)
            PV_ma_sum=PV_ma.sum(axis=1)*outtime_step_hours
               
            #write otputs
            var_name = 'mean'
            if save_15_min_results:
                disaggregate_common.write_proj_model_output_disaggreg_4dim(NC_out_PV_filename, var_name, dim0_minmax, dim1_minmax, dim2_minmax, dim3_minmax, PV_incl_dissag_sh, logger)
            disaggregate_common.write_proj_model_output_disaggreg_3dim(NC_out_PV_filename_m, var_name, dim0_minmax, dim2_minmax, dim3_minmax, PV_ma_sum, logger)
            
#            if counter>20:break
        logger.info( 'finished seg: r%d c%d' %( seg_row,seg_col))
    logger.info("finished")
    if mail_notification is not None:
        basic_mail.mail_process_message_ssl(reciever_to=mail_notification, message='PV disagregation finished.' )
        
        